## **Step 0 â€” Prep**

- Pick a **Celery broker** (Redis or RabbitMQ)
- Decide on **task/result handling** (Postgres remains source of truth)
- Ensure your **services/data_ingestion** is **pure business logic**, no Celery or BackgroundTasks

---

## **Step 1 â€” Add Celery bootstrap**

1. Create `celery_app.py`:

```python
from celery import Celery
from app.core.config import settings

celery_app = Celery(
    "backend",
    broker=settings.CELERY_BROKER_URL,
    backend=settings.CELERY_RESULT_BACKEND,
)
celery_app.autodiscover_tasks(["app.tasks"])
```

2. Keep **FastAPI imports separate** to avoid side effects

---

## **Step 2 â€” Move worker orchestration to `tasks/`**

1. Create `tasks/ingestion_tasks.py`
2. Wrap your current worker function in a Celery task
3. Use **serializable arguments only** (IDs, strings, dicts)
4. Inside the task:
   - reconstruct provider/service
   - update job status in Postgres (`RUNNING`, `SUCCESS`, `FAILED`)

```python
@celery_app.task(bind=True)
def run_ingestion(provider_name: str, job_id: int, filters: dict):
    # Reconstruct provider & service
    # Update job status
    # Run logic
```

---

## **Step 3 â€” Refactor FastAPI route**

- Remove `background_tasks.add_task(...)`
- Enqueue Celery task instead:

```python
job_id = await provider.create_job(...)
run_ingestion.delay(
    provider_name=provider.__class__.__name__,
    job_id=job_id,
    filters=request.filters,
)
```

- The API is now **thin, only I/O + enqueue**

---

## **Step 4 â€” Separate responsibilities**

| Layer          | Responsibility                    |
| -------------- | --------------------------------- |
| `api`          | HTTP, auth, enqueue, SSE          |
| `tasks`        | Orchestration, retries, lifecycle |
| `services`     | Pure business logic, reusable     |
| `repositories` | DB access                         |
| `models`       | ORM/SQLModel                      |
| `db`           | DB connection + migrations        |

---

## **Step 5 â€” SSE / frontend updates**

1. Use **Postgres as authoritative source**
2. Two options:
   - **Option A:** LISTEN / NOTIFY
     - Celery task calls `NOTIFY job_updates, ...`
     - FastAPI SSE endpoint streams notifications

   - **Option B:** Poll DB in SSE loop (simpler but more load)

```python
@app.get("/jobs/stream")
async def job_stream():
    async for payload in listen_pg("job_updates"):
        yield {"event": "job_update", "data": payload}
```

---

## **Step 6 â€” Docker / Deployment**

- **One Docker image** for both API and worker
- Override CMD/entrypoint:

```yaml
# docker-compose example
api:
  image: backend:latest
  command: uvicorn app.main:app --host 0.0.0.0 --port 8000

worker:
  image: backend:latest
  command: celery -A app.celery_app worker -l info
```

---

## **Step 7 â€” Optional improvements**

- Add **idempotency** in tasks (use job_id)
- Add **retry policy** via Celery
- Add **queues** if different ingestion types require prioritization

---

### âœ… Outcome

- FastAPI is **fast and decoupled**
- Celery handles **all background tasks**
- Job status remains in Postgres
- Frontend can receive **near-real-time updates via SSE**
- Clear separation of concerns prevents coupling or code drift

---

### **visual mini-diagram + â€œbefore vs afterâ€ tableâ€** so you have a one-page reference for

---

## **Before: FastAPI BackgroundTasks**

```
Client
  â”‚
  â–¼
FastAPI API â”€â”€> background_tasks.add_task(run_sync_task)
  â”‚
  â””â”€ executes job in same process/thread
       â”‚
       â””â”€ services/data_ingestion/*.py
            â”‚
            â””â”€ repositories â†’ Postgres
```

**Drawbacks:**

- API thread blocked until DB writes complete
- No retries / limited lifecycle
- Hard to scale horizontally

---

## **After: Celery + SSE**

```
Client
  â”‚
  â–¼
FastAPI API â”€â”€> enqueue task â”€â”€> Broker (Redis/RabbitMQ)
  â”‚                                  â”‚
  â”‚                                  â–¼
  â”‚                          Celery Worker(s)
  â”‚                                  â”‚
  â”‚                          call services/data_ingestion
  â”‚                                  â”‚
  â”‚                          repositories â†’ Postgres
  â”‚                                  â”‚
  â”‚                  NOTIFY / update job status
  â–¼
Frontend SSE endpoint â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
(listens for Postgres notifications)
```

**Benefits:**

- API never blocks, only enqueues
- Workers handle retries, concurrency, scaling
- Job status in Postgres = source of truth
- Frontend updates in near-real-time via SSE

---

ğŸ’¡ **Mental model:**

```
API = I/O & enqueue
Tasks = orchestration
Services = business logic
Repositories = DB access
DB = state + event source
```

This gives you a **clear separation of responsibilities**.

```ascii
#
#        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
#        â”‚   Frontend    â”‚
#        â”‚  (React / JS) â”‚
#        â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
#                â”‚
#                â–¼
#        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
#        â”‚   FastAPI     â”‚
#        â”‚   API Router  â”‚
#        â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
#                â”‚
#                â”‚ create job in DB
#                â”‚ enqueue Celery task
#                â–¼
#        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
#        â”‚   Redis       â”‚  <-- Celery Broker
#        â”‚   (Queue)     â”‚
#        â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
#                â”‚
#                â–¼
#        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
#        â”‚  Celery Worker â”‚
#        â”‚ (Python app)  â”‚
#        â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
#                â”‚
#                â”‚ calls
#                â–¼
#    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
#    â”‚ services/data_ingestion â”‚
#    â”‚  (process job based on  â”‚
#    â”‚   entity_type / meta)   â”‚
#    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
#            â”‚
#            â–¼
#        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
#        â”‚   Postgres    â”‚  <-- DataIngestionJob table + results
#        â”‚  (job status) â”‚
#        â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
#                â”‚
#        NOTIFY / LISTEN
#                â”‚
#                â–¼
#        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
#        â”‚   Frontend    â”‚
#        â”‚  (SSE / Live) â”‚
#        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```
