{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"EPFL Project Technical Documentation","text":"<p>Welcome to the technical documentation for the project n\u00ba200. This documentation is organized into five main sections, each covering a specific aspect of the system.</p>"},{"location":"#documentation-sections","title":"Documentation Sections","text":""},{"location":"#architecture","title":"Architecture","text":"<p>High-level system design, technology choices, and cross-cutting concerns:</p> <ul> <li>System overview and component interactions</li> <li>Security model and authentication flow</li> <li>CI/CD pipeline and environment topology</li> <li>Tech stack rationale</li> </ul>"},{"location":"#frontend","title":"Frontend","text":"<p>User interface layer implementation details.</p> <ul> <li>Frontend architecture and technologies</li> <li>UI component system and design patterns</li> <li>API integration and data management</li> <li>Development workflows and testing</li> </ul>"},{"location":"#backend","title":"Backend","text":"<p>Business logic and API layer implementation details.</p> <ul> <li>Backend architecture and module structure</li> <li>API design and contracts</li> <li>Plugin system and extension mechanisms</li> <li>Testing strategies and deployment</li> </ul>"},{"location":"#database","title":"Database","text":"<p>Data persistence layer implementation details.</p> <ul> <li>Database schema and entity relationships</li> <li>Data flows and ownership models</li> <li>Migration processes and versioning</li> <li>Backup and maintenance procedures</li> </ul>"},{"location":"#infrastructure","title":"Infrastructure","text":"<p>Hosting and operational infrastructure.</p> <ul> <li>Hosting environment and networking</li> <li>Monitoring and logging systems</li> <li>Deployment and scaling strategies</li> </ul>"},{"location":"#getting-started","title":"Getting Started","text":"<p>To get started with the project, we recommend:</p> <ol> <li>Read the Architecture Overview to understand the big picture</li> <li>Explore the specific section relevant to your area of interest</li> <li>Check the development guides in each section for implementation details</li> </ol>"},{"location":"#contributing","title":"Contributing","text":"<p>This documentation is a living document that evolves with the project. If you find any inaccuracies or have suggestions for improvement, please submit a pull request or open an issue in the repository.</p>"},{"location":"#additional-resources","title":"Additional Resources","text":"<ul> <li>Repository</li> <li>Issue Tracker</li> </ul>"},{"location":"architecture/","title":"System Architecture Overview","text":"<p>This documentation has been restructured into smaller, more manageable files. Please see the table of contents below for specific topics.</p>"},{"location":"architecture/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Purpose &amp; Scope</li> <li>System Overview Diagram</li> <li>Subsystem Map</li> <li>Auth Flow Across Layers</li> <li>Environments</li> <li>CI/CD Pipeline Overview</li> <li>Global Conventions</li> <li>Tech Stack Rationale</li> <li>Component Breakdown</li> <li>Data Flow Diagram</li> <li>Deployment Topology</li> <li>Scalability &amp; Statelessness Strategy</li> <li>Cross-Cutting Concerns</li> <li>Architectural Decisions</li> <li>Appendices</li> </ol> <p>For implementation details of specific components, see:</p> <ul> <li>Frontend Documentation</li> <li>Backend Documentation</li> <li>Database Documentation</li> </ul>"},{"location":"architecture/01-purpose-scope/","title":"Purpose &amp; Scope","text":"<p>This document provides a comprehensive overview of the system architecture for project n\u00ba200. It describes the high-level design, component interactions, and key architectural decisions that shape the system.</p>"},{"location":"architecture/01-purpose-scope/#intended-audience","title":"Intended Audience","text":"<p>This documentation is intended for:</p> <ul> <li>System architects and designers</li> <li>Developers working on the project</li> <li>Technical stakeholders and product managers</li> <li>Operations and DevOps engineers</li> <li>New team members onboarding to the project</li> </ul>"},{"location":"architecture/01-purpose-scope/#goals-non-goals","title":"Goals &amp; Non-goals","text":"<p>Goals:</p> <ul> <li>Provide a clear understanding of the system's structure and components</li> <li>Explain how different parts of the system interact</li> <li>Document key architectural decisions and their rationales</li> <li>Serve as a reference for future development and maintenance</li> <li>Guide discussions about system evolution and scalability</li> </ul> <p>Non-goals:</p> <ul> <li>Provide implementation details (see component-specific documentation)</li> <li>Serve as a tutorial for using specific technologies</li> <li>Document every possible configuration option</li> <li>Replace detailed technical specifications in other sections</li> </ul>"},{"location":"architecture/02-system-overview/","title":"System Overview Diagram","text":"<ul> <li>Interaction component Basic</li> </ul> <pre><code>graph TB\n    User([User/Browser])\n    LB[EPFL Load Balancer]\n\n    subgraph K8S[\"Kubernetes Cluster (XaaS Platform)\"]\n        Ingress[Ingress Controller]\n\n        subgraph Routes[\"Route Definitions\"]\n            Root[\"/ \u2192 SPA\"]\n            API[\"/api \u2192 Backend\"]\n            Docs[\"/docs \u2192 API Docs\"]\n            ITMgr[\"/it-manager \u2192 IT UI\"]\n            TeamMgr[\"/team-manager \u2192 Team UI\"]\n        end\n\n        Frontend[Frontend Pods&lt;br/&gt;Vue 3 Applications]\n        Backend[Backend Pods&lt;br/&gt;FastAPI Services]\n        Workers[Worker Pods&lt;br/&gt;Celery + Redis]\n        Database[Database Layer&lt;br/&gt;PostgreSQL + PgBouncer]\n    end\n\n    subgraph External[\"External Services\"]\n        Auth[Microsoft Entra ID&lt;br/&gt;OAuth2/OIDC]\n        S3[EPFL S3 Storage]\n    end\n\n    User --&gt;|HTTPS| LB\n    LB --&gt; Ingress\n    Ingress --&gt; Routes\n    Routes --&gt; Frontend\n    Routes --&gt; Backend\n\n    Frontend --&gt;|API Calls| Backend\n    Backend &lt;--&gt;|Authentication| Auth\n    Backend --&gt;|Read/Write| Database\n    Backend --&gt;|Enqueue Tasks| Workers\n    Backend &lt;--&gt;|Files| S3\n\n    Workers --&gt;|Read/Write| Database\n    Workers &lt;--&gt;|Files| S3\n\n    classDef external fill:#ffebee,stroke:#c62828,stroke-width:2px\n    classDef ingress fill:#e8eaf6,stroke:#3949ab,stroke-width:2px\n    classDef route fill:#fff9c4,stroke:#f57f17,stroke-width:2px\n    classDef frontend fill:#e1f5ff,stroke:#01579b,stroke-width:2px\n    classDef backend fill:#fff3e0,stroke:#e65100,stroke-width:2px\n    classDef workers fill:#f3e5f5,stroke:#4a148c,stroke-width:2px\n    classDef database fill:#e8f5e9,stroke:#1b5e20,stroke-width:2px\n\n    class User,LB external\n    class Ingress ingress\n    class Root,API,Docs,ITMgr,TeamMgr route\n    class Frontend frontend\n    class Backend backend\n    class Workers workers\n    class Database database\n    class Auth,S3 external</code></pre> <ul> <li>Interaction component detailed</li> </ul> <pre><code>graph TB\n    User([User/Browser])\n    LB[EPFL Load Balancer]\n\n    subgraph K8S[\"Kubernetes Cluster (XaaS Platform)\"]\n        Ingress[Ingress Controller]\n\n        subgraph Routes[\"Ingress Definitions\"]\n            Root[\"/ - SPA Frontend\"]\n            API[\"/api - Backend REST\"]\n            Docs[\"/docs - Public API Docs\"]\n            ITMgr[\"/it-manager - IT Interface\"]\n            TeamMgr[\"/team-manager - Team Interface\"]\n        end\n\n        subgraph Frontend[\"Frontend Pods\"]\n            SPA[Vue 3 SPA]\n            ITApp[IT Manager App]\n            TeamApp[Team Manager App]\n        end\n\n        subgraph AppLayer[\"Application Layer\"]\n            subgraph Backend[\"Backend Pods\"]\n                FastAPI1[FastAPI Pod 1]\n                FastAPI2[FastAPI Pod 2]\n                APIAuth[Auth Middleware]\n            end\n\n            subgraph Workers[\"Worker Pods\"]\n                Redis[Redis Queue]\n                Celery1[Celery Worker 1]\n                Celery2[Celery Worker 2]\n            end\n        end\n\n        subgraph DatabaseLayer[\"Database Layer\"]\n            subgraph Pooling[\"Connection Pooling\"]\n                PGBouncer1[PgBouncer Primary]\n                PGBouncer2[PgBouncer Secondary]\n            end\n\n            subgraph PostgreSQL[\"PostgreSQL Cluster\"]\n                Primary[(PostgreSQL Primary&lt;br/&gt;Read/Write)]\n                Replica1[(PostgreSQL Replica 1&lt;br/&gt;Read Only)]\n                Replica2[(PostgreSQL Replica 2&lt;br/&gt;Read Only)]\n            end\n        end\n\n        subgraph Config[\"Config &amp; Secrets\"]\n            DBCreds[DB Credentials]\n            ConfigMaps[ConfigMaps]\n        end\n\n        subgraph Monitoring[\"Monitoring &amp; Observability\"]\n            Prometheus[Prometheus]\n            Grafana[Grafana]\n        end\n    end\n\n    subgraph External[\"External Services\"]\n        EntraID[Microsoft Entra ID&lt;br/&gt;OAuth2/OpenID Connect]\n        S3[EPFL S3 Storage&lt;br/&gt;Object Storage]\n    end\n\n    User --&gt;|HTTPS| LB\n    LB --&gt;|Route Traffic| Ingress\n\n    Ingress --&gt;|/* catch-all| Root\n    Ingress --&gt;|/api/*| API\n    Ingress --&gt;|/docs| Docs\n    Ingress --&gt;|/it-manager/*| ITMgr\n    Ingress --&gt;|/team-manager/*| TeamMgr\n\n    Root --&gt;|Serve| SPA\n    ITMgr --&gt;|Serve| ITApp\n    TeamMgr --&gt;|Serve| TeamApp\n\n    API --&gt;|Forward| FastAPI1\n    API --&gt;|Forward| FastAPI2\n    Docs --&gt;|Swagger UI| FastAPI1\n\n    SPA --&gt;|API Calls| FastAPI1\n    ITApp --&gt;|API Calls| FastAPI1\n    TeamApp --&gt;|API Calls| FastAPI2\n\n    FastAPI1 --&gt;|Authenticate| APIAuth\n    FastAPI2 --&gt;|Authenticate| APIAuth\n    APIAuth &lt;--&gt;|OAuth2/OIDC| EntraID\n\n    FastAPI1 --&gt;|Enqueue Jobs| Redis\n    FastAPI2 --&gt;|Enqueue Jobs| Redis\n\n    FastAPI1 --&gt;|Read/Write Queries| PGBouncer1\n    FastAPI2 --&gt;|Read/Write Queries| PGBouncer1\n\n    Redis --&gt;|Distribute| Celery1\n    Redis --&gt;|Distribute| Celery2\n\n    Celery1 --&gt;|Read/Write Queries| PGBouncer2\n    Celery2 --&gt;|Read/Write Queries| PGBouncer2\n\n    FastAPI1 &lt;--&gt;|Store/Retrieve Files| S3\n    FastAPI2 &lt;--&gt;|Store/Retrieve Files| S3\n    Celery1 &lt;--&gt;|Read/Write Files| S3\n    Celery2 &lt;--&gt;|Read/Write Files| S3\n\n    PGBouncer1 --&gt;|Writes| Primary\n    PGBouncer1 --&gt;|Reads| Replica1\n    PGBouncer1 --&gt;|Reads| Replica2\n\n    PGBouncer2 --&gt;|Writes| Primary\n    PGBouncer2 --&gt;|Reads| Replica1\n    PGBouncer2 --&gt;|Reads| Replica2\n\n    Primary -.-&gt;|Replication| Replica1\n    Primary -.-&gt;|Replication| Replica2\n\n    DBCreds --&gt; FastAPI1\n    DBCreds --&gt; FastAPI2\n    DBCreds --&gt; Celery1\n    DBCreds --&gt; Celery2\n    DBCreds --&gt; PGBouncer1\n    DBCreds --&gt; PGBouncer2\n\n    ConfigMaps --&gt; FastAPI1\n    ConfigMaps --&gt; FastAPI2\n\n    Prometheus --&gt; FastAPI1\n    Prometheus --&gt; FastAPI2\n    Prometheus --&gt; PGBouncer1\n    Prometheus --&gt; PGBouncer2\n    Grafana --&gt; Prometheus\n\n    classDef external fill:#ffebee,stroke:#c62828,stroke-width:2px\n    classDef ingress fill:#e8eaf6,stroke:#3949ab,stroke-width:2px\n    classDef frontend fill:#e1f5ff,stroke:#01579b,stroke-width:2px\n    classDef backend fill:#fff3e0,stroke:#e65100,stroke-width:2px\n    classDef workers fill:#f3e5f5,stroke:#4a148c,stroke-width:2px\n    classDef database fill:#e8f5e9,stroke:#1b5e20,stroke-width:2px\n    classDef config fill:#fce4ec,stroke:#880e4f,stroke-width:2px\n    classDef route fill:#fff9c4,stroke:#f57f17,stroke-width:2px\n\n    class User,LB external\n    class Ingress ingress\n    class Root,API,Docs,ITMgr,TeamMgr route\n    class SPA,ITApp,TeamApp frontend\n    class FastAPI1,FastAPI2,APIAuth backend\n    class Redis,Celery1,Celery2 workers\n    class PGBouncer1,PGBouncer2,Primary,Replica1,Replica2 database\n    class DBCreds,ConfigMaps,Prometheus,Grafana config\n    class EntraID,S3 external</code></pre> <ul> <li>Interaction component less detailed</li> </ul> <pre><code>graph TB\n    Frontend[\"Frontend Layer&lt;br/&gt;Vue 3 + Quasar\"]\n    Backend[\"Backend Layer&lt;br/&gt;FastAPI\"]\n    Workers[\"Workers Layer&lt;br/&gt;Celery + Redis\"]\n    Database[\"Database Layer&lt;br/&gt;PostgreSQL\"]\n    Storage[\"Storage Layer&lt;br/&gt;EPFL S3\"]\n    Infra[\"Infrastructure Layer&lt;br/&gt;Kubernetes on XaaS\"]\n\n    Frontend &lt;--&gt;|REST API| Backend\n    Backend &lt;--&gt;|Enqueue Tasks| Workers\n    Backend &lt;--&gt;|Read/Write| Database\n    Backend &lt;--&gt;|Upload/Download| Storage\n    Workers --&gt;|Read/Write Files| Storage\n    Workers --&gt;|Store Results| Database\n    Infra -.-&gt;|Hosts| Frontend\n    Infra -.-&gt;|Hosts| Backend\n    Infra -.-&gt;|Hosts| Workers\n    Infra -.-&gt;|Manages| Database\n    Infra -.-&gt;|Manages| Storage\n\n    classDef frontend fill:#e1f5ff,stroke:#01579b,stroke-width:2px\n    classDef backend fill:#fff3e0,stroke:#e65100,stroke-width:2px\n    classDef workers fill:#f3e5f5,stroke:#4a148c,stroke-width:2px\n    classDef database fill:#e8f5e9,stroke:#1b5e20,stroke-width:2px\n    classDef storage fill:#fff9c4,stroke:#f57f17,stroke-width:2px\n    classDef infra fill:#fce4ec,stroke:#880e4f,stroke-width:2px\n\n    class Frontend frontend\n    class Backend backend\n    class Workers workers\n    class Database database\n    class Storage storage\n    class Infra infra</code></pre> <ul> <li>Overview of database query system</li> </ul> <pre><code>flowchart TD\n    subgraph K8s Cluster\n        A[FastAPI Pods] --&gt;|Read/Write Queries| B[PgBouncer Primary/Secondary]\n        B --&gt;|Writes| C[(PostgreSQL Primary)]\n        B --&gt;|Reads| D[(PostgreSQL Replica 1)]\n        B --&gt;|Reads| E[(PostgreSQL Replica 2)]\n    end\n\n    subgraph Config &amp; Secrets\n        F[DB Credentials &amp; ConfigMaps] --&gt; A\n        F --&gt; B\n    end\n\n    subgraph Monitoring &amp; Observability\n        G[Prometheus / Grafana] --&gt; A\n        G --&gt; B\n    end</code></pre> <ul> <li>Dataflow</li> </ul> <pre><code>graph TB\n    User([User])\n    FE[Frontend]\n    BE[Backend API]\n    Queue[Redis Queue]\n    Worker[Celery Workers]\n    Process[Process]\n    DB[(PostgreSQL)]\n    S3[(S3 Storage)]\n\n    User --&gt;|1. Upload File| FE\n    FE --&gt;|2. POST Request| BE\n    BE --&gt;|3. Store File| S3\n    BE --&gt;|4. Create Task| Queue\n    BE --&gt;|5. Save Metadata| DB\n    Queue --&gt;|6. Dispatch| Worker\n    Worker --&gt;|7. Fetch File| S3\n    Worker --&gt;|8. Process| Process\n    Process --&gt;|8.a result |Worker\n    Worker --&gt;|9. Store Results| DB\n    Worker --&gt;|10. Save Output| S3\n    BE --&gt;|11. Response| FE\n    FE --&gt;|12. Display| User\n\n    classDef userStyle fill:#e0e0e0,stroke:#424242,stroke-width:2px\n    classDef frontendStyle fill:#e1f5ff,stroke:#01579b,stroke-width:2px\n    classDef backendStyle fill:#fff3e0,stroke:#e65100,stroke-width:2px\n    classDef workerStyle fill:#f3e5f5,stroke:#4a148c,stroke-width:2px\n    classDef dataStyle fill:#e8f5e9,stroke:#1b5e20,stroke-width:2px\n    classDef storageStyle fill:#fff9c4,stroke:#f57f17,stroke-width:2px\n    classDef ProcessStyle fill:#ffeeff,stroke:#f13f4a,stroke-width:2px\n\n    class User userStyle\n    class FE frontendStyle\n    class BE backendStyle\n    class Queue,Worker workerStyle\n    class DB dataStyle\n    class S3 storageStyle\n    class Process ProcessStyle</code></pre> <p>The system consists of several interconnected layers that work together to provide the complete functionality. The diagram above shows the high-level components and their interactions.</p>"},{"location":"architecture/02-system-overview/#high-level-components","title":"High-Level Components","text":"<ol> <li>Frontend Layer - User interface implemented with Vue 3 and Quasar</li> <li>Backend Layer - RESTful API implemented with FastAPI</li> <li>Workers Layer - Asynchronous processing with Celery and Redis</li> <li>Database Layer - Data persistence with PostgreSQL</li> <li>Storage Layer - Object storage for file uploads</li> <li>Infrastructure Layer - Hosting and operational components</li> </ol> <p>For detailed information about each component, see the Component Breakdown section below and the specific documentation in the corresponding folders under <code>docs/</code>.</p>"},{"location":"architecture/03-subsystem-map/","title":"Subsystem Map","text":"<ul> <li>Basic communication between component</li> </ul> <pre><code>graph TD\n    %% Layers\n    FE[Frontend]\n    BE[Backend]\n    WK[Workers]\n    DB[Database]\n    ST[Storage]\n\n    %% Main Flow\n    FE --&gt;|HTTP REST API| BE\n    BE --&gt;|Message Queue| WK\n    BE --&gt;|SQLAlchemy ORM| DB\n    BE --&gt;|API Calls| ST\n    WK --&gt;|Optional DB Access| DB\n    WK --&gt;|Optional Storage Access| ST\n\n    %% Bidirectional Arrows\n    FE &lt;--&gt; BE\n    BE &lt;--&gt; WK</code></pre> <ul> <li>Detailed mermaid graph</li> </ul> <pre><code>graph TD\n    %% External / Load Balancer\n    LB[Load Balancer]\n    User[User]\n    EntraID[EntraID]\n    S3[S3]\n\n    %% Ingress\n    Ingress[Ingress]\n\n    %% Routes\n    Root[Root]\n    API[API]\n    Docs[Docs]\n    ITMgr[IT Manager Route]\n    TeamMgr[Team Manager Route]\n\n    %% Frontend Apps\n    SPA[SPA Frontend]\n    ITApp[IT App Frontend]\n    TeamApp[Team App Frontend]\n\n    %% Backend\n    FastAPI1[FastAPI1]\n    FastAPI2[FastAPI2]\n    APIAuth[API Auth]\n\n    %% Workers\n    Redis[Redis]\n    Celery1[Celery1]\n    Celery2[Celery2]\n\n    %% Database\n    PGBouncer1[PGBouncer1]\n    PGBouncer2[PGBouncer2]\n    Primary[Primary DB]\n    Replica1[Replica1 DB]\n    Replica2[Replica2 DB]\n\n    %% Config / Monitoring\n    DBCreds[DB Credentials]\n    ConfigMaps[Config Maps]\n    Prometheus[Prometheus]\n    Grafana[Grafana]\n\n    %% --- Connections ---\n    %% Users flow\n    User --&gt;|HTTP / HTTPS| LB\n    LB --&gt; Ingress\n    Ingress --&gt; Root\n    Ingress --&gt; API\n    Ingress --&gt; Docs\n    Ingress --&gt; ITMgr\n    Ingress --&gt; TeamMgr\n\n    %% Routes to frontends\n    Root --&gt; SPA\n    ITMgr --&gt; ITApp\n    TeamMgr --&gt; TeamApp\n    API --&gt; FastAPI1\n    API --&gt; FastAPI2\n    API --&gt; APIAuth\n\n    %% Backend to workers\n    FastAPI1 --&gt; Celery1\n    FastAPI2 --&gt; Celery2\n    APIAuth --&gt; Redis\n    FastAPI1 --&gt; Redis\n    FastAPI2 --&gt; Redis\n\n    %% Backend to Database via PGBouncer\n    FastAPI1 --&gt; PGBouncer1\n    FastAPI2 --&gt; PGBouncer2\n    APIAuth --&gt; PGBouncer1\n    PGBouncer1 --&gt; Primary\n    PGBouncer1 --&gt; Replica1\n    PGBouncer2 --&gt; Primary\n    PGBouncer2 --&gt; Replica2\n\n    %% Workers optional DB/Storage access\n    Celery1 --&gt; Primary\n    Celery2 --&gt; Replica2\n    Celery1 --&gt; S3\n    Celery2 --&gt; S3\n\n    %% Config &amp; Monitoring\n    FastAPI1 --&gt; ConfigMaps\n    FastAPI2 --&gt; ConfigMaps\n    APIAuth --&gt; DBCreds\n    Prometheus --&gt; FastAPI1\n    Prometheus --&gt; FastAPI2\n    Prometheus --&gt; Celery1\n    Prometheus --&gt; Celery2\n    Grafana --&gt; Prometheus\n\n    %% External Identity &amp; Storage\n    SPA --&gt; EntraID\n    ITApp --&gt; EntraID\n    TeamApp --&gt; EntraID\n</code></pre> <p>The system follows a layered architecture pattern with clear separation of concerns between different subsystems.</p>"},{"location":"architecture/03-subsystem-map/#layer-dependencies","title":"Layer Dependencies","text":"<pre><code>Frontend \u2194 Backend \u2194 Workers \u2194 DB\n                \u2195\n            Storage\n</code></pre> <p>Each layer communicates with adjacent layers through well-defined interfaces:</p> <ul> <li>Frontend communicates with Backend via HTTP REST APIs</li> <li>Backend communicates with Workers via message queues</li> <li>Backend communicates with Database via SQLAlchemy ORM</li> <li>Backend communicates with Storage via direct API calls</li> <li>Workers may communicate with Database and Storage as needed</li> </ul> <p>For implementation details, see:</p> <ul> <li>Frontend Documentation</li> <li>Backend Documentation</li> <li>Database Documentation</li> <li>Storage Documentation</li> </ul>"},{"location":"architecture/04-auth-flow/","title":"Auth Flow Across Layers","text":"<ul> <li>Sequence diagram showing login --&gt; token usage</li> </ul> <pre><code>sequenceDiagram\n    autonumber\n    participant User\n    participant SPA as Frontend SPA\n    participant API as Backend API\n    participant Entra as Microsoft Entra ID\n    participant DB as Database / Storage\n\n    %% Login Flow\n    User-&gt;&gt;SPA: Navigate to login page\n    SPA-&gt;&gt;Entra: Redirect user for OIDC login\n    Entra--&gt;&gt;User: Prompt for credentials\n    User-&gt;&gt;Entra: Submit credentials\n    Entra--&gt;&gt;SPA: Return ID Token + Access Token\n\n    %% Cookie Handling\n    SPA-&gt;&gt;API: Send login request with Access Token\n    API--&gt;&gt;SPA: Set HTTP-only cookie with session token\n    SPA--&gt;&gt;User: Login successful\n\n    %% API Requests\n    User-&gt;&gt;SPA: Interact with app\n    SPA-&gt;&gt;API: Send request with cookie (Access Token stored in backend session)\n    API-&gt;&gt;API: Validate token, extract roles/claims\n    API-&gt;&gt;DB: Access data based on roles/permissions\n    DB--&gt;&gt;API: Return data\n    API--&gt;&gt;SPA: Return response\n    SPA--&gt;&gt;User: Render data\n\n    %% Optional Refresh\n    Note over SPA, API: Stateless backend, token refresh handled via cookie/session renewal</code></pre> <p>The authentication and authorization system spans multiple layers of the application, ensuring secure access to resources.</p>"},{"location":"architecture/04-auth-flow/#user-authentication-authorization-model","title":"User Authentication &amp; Authorization Model","text":"<p>The system implements a centralized authentication model using Microsoft Entra ID (formerly Azure AD) as the identity provider. All authentication requests are handled through OpenID Connect (OIDC) protocol.</p>"},{"location":"architecture/04-auth-flow/#token-propagation-strategy","title":"Token Propagation Strategy","text":"<p>The system uses JWT tokens for stateless authentication:</p> <ul> <li>ID Tokens for user identification</li> <li>Access Tokens for API authorization</li> <li>Refresh Tokens for session continuity (optional)</li> </ul> <p>Tokens are propagated through the system as HTTP headers, with each layer validating token authenticity and extracting user claims as needed.</p>"},{"location":"architecture/04-auth-flow/#role-based-access-control-rbac-implementation","title":"Role-Based Access Control (RBAC) Implementation","text":"<p>Access control is implemented using role-based permissions:</p> <ul> <li>Roles are defined in Microsoft Entra ID</li> <li>Permissions are mapped to API endpoints and resources</li> <li>Authorization is enforced at both the API gateway and individual service levels</li> </ul> <p>For detailed implementation information, see:</p> <ul> <li>Backend Security Documentation</li> <li>Frontend Auth Documentation</li> </ul>"},{"location":"architecture/05-environments/","title":"Environments","text":"<p>The system is deployed across multiple environments with different configurations and purposes.</p>"},{"location":"architecture/05-environments/#dev-stage-prod-topology","title":"Dev / Stage / Prod Topology","text":"Environment Purpose Key Characteristics Local Individual development Docker Compose, minimal services Development Team collaboration Shared services, frequent updates Staging Pre-production testing Production-like configuration Production Live user traffic High availability, monitoring"},{"location":"architecture/05-environments/#local-setup-instructions","title":"Local Setup Instructions","text":"<p>For local development, the system can be run using Docker Compose. See the Development Guide for detailed setup instructions.</p> <p>![TO COMPLETE TAG: Describe environment-specific configurations/secrets]</p> <p>Environment-specific configurations are managed through:</p> <ul> <li>Environment variables for runtime settings</li> <li>Kubernetes secrets for sensitive information in cloud environments</li> <li>Local .env files for development</li> </ul> <p>For detailed infrastructure information, see Infrastructure Documentation.</p>"},{"location":"architecture/06-cicd-pipeline/","title":"CI/CD Pipeline Overview","text":"<p>![TO COMPLETE TAG: Include pipeline architecture diagram]</p> <p>The continuous integration and deployment pipeline automates the build, test, and deployment processes across all environments.</p>"},{"location":"architecture/06-cicd-pipeline/#build-process-per-subsystem","title":"Build Process per Subsystem","text":"<p>Each subsystem has its own build process:</p> <ul> <li>Frontend: Node.js build with webpack</li> <li>Backend: Python package with dependencies</li> <li>Infrastructure: Terraform plans and Kubernetes manifests</li> </ul>"},{"location":"architecture/06-cicd-pipeline/#deployment-automation-flow","title":"Deployment Automation Flow","text":"<p>Deployments are fully automated through GitHub Actions:</p> <ol> <li>Code changes trigger CI pipeline</li> <li>Tests are run in isolated environments</li> <li>Artifacts are built and stored in registry</li> <li>ArgoCD handles deployment to Kubernetes clusters</li> </ol>"},{"location":"architecture/06-cicd-pipeline/#testing-integration-points","title":"Testing Integration Points","text":"<p>Automated testing includes:</p> <ul> <li>Unit tests for individual components</li> <li>Integration tests for subsystem interactions</li> <li>End-to-end tests for critical user flows</li> <li>Security scans and vulnerability assessments</li> </ul>"},{"location":"architecture/06-cicd-pipeline/#rollback-mechanisms","title":"Rollback Mechanisms","text":"<p>Rollbacks are supported through:</p> <ul> <li>Blue-green deployment strategy</li> <li>Kubernetes deployment history</li> <li>Database migration versioning</li> </ul>"},{"location":"architecture/07-global-conventions/","title":"Global Conventions","text":"<p>The system follows consistent conventions across all components to ensure maintainability and developer productivity.</p>"},{"location":"architecture/07-global-conventions/#naming-standards","title":"Naming Standards","text":"<ul> <li>Services: lowercase with hyphens (e.g., <code>user-service</code>)</li> <li>APIs: RESTful with plural nouns (e.g., <code>/api/v1/users</code>)</li> <li>Variables: snake_case for Python, camelCase for JavaScript</li> <li>Database tables: plural snake_case (e.g., <code>user_profiles</code>)</li> </ul>"},{"location":"architecture/07-global-conventions/#logging-monitoring-practices","title":"Logging &amp; Monitoring Practices","text":"<p>All components implement structured logging:</p> <ul> <li>JSON format for machine parsing</li> <li>Consistent log levels (DEBUG, INFO, WARNING, ERROR)</li> <li>Correlation IDs for request tracing</li> <li>Performance metrics exposure</li> </ul>"},{"location":"architecture/07-global-conventions/#secret-management-policy","title":"Secret Management Policy","text":"<p>Secrets are managed through:</p> <ul> <li>Environment variables for runtime configuration</li> <li>Kubernetes secrets for containerized deployments</li> <li>Azure Key Vault for production secrets</li> <li>Never committed to source control</li> </ul>"},{"location":"architecture/07-global-conventions/#error-handling-patterns","title":"Error Handling Patterns","text":"<p>Error handling follows consistent patterns:</p> <ul> <li>Standardized error response format</li> <li>Proper HTTP status codes</li> <li>Detailed error messages in development</li> <li>Generic messages in production</li> </ul> <p>![TO COMPLETE TAG: Link to style guide/convention docs if any]</p> <p>For detailed conventions, see the individual component documentation.</p>"},{"location":"architecture/08-tech-stack/","title":"Tech Stack Rationale","text":"<p>The technology stack was chosen based on team expertise, project requirements, and long-term maintainability considerations.</p>"},{"location":"architecture/08-tech-stack/#why-vuejs-for-frontend","title":"Why Vue.js for Frontend?","text":"<p>Selected for:</p> <ul> <li>Reactive data binding and component-based architecture</li> <li>Rich ecosystem and community support</li> <li>Good performance with Quasar UI framework</li> <li>Team familiarity and productivity</li> </ul>"},{"location":"architecture/08-tech-stack/#why-fastapi-for-backend","title":"Why FastAPI for Backend?","text":"<p>Selected for:</p> <ul> <li>Modern Python async capabilities</li> <li>Automatic OpenAPI documentation generation</li> <li>Type hints and validation with Pydantic</li> <li>High performance with minimal boilerplate</li> </ul>"},{"location":"architecture/08-tech-stack/#why-postgresql-for-database","title":"Why PostgreSQL for Database?","text":"<p>Selected for:</p> <ul> <li>Strong consistency and ACID compliance</li> <li>Advanced data types and indexing options</li> <li>Mature ecosystem and tooling</li> <li>Team experience and preference</li> </ul>"},{"location":"architecture/08-tech-stack/#why-rediscelery-for-background-jobs","title":"Why Redis/Celery for Background Jobs?","text":"<p>Selected for:</p> <ul> <li>Simple deployment and operation</li> <li>Reliable task queuing mechanism</li> <li>Good integration with Python ecosystem</li> <li>Support for distributed task processing</li> </ul>"},{"location":"architecture/08-tech-stack/#alternatives-considered-summary","title":"Alternatives Considered Summary","text":"<p>Several alternatives were evaluated:</p> <ul> <li>Frontend: React vs Vue - Chosen Vue for team familiarity</li> <li>Backend: Django vs FastAPI - Chosen FastAPI for async capabilities</li> <li>Database: MySQL vs PostgreSQL - Chosen PostgreSQL for advanced features</li> <li>Workers: RQ vs Celery - Chosen Celery for robustness</li> </ul> <p>![TO COMPLETE TAG: Reference specific ADR files where applicable]</p> <p>For detailed architectural decisions, see Architecture Decision Records.</p>"},{"location":"architecture/09-component-breakdown/","title":"Component Breakdown (High-Level View)","text":""},{"location":"architecture/09-component-breakdown/#frontend-layer","title":"Frontend Layer","text":""},{"location":"architecture/09-component-breakdown/#architecture-pattern","title":"Architecture Pattern","text":"<p>Single Page Application (SPA) with client-side routing</p>"},{"location":"architecture/09-component-breakdown/#main-technologies","title":"Main Technologies","text":"<ul> <li>Vue 3 Composition API</li> <li>Quasar Framework for UI components</li> <li>Pinia for state management</li> <li>Axios for HTTP requests</li> </ul>"},{"location":"architecture/09-component-breakdown/#api-interface-style","title":"API Interface Style","text":"<p>RESTful HTTP APIs with JSON payloads, following OpenAPI specification</p>"},{"location":"architecture/09-component-breakdown/#how-it-connects-to-backend","title":"How It Connects to Backend","text":"<ul> <li>HTTP GET/POST/PUT/DELETE requests</li> <li>Authentication headers with JWT tokens</li> <li>Error handling with standardized responses</li> </ul>"},{"location":"architecture/09-component-breakdown/#behavior-as-subsystem","title":"Behavior as Subsystem","text":"<ul> <li>Client-side routing with Vue Router</li> <li>Centralized state management with Pinia</li> <li>Responsive UI with Quasar components</li> </ul> <p>For detailed frontend information, see Frontend Documentation.</p>"},{"location":"architecture/09-component-breakdown/#backend-layer","title":"Backend Layer","text":""},{"location":"architecture/09-component-breakdown/#architecture-pattern_1","title":"Architecture Pattern","text":"<p>RESTful API microservice architecture</p>"},{"location":"architecture/09-component-breakdown/#main-technologies_1","title":"Main Technologies","text":"<ul> <li>FastAPI for API implementation</li> <li>Pydantic for data validation</li> <li>SQLAlchemy for ORM</li> <li>Uvicorn for ASGI server</li> </ul>"},{"location":"architecture/09-component-breakdown/#api-interface","title":"API Interface","text":"<ul> <li>RESTful endpoints with JSON request/response formats</li> <li>Automatic OpenAPI documentation at <code>/docs</code></li> <li>Standardized error responses</li> </ul>"},{"location":"architecture/09-component-breakdown/#how-it-connects-to-other-layers","title":"How It Connects to Other Layers","text":"<ul> <li>Database via SQLAlchemy ORM</li> <li>Workers via Redis message queue</li> <li>Frontend via HTTP REST APIs</li> <li>Storage via direct API calls</li> </ul>"},{"location":"architecture/09-component-breakdown/#behavior-as-subsystem_1","title":"Behavior as Subsystem","text":"<ul> <li>Request handling and validation</li> <li>Business logic orchestration</li> <li>Data transformation and aggregation</li> </ul> <p>For detailed backend information, see Backend Documentation.</p>"},{"location":"architecture/09-component-breakdown/#workers-async-processing-layer","title":"Workers / Async Processing Layer","text":""},{"location":"architecture/09-component-breakdown/#architecture-pattern_2","title":"Architecture Pattern","text":"<p>Task queue with event-driven processing</p>"},{"location":"architecture/09-component-breakdown/#main-technologies_2","title":"Main Technologies","text":"<ul> <li>Celery for distributed task queue</li> <li>Redis as message broker</li> <li>Custom task definitions in Python</li> </ul>"},{"location":"architecture/09-component-breakdown/#how-tasks-are-triggered-and-handled","title":"How Tasks Are Triggered and Handled","text":"<ul> <li>Tasks enqueued via Redis broker</li> <li>Workers consume tasks asynchronously</li> <li>Results stored in Redis or database</li> </ul>"},{"location":"architecture/09-component-breakdown/#behavior-as-subsystem_2","title":"Behavior as Subsystem","text":"<ul> <li>Background job execution</li> <li>Retry logic with exponential backoff</li> <li>Task monitoring and management</li> </ul> <p>For detailed worker information, see Backend Plugins Documentation.</p>"},{"location":"architecture/09-component-breakdown/#database-layer","title":"Database Layer","text":""},{"location":"architecture/09-component-breakdown/#type-and-purpose","title":"Type and Purpose","text":"<p>PostgreSQL relational database for structured data persistence</p>"},{"location":"architecture/09-component-breakdown/#connection-method","title":"Connection Method","text":"<p>SQLAlchemy ORM with connection pooling</p>"},{"location":"architecture/09-component-breakdown/#behavior-as-subsystem_3","title":"Behavior as Subsystem","text":"<ul> <li>Data persistence with ACID guarantees</li> <li>Transaction handling with rollback support</li> <li>Schema migrations with Alembic</li> </ul> <p>For detailed database information, see Database Documentation.</p>"},{"location":"architecture/09-component-breakdown/#storage-layer","title":"Storage Layer","text":""},{"location":"architecture/09-component-breakdown/#type-and-purpose_1","title":"Type and Purpose","text":"<p>S3-compatible object storage for unstructured file uploads</p>"},{"location":"architecture/09-component-breakdown/#integration-method","title":"Integration Method","text":"<p>Presigned URLs for secure direct uploads</p>"},{"location":"architecture/09-component-breakdown/#behavior-as-subsystem_4","title":"Behavior as Subsystem","text":"<ul> <li>File lifecycle management</li> <li>Access control through signed URLs</li> <li>Metadata storage in database</li> </ul> <p>For detailed storage information, see Storage Documentation.</p>"},{"location":"architecture/10-data-flow/","title":"Data Flow Diagram","text":"<p>![TO COMPLETE TAG: Visualize key steps end-to-end]</p> <p>The diagram above illustrates a typical data flow through the system.</p>"},{"location":"architecture/10-data-flow/#example-journey-file-upload-processing-visualization","title":"Example Journey: File Upload \u2192 Processing \u2192 Visualization","text":"<ol> <li>User uploads file through frontend</li> <li>Frontend requests presigned URL from backend</li> <li>File uploaded directly to storage</li> <li>Backend enqueues processing task</li> <li>Worker processes file and stores results</li> <li>Frontend retrieves processed data for visualization</li> </ol>"},{"location":"architecture/10-data-flow/#key-systems-involved-at-each-step","title":"Key Systems Involved at Each Step","text":"<ul> <li>Frontend: User interface and file selection</li> <li>Backend: Authentication, authorization, and task coordination</li> <li>Storage: File persistence and retrieval</li> <li>Workers: Asynchronous processing</li> <li>Database: Metadata and processed data storage</li> </ul>"},{"location":"architecture/11-deployment-topology/","title":"Deployment Topology","text":""},{"location":"architecture/11-deployment-topology/#docker-compose-localstaging","title":"Docker Compose (Local/Staging)","text":"<p>Local development uses Docker Compose for simplified service orchestration:</p> <ul> <li>Single docker-compose.yml file</li> <li>Shared network for service communication</li> <li>Volume mounts for data persistence</li> </ul>"},{"location":"architecture/11-deployment-topology/#kubernetes-cluster-production","title":"Kubernetes Cluster (Production)","text":"<p>Production deployments use Kubernetes for scalability and reliability:</p> <ul> <li>Helm charts for service deployment</li> <li>ArgoCD for GitOps deployment management</li> <li>Ingress controllers for external access</li> </ul>"},{"location":"architecture/11-deployment-topology/#service-mesh-overview","title":"Service Mesh Overview","text":"<p>Currently not using a service mesh, but may adopt Istio in the future for:</p> <ul> <li>Enhanced observability</li> <li>Traffic management</li> <li>Security policies</li> </ul>"},{"location":"architecture/11-deployment-topology/#ingress-and-networking-patterns","title":"Ingress and Networking Patterns","text":"<ul> <li>NGINX ingress controller for HTTP routing</li> <li>TLS termination at ingress level</li> <li>Network policies for service isolation</li> </ul> <p>![TO COMPLETE TAG: Deployment diagrams for both setups]</p> <p>For detailed deployment information, see Infrastructure Documentation.</p>"},{"location":"architecture/12-scalability/","title":"Scalability &amp; Statelessness Strategy","text":"<p>The system is designed for horizontal scaling with stateless components.</p>"},{"location":"architecture/12-scalability/#horizontal-scaling-plan","title":"Horizontal Scaling Plan","text":"<ul> <li>Frontend: Multiple instances behind load balancer</li> <li>Backend: Multiple FastAPI workers</li> <li>Database: Read replicas for read-heavy workloads</li> <li>Workers: Multiple consumer processes</li> </ul>"},{"location":"architecture/12-scalability/#stateless-design-principles-applied","title":"Stateless Design Principles Applied","text":"<p>All components are designed to be stateless:</p> <ul> <li>Session data stored in Redis</li> <li>User state persisted in database</li> <li>File uploads stored in object storage</li> <li>No local file system dependencies</li> </ul>"},{"location":"architecture/12-scalability/#load-distribution-mechanisms","title":"Load Distribution Mechanisms","text":"<ul> <li>Load balancers for external traffic distribution</li> <li>Kubernetes service discovery for internal communication</li> <li>Database connection pooling for efficient resource usage</li> </ul>"},{"location":"architecture/12-scalability/#caching-strategy-overview","title":"Caching Strategy Overview","text":"<p>Caching is implemented at multiple levels:</p> <ul> <li>CDN for static assets</li> <li>Redis for session data and temporary storage</li> <li>Database query caching where appropriate</li> <li>HTTP caching headers for API responses</li> </ul>"},{"location":"architecture/13-cross-cutting-concerns/","title":"Cross-Cutting Concerns","text":""},{"location":"architecture/13-cross-cutting-concerns/#security-model","title":"Security Model","text":""},{"location":"architecture/13-cross-cutting-concerns/#data-classification-and-protection-levels","title":"Data Classification and Protection Levels","text":"<p>Data is classified into four protection levels:</p> <ul> <li>Public: Available to all users</li> <li>Internal: Authenticated users only</li> <li>Confidential: Role-based access</li> <li>Restricted: Highly sensitive, limited access</li> </ul>"},{"location":"architecture/13-cross-cutting-concerns/#transport-and-data-at-rest-encryption","title":"Transport and Data-at-Rest Encryption","text":"<ul> <li>TLS 1.3 for all network communications</li> <li>AES-256 encryption for data at rest</li> <li>Regular certificate rotation</li> <li>Key management through Azure Key Vault</li> </ul>"},{"location":"architecture/13-cross-cutting-concerns/#authentication-enforcement-points","title":"Authentication Enforcement Points","text":"<p>Authentication is enforced at multiple points:</p> <ul> <li>API gateway level</li> <li>Individual service endpoints</li> <li>Database access layer</li> <li>Storage access controls</li> </ul> <p>This section provides detailed security information. For implementation details, see Backend Security and Frontend Auth.</p>"},{"location":"architecture/13-cross-cutting-concerns/#data-contracts","title":"Data Contracts","text":""},{"location":"architecture/13-cross-cutting-concerns/#api-schema-standards","title":"API Schema Standards","text":"<p>All APIs follow OpenAPI 3.0 specification with:</p> <ul> <li>Defined request/response schemas</li> <li>Standardized error formats</li> <li>Versioned endpoints</li> </ul>"},{"location":"architecture/13-cross-cutting-concerns/#internal-messageevent-format","title":"Internal Message/Event Format","text":"<p>Asynchronous messages use JSON format with:</p> <ul> <li>Standardized metadata fields</li> <li>Event type identifiers</li> <li>Timestamp and correlation IDs</li> </ul>"},{"location":"architecture/13-cross-cutting-concerns/#versioning-and-compatibility-policies","title":"Versioning and Compatibility Policies","text":"<ul> <li>Semantic versioning for APIs</li> <li>Backward compatibility maintained for N-1 versions</li> <li>Deprecation notices for obsolete endpoints</li> </ul>"},{"location":"architecture/13-cross-cutting-concerns/#observability","title":"Observability","text":""},{"location":"architecture/13-cross-cutting-concerns/#structured-logging-approach","title":"Structured Logging Approach","text":"<p>All components implement structured logging with:</p> <ul> <li>JSON format for easy parsing</li> <li>Consistent field naming</li> <li>Log level standardization</li> <li>Request correlation IDs</li> </ul>"},{"location":"architecture/13-cross-cutting-concerns/#metrics-exposure","title":"Metrics Exposure","text":"<p>Metrics are exposed through:</p> <ul> <li>Prometheus-style endpoints</li> <li>Custom business metrics</li> <li>Standard system metrics (CPU, memory, etc.)</li> </ul>"},{"location":"architecture/13-cross-cutting-concerns/#distributed-tracing-support","title":"Distributed Tracing Support","text":"<p>Tracing is implemented with:</p> <ul> <li>OpenTelemetry instrumentation</li> <li>Request span propagation</li> <li>Service dependency mapping</li> </ul> <p>For detailed observability information, see Infrastructure Monitoring.</p>"},{"location":"architecture/14-architectural-decisions/","title":"Architectural Decisions (ADR Summaries)","text":"<p>Key architectural decisions are documented in Architecture Decision Records (ADRs):</p> <ul> <li>ADR-001: Use FastAPI for Backend Microservices</li> <li>ADR-002: Adopt JWT-based Authentication</li> <li>ADR-003: Store Files on S3-compatible Object Storage</li> <li>ADR-004: Use Celery for Background Job Processing</li> <li>ADR-005: Implement Role-Based Access Control</li> </ul> <p>![TO COMPLETE TAG: List other major decisions and link to full ADRs]</p> <p>For complete ADRs, see Architecture Decision Records.</p>"},{"location":"architecture/15-appendices/","title":"Appendices","text":""},{"location":"architecture/15-appendices/#appendix-a-glossary-of-terms","title":"Appendix A: Glossary of Terms","text":"<ul> <li>API: Application Programming Interface</li> <li>CDN: Content Delivery Network</li> <li>CI/CD: Continuous Integration/Continuous Deployment</li> <li>ORM: Object-Relational Mapping</li> <li>SPA: Single Page Application</li> <li>TLS: Transport Layer Security</li> </ul>"},{"location":"architecture/15-appendices/#appendix-b-acronyms-used","title":"Appendix B: Acronyms Used","text":"<ul> <li>ADR: Architecture Decision Record</li> <li>JWT: JSON Web Token</li> <li>RBAC: Role-Based Access Control</li> <li>S3: Simple Storage Service</li> <li>SQL: Structured Query Language</li> <li>UI: User Interface</li> </ul>"},{"location":"architecture/15-appendices/#appendix-c-links-to-full-adr-documents","title":"Appendix C: Links to Full ADR Documents","text":"<ul> <li>ADR-001: FastAPI Backend</li> <li>ADR-002: JWT Authentication</li> <li>ADR-003: S3 Storage</li> <li>ADR-004: Celery Workers</li> <li>ADR-005: RBAC Implementation</li> </ul>"},{"location":"architecture/TODO/","title":"Architecture Documentation TODO","text":"<p>This document tracks missing content, incomplete sections, and items to be completed in the architecture documentation.</p>"},{"location":"architecture/TODO/#high-priority-missing-content","title":"\ud83d\udd34 High Priority - Missing Content","text":""},{"location":"architecture/TODO/#diagrams-visualizations","title":"Diagrams &amp; Visualizations","text":"<ol> <li> <p>02-system-overview.md</p> </li> <li> <p> Add component interaction diagram showing all layers and their connections</p> </li> <li> <p> Create visual representation of data flow between Frontend, Backend, Workers, Database, and Storage</p> </li> <li> <p>03-subsystem-map.md</p> </li> <li> <p> Add dependency graph showing layer relationships</p> </li> <li> <p> Create detailed mapping of service dependencies</p> </li> <li> <p>04-auth-flow.md</p> </li> <li> <p> Add sequence diagram showing complete login \u2192 token usage \u2192 API call flow</p> </li> <li> <p> Visualize token propagation across Frontend \u2192 Backend \u2192 Workers \u2192 Database</p> </li> <li> <p>06-cicd-pipeline.md</p> </li> <li> <p> Include pipeline architecture diagram showing GitHub Actions \u2192 Build \u2192 Test \u2192 Deploy flow</p> </li> <li> <p> Add visual representation of ArgoCD deployment process</p> </li> <li> <p>10-data-flow.md</p> </li> <li> <p> Visualize complete end-to-end data flow for file upload \u2192 processing \u2192 visualization</p> </li> <li> <p> Add swimlane diagram showing which systems handle each step</p> </li> <li> <p>11-deployment-topology.md</p> </li> <li> Add deployment diagram for Docker Compose (local/staging) setup</li> <li> Add deployment diagram for Kubernetes (production) topology</li> <li> Include network topology and ingress routing diagrams</li> </ol>"},{"location":"architecture/TODO/#environment-configuration-details","title":"Environment Configuration Details","text":"<ol> <li>05-environments.md</li> <li> Document environment-specific configurations in detail</li> <li> Describe secrets management approach per environment (local .env, K8s secrets, Azure Key Vault)</li> <li> Add table of environment variables and their purposes</li> <li> Document database configuration differences between environments</li> <li> Specify Redis/Celery configuration per environment</li> </ol>"},{"location":"architecture/TODO/#convention-documentation","title":"Convention Documentation","text":"<ol> <li>07-global-conventions.md</li> <li> Link to or create comprehensive style guide document</li> <li> Add code formatting examples for Python (black, ruff)</li> <li> Add code formatting examples for JavaScript/Vue (ESLint, Prettier)</li> <li> Document API response format standards</li> <li> Add error code registry</li> </ol>"},{"location":"architecture/TODO/#architecture-decision-records","title":"Architecture Decision Records","text":"<ol> <li> <p>08-tech-stack.md</p> </li> <li> <p> Reference specific ADR files for each technology choice</p> </li> <li> Create ADR folder structure if not exists</li> <li> <p> Link to individual ADR documents</p> </li> <li> <p>14-architectural-decisions.md</p> <ul> <li> List additional major architectural decisions beyond the 5 mentioned</li> <li> Link to complete ADR documents in <code>/docs/architecture-decision-records/</code></li> </ul> </li> </ol>"},{"location":"architecture/TODO/#medium-priority-additional-documentation-needed","title":"\ud83d\udfe1 Medium Priority - Additional Documentation Needed","text":""},{"location":"architecture/TODO/#security-epfl-compliance","title":"Security &amp; EPFL Compliance","text":"<ol> <li>EPFL Constraints Implementation<ul> <li> Create document mapping EPFL requirements (from epfl-constraint.md) to actual implementation</li> <li> Document how OIDC/OAuth2 integration meets SVC0018 requirements</li> <li> Explain OCI container compliance strategy</li> <li> Detail backup strategy compliance with SVC0003</li> <li> Document SIEM log integration approach</li> <li> Explain monitoring integration with EPFL End-to-End Service</li> </ul> </li> </ol>"},{"location":"architecture/TODO/#component-documentation-cross-references","title":"Component Documentation Cross-References","text":"<ol> <li> <p>Frontend Documentation</p> <ul> <li> Verify all references to <code>../frontend/index.md</code> are valid</li> <li> Ensure frontend architecture documentation exists</li> <li> Verify frontend dev-guide is available</li> </ul> </li> <li> <p>Backend Documentation</p> <ul> <li> Verify all references to <code>../backend/index.md</code> are valid</li> <li> Ensure backend architecture documentation exists</li> <li> Verify backend plugins documentation exists</li> </ul> </li> <li> <p>Database Documentation</p> <ul> <li> Verify all references to <code>../database/index.md</code> are valid</li> <li> Ensure database schema documentation exists</li> <li> Document migration strategy</li> </ul> </li> <li> <p>Infrastructure Documentation</p> <ul> <li> Verify all references to <code>../infra/</code> are valid</li> <li> Ensure infrastructure hosting documentation exists</li> <li> Document monitoring setup</li> </ul> </li> </ol>"},{"location":"architecture/TODO/#development-operations","title":"Development &amp; Operations","text":"<ol> <li> <p>Local Development Setup</p> <ul> <li> Create comprehensive local development guide</li> <li> Document Docker Compose setup steps</li> <li> Add troubleshooting section for common dev environment issues</li> <li> Document how to run tests locally</li> </ul> </li> <li> <p>Deployment Procedures</p> <ul> <li> Document step-by-step deployment process for each environment</li> <li> Create rollback procedure documentation</li> <li> Document blue-green deployment strategy in detail</li> <li> Add deployment checklist</li> </ul> </li> <li> <p>Monitoring &amp; Alerting</p> <ul> <li> Document Prometheus metrics exposed by each service</li> <li> List key Grafana dashboards and their purposes</li> <li> Define alert thresholds and escalation procedures</li> <li> Document SIEM integration configuration</li> </ul> </li> </ol>"},{"location":"architecture/TODO/#low-priority-nice-to-have","title":"\ud83d\udfe2 Low Priority - Nice to Have","text":""},{"location":"architecture/TODO/#performance-scalability","title":"Performance &amp; Scalability","text":"<ol> <li>Scalability Documentation<ul> <li> Add load testing results and capacity planning data</li> <li> Document autoscaling thresholds and configurations</li> <li> Create performance benchmarks for different load scenarios</li> <li> Document database optimization strategies</li> </ul> </li> </ol>"},{"location":"architecture/TODO/#data-management","title":"Data Management","text":"<ol> <li>Data Lifecycle<ul> <li> Document data retention policies (10 years for results, 5 years for travel)</li> <li> Create data archival strategy</li> <li> Document GDPR compliance measures</li> <li> Add data backup and recovery procedures</li> </ul> </li> </ol>"},{"location":"architecture/TODO/#testing-strategy","title":"Testing Strategy","text":"<ol> <li>Testing Documentation<ul> <li> Document unit testing strategy and coverage requirements (70% minimum)</li> <li> Explain integration testing approach</li> <li> Document E2E testing with Cypress</li> <li> Add load testing strategy with k6/Locust</li> </ul> </li> </ol>"},{"location":"architecture/TODO/#api-documentation","title":"API Documentation","text":"<ol> <li>API Specifications<ul> <li> Ensure OpenAPI/Swagger documentation is complete</li> <li> Document all API versioning strategy</li> <li> Add API deprecation policy</li> <li> Create API usage examples for common workflows</li> </ul> </li> </ol>"},{"location":"architecture/TODO/#project-context","title":"Project Context","text":"<ol> <li>Functional Requirements Mapping<ul> <li> Map architecture components to functional modules from spec.md:</li> <li>Mon Laboratoire</li> <li>D\u00e9placements professionnels</li> <li>Infrastructure</li> <li>Consommation \u00e9lectrique \u00e9quipement</li> <li>Achats</li> <li>Services internes</li> <li>Visualisation des r\u00e9sultats</li> <li>Documentation &amp; Contact</li> <li>Interfaces de gestion (admin)</li> <li> Document how each layer supports the functional requirements</li> </ul> </li> </ol>"},{"location":"architecture/TODO/#documentation-quality-improvements","title":"\ud83d\udccb Documentation Quality Improvements","text":""},{"location":"architecture/TODO/#consistency-completeness","title":"Consistency &amp; Completeness","text":"<ol> <li> <p>Cross-Reference Validation</p> <ul> <li> Verify all internal links work correctly</li> <li> Ensure consistent terminology across all documents</li> <li> Validate that referenced documents exist</li> <li> Check that all \"TO COMPLETE TAG\" items are addressed</li> </ul> </li> <li> <p>Code Examples</p> <ul> <li> Add configuration file examples where referenced</li> <li> Include sample API requests/responses</li> <li> Add example environment variable files</li> <li> Provide sample Kubernetes manifests</li> </ul> </li> <li> <p>Migration Documentation</p> <ul> <li> Document database migration procedures</li> <li> Add version upgrade guides</li> <li> Create breaking change documentation</li> </ul> </li> </ol>"},{"location":"architecture/TODO/#quick-wins-can-be-addressed-immediately","title":"\ud83c\udfaf Quick Wins (Can be addressed immediately)","text":"<ul> <li> Replace all \"TO COMPLETE TAG\" markers with actual content or remove if not needed</li> <li> Fix typo in filename: <code>full-tech-stach.md</code> \u2192 <code>full-tech-stack.md</code></li> <li> Add index links in index.md for kickoff.md, spec.md, epfl-constraint.md, and full-tech-stack.md</li> <li> Create Architecture Decision Records folder structure</li> <li> Ensure all Markdown files follow consistent formatting</li> </ul>"},{"location":"architecture/TODO/#notes","title":"Notes","text":"<ul> <li>Many sections reference documents in <code>../frontend/</code>, <code>../backend/</code>, <code>../database/</code>, and <code>../infra/</code> folders. Verify these exist and contain the expected content.</li> <li>The \"TO COMPLETE TAG\" markers indicate placeholder content that needs diagrams, links, or detailed explanations.</li> <li>Consider using tools like Mermaid for inline diagrams in Markdown files.</li> <li>EPFL compliance requirements from <code>epfl-constraint.md</code> need to be explicitly mapped to implementation details.</li> </ul>"},{"location":"architecture/epfl-constraint/","title":"RFC-EPFL-IT-001: IT Requirements Specification","text":"<p>Author: F. Pitteloud Version: 1.0 Date: 05.02.2025</p>"},{"location":"architecture/epfl-constraint/#1-scope","title":"1. Scope","text":"<p>This RFC defines the mandatory (P0), recommended (P1), and optional (P2) technical requirements for any IT solution deployed or acquired by EPFL. Compliance ensures interoperability, maintainability, and alignment with EPFL infrastructure standards.</p>"},{"location":"architecture/epfl-constraint/#2-authentication-and-authorization-svc0018","title":"2. Authentication and Authorization (SVC0018)","text":"<p>2.1 Solutions MUST support strong authentication mechanisms. 2.2 Solutions MUST support OpenID Connect (OIDC) and OAuth 2.0+. 2.3 Solutions SHOULD support SAML 2.0+. 2.4 Solutions MAY support SCIM for identity provisioning. 2.5 LDAPS is PROHIBITED (does not meet EPFL strong auth requirements).</p>"},{"location":"architecture/epfl-constraint/#3-infrastructure-as-code-iac","title":"3. Infrastructure as Code (IaC)","text":"<p>3.1 Solutions SHOULD support Ansible or Puppet for deployment and orchestration. 3.2 IaC integration MAY be used to automate configuration management.</p>"},{"location":"architecture/epfl-constraint/#4-virtualization-hypervisors","title":"4. Virtualization / Hypervisors","text":"<p>4.1 Solutions MUST support hypervisor upgrades. 4.2 Solutions MUST support VMware, including high-availability mechanisms.</p>"},{"location":"architecture/epfl-constraint/#5-containers","title":"5. Containers","text":"<p>5.1 Containerized solutions MUST support OS patching and upgrades. 5.2 Container images MUST be OCI-compliant. 5.3 Docker images SHOULD be used only if OCI-compliant.</p>"},{"location":"architecture/epfl-constraint/#6-server-operating-systems-svc1168-svc1215","title":"6. Server Operating Systems (SVC1168 / SVC1215)","text":"<p>6.1 Solutions MUST support OS patching and upgrade cycles. 6.2 Supported server OS:</p> <ul> <li>Windows Server</li> <li>Red Hat Enterprise Linux</li> <li>SUSE Enterprise Linux (SAP-only)</li> </ul>"},{"location":"architecture/epfl-constraint/#7-client-operating-systems","title":"7. Client Operating Systems","text":"<p>7.1 Solutions MUST support OS patching and upgrade cycles. 7.2 Supported client OS:</p> <ul> <li>Windows</li> <li>macOS</li> <li>Linux (optional)</li> </ul>"},{"location":"architecture/epfl-constraint/#8-databases-svc0020-svc0021","title":"8. Databases (SVC0020 / SVC0021)","text":"<p>8.1 Supported databases:</p> <ul> <li>SQL Server (MUST)</li> <li>MariaDB (MUST)</li> </ul>"},{"location":"architecture/epfl-constraint/#9-antivirus-svc0062","title":"9. Antivirus (SVC0062)","text":"<p>9.1 Solutions MUST comply with EPFL antivirus standards and policies. 9.2 Any deviation MUST be approved by IT Security.</p>"},{"location":"architecture/epfl-constraint/#10-backup-svc0003","title":"10. Backup (SVC0003)","text":"<p>10.1 Solutions MUST support EPFL\u2019s official backup solution and strategy. 10.2 Any exception MUST be validated by IT Security.</p>"},{"location":"architecture/epfl-constraint/#11-log-management","title":"11. Log Management","text":"<p>11.1 Solutions MUST provide logs compatible with the EPFL SIEM service. 11.2 Exceptions MUST be approved by IT Security.</p>"},{"location":"architecture/epfl-constraint/#12-monitoring-svc0345","title":"12. Monitoring (SVC0345)","text":"<p>12.1 Solutions MUST be monitorable by EPFL End-to-End Service. 12.2 Exceptions MUST be validated by the IT Service Manager.</p>"},{"location":"architecture/epfl-constraint/#13-priority-levels","title":"13. Priority Levels","text":"Code Level Meaning P0 MUST Mandatory requirement P1 SHOULD Recommended / acceptable alternative P2 MAY Optional / nice-to-have <p>End of RFC-EPFL-IT-001</p>"},{"location":"architecture/full-tech-stach/","title":"Full tech stach","text":""},{"location":"architecture/full-tech-stach/#3-full-rationale-detailed-choices","title":"3 \u2014 Full rationale &amp; detailed choices","text":""},{"location":"architecture/full-tech-stach/#31-frontend-choices-why","title":"3.1 Frontend choices (why)","text":"<ul> <li>npm: EPFL/industry standard; broad ecosystem; works seamlessly with Vite/Quasar.</li> <li>Vite: lightning-fast dev server, HMR, small build overhead \u2014 ideal for Vue 3 modern stack and faster iteration. Supports SSR or SPA if needed later.</li> <li>Vue 3: requested; stable, reactive composition API, good developer ergonomics; excellent TypeScript support if needed.</li> <li>Quasar: component library + layout scaffolding + built-in PWA, i18n-friendly and speeds UI development; fits EPFL need for quick, consistent UI with themable design.</li> <li>Pinia: modern, lightweight state management for Vue 3; easier to reason about than Vuex; integrates with devtools.</li> <li>eCharts: powerful, rich charts; good for complex visualizations required by CO2 dashboards. It handles large datasets and interactive charts.</li> <li>vue-i18n: EPFL needs multiple languages; this is a standard, robust solution.</li> <li>marked: lightweight markdown renderer; v9 is modern and secure when used with proper sanitization (explain sanitization below).</li> </ul> <p>Security &amp; accessibility notes for frontend</p> <ul> <li>Sanitize any Markdown output (use DOMPurify or similar) before rendering to avoid XSS.</li> <li>Implement CSP headers via backend / ingress to reduce client-side risk.</li> <li>Ensure accessibility (a11y) \u2014 Quasar helps but audits required.</li> </ul>"},{"location":"architecture/full-tech-stach/#32-backend-choices-why","title":"3.2 Backend choices (why)","text":"<ul> <li>Python 3.13 runtime: latest supported stable release increases performance and typing improvements. You listed <code>python = \"^3.10\"</code> in dependencies; that shows compatibility with 3.10+, so selecting 3.13 as runtime keeps compatibility while giving performance/security improvements. If a strict constraint demands 3.10 only, we can downgrade.</li> <li>FastAPI: excellent async performance, automatic OpenAPI generation (required), good typing and developer speed, plays well with Uvicorn + asyncpg. It also produces clear, machine-readable API docs (Swagger) the cahier requires.</li> <li>Uvicorn (ASGI server): lightweight, async; production run either with Gunicorn + Uvicorn workers or using Uvicorn and process manager. The list included <code>uvicorn</code>.</li> <li>asyncpg: async Postgres driver with great performance for coroutine-based stack. Use with SQLAlchemy (1.4+ async ORM) or with a lean SQL layer like <code>databases</code> if preferred. You included <code>enacit4r-sql</code> so integrate with that.</li> <li>psycopg2: kept for CLI / tooling that prefer sync driver.</li> <li>Alembic: migrations management standard for SQLAlchemy.</li> <li>Dynaconf + python-dotenv: structured config that supports env vars, multiple environments; Dynaconf integrates well with Docker/K8s patterns.</li> <li>EPFL enacit4r-* packages: reuse EPFL-specific helpers (files, auth, sql). Pin exact git revisions for reproducibility.</li> <li> <p>Uv (recommended) as package manager</p> </li> <li> <p>Why not pip alone? Pip doesn't produce a lockfile by default; Uv gives locked, reproducible builds. This is important in production.</p> </li> </ul> <p>Security &amp; standards</p> <ul> <li>Implement JWT/OIDC integration with MS Entra ID using a dedicated module (enacit4r-auth or standard libraries such as <code>python-jose</code>, <code>authlib</code> or <code>fastapi_oidc</code>). Provide an auth module that maps Entra group claims to application roles.</li> <li>Auth integration should be a pluggable adapter so the app can be used by other universities without Entra (e.g., simple OAuth2 provider or local SAML plugin).</li> <li>Logging structured as JSON (logfmt or JSON) to feed EPFL SIEM. Include request IDs, user GUIDs (where allowed), timestamps, severity, and event types.</li> <li>Security scanning: SAST (Bandit/semgrep), dependency scan (safety, Dependabot or GitHub Dependabot), container scanning (Trivy).</li> </ul>"},{"location":"architecture/full-tech-stach/#33-data-caching-redis-decision","title":"3.3 Data &amp; caching \u2014 Redis decision","text":"<p>Do we need Redis? \u2014 Recommendation: Yes (recommended)</p> <p>Why Redis is recommended</p> <ul> <li>Cache emission factors and static lookups (e.g., NACRES mapping, factor sets) to reduce DB queries and speed dashboard loads during peak (February annual load).</li> <li>Rate limiting (per-user or per-IP) implemented in Redis is standard and helps protect from abusive loads.</li> <li>Short-lived sessions / token revocation lists: If we use JWTs, sessions are stateless but JWT revocation (logout / forced logout) requires a store. Redis is the natural choice.</li> <li>Background job broker: Celery/RQ require a broker\u2014Redis is also commonly used here.</li> <li>Feature flags &amp; ephemeral storage: Redis is handy for locks, counters, and concurrency control.</li> </ul> <p>Costs &amp; trade-offs</p> <ul> <li>Adds operational complexity (another service to manage).</li> <li>If you must minimize infrastructure and you accept eventual longer response times and no revocation capability, you could omit Redis initially and rely completely on database caching + CDN. But given the expected annual spikes, using Redis early reduces DB load and is safer.</li> </ul> <p>Conclusion: Include Redis as an optional-but-highly-recommended service in all environments (dev: single container, staging/prod: managed Redis instance or k8s operator). Use Redis for caching, rate limits, and the job broker.</p>"},{"location":"architecture/full-tech-stach/#34-background-processing","title":"3.4 Background processing","text":"<ul> <li>Option A (recommended): Celery with Redis broker + Redis result backend. Mature, widely-known.</li> </ul> <p>Recommendation: Celery for max flexibility (scheduling, retries, priorities). Use it for heavy tasks: ingest CSVs, long-running factor recalculations, export generation (PDF), and optionally for auto-ingestion jobs.</p>"},{"location":"architecture/full-tech-stach/#35-session-auth-flow","title":"3.5 Session &amp; auth flow","text":"<ul> <li>Primary: OIDC login via MS Entra ID (EPFL). Use OIDC provider to receive id_token + access_token. Validate tokens server-side (signature, audience, expiry) using <code>python-jose</code> or <code>authlib</code>. Map Entra claims / groups to app roles (Gestionnaire IT, Gestionnaire M\u00e9tier, etc.).</li> <li>Statelessness: Use JWTs for session tokens to stay stateless and scale horizontally. Keep token lifetime short and use refresh tokens if necessary.</li> <li>Revocation / logout: Implement token revocation via Redis blacklist (recommended). Without Redis, revocation is hard.</li> <li>Pluggable module: Build auth adapter interface so the auth layer can be swapped for other IDM (SAML2) for non-Entra institutions.</li> </ul>"},{"location":"architecture/full-tech-stach/#36-database-data-model-notes","title":"3.6 Database &amp; data model notes","text":"<ul> <li>Postgres (primary). Use schemas for separation (e.g., <code>public</code>, <code>audit</code>, <code>analytics</code>) if desired.</li> <li>Connection pooling: Use <code>asyncpg</code> with built-in pool, configure pool size according to pod/worker counts; use PgBouncer if high concurrency is expected.</li> <li>Migrations: Alembic. Keep migration scripts in repo; enforce code review on migrations.</li> <li>Backups: Conform to EPFL backup policy \u2014 automated backups, retention (align with cahier: results stored 10 years, some travel data 5 years). Store backups in EPFL-approved storage.</li> <li>Audit logs: All writes and important changes logged (who, when, what), and logs forwarded to SIEM.</li> </ul>"},{"location":"architecture/full-tech-stach/#37-containerization-orchestration","title":"3.7 Containerization &amp; orchestration","text":"<ul> <li>Images: OCI-compliant, small base images (python:3.13-slim or distroless) with multi-stage builds. EPFL requirement: support OS patching and updates.</li> <li> <p>docker-compose (dev / Ansible flows):</p> </li> <li> <p>Use Traefik as reverse proxy in compose for routing, TLS (Let\u2019s Encrypt or cert manager for local certs), and for ease of Ansible-driven deployments.</p> </li> <li> <p>Example services: web (backend), frontend (vite build served by CDN or static nginx), postgres, redis, minio (if object storage required), traefik, pgadmin (optional).</p> </li> <li> <p>Kubernetes (prod):</p> </li> <li> <p>Use k8s manifests or Helm charts.</p> </li> <li>Use nginx-ingress controller (as requested) for production ingress. TLS managed with cert-manager.</li> <li>Use Horizontal Pod Autoscaler (HPA) and resource requests/limits for autoscaling.</li> <li>Readiness/liveness probes configured.</li> <li>Use ephemeral storage for pods; persistent volumes only for Postgres (or use managed Postgres). For Redis prefer managed service or k8s operator.</li> <li>Use PodDisruptionBudgets and anti-affinity rules across nodes.</li> <li>Use liveness/readiness for worker pods (Celery) too.</li> </ul>"},{"location":"architecture/full-tech-stach/#38-networking-proxies-tls","title":"3.8 Networking, proxies &amp; TLS","text":"<ul> <li>k8s ingress: nginx-ingress controller (EPFL standard) with cert-manager.</li> <li>compose/ansible proxy: Traefik \u2014 matches your Ansible/local flow request. Traefik provides automatic dynamic routing and supports Let's Encrypt, etc.</li> <li>HTTP headers: Set HSTS, CSP, X-Frame-Options, X-XSS-Protection, Referrer-Policy; enforced at ingress/proxy.</li> <li>CORS: Backend must implement strict CORS rules allowing only EPFL UIs / origins.</li> </ul>"},{"location":"architecture/full-tech-stach/#39-observability-logging","title":"3.9 Observability &amp; logging","text":"<ul> <li>Metrics: Instrument FastAPI endpoints with Prometheus client; export <code>/metrics</code>. Frontend usage metrics via custom metrics pipeline (if allowed).</li> <li>Tracing: OpenTelemetry SDK to capture traces; send to collector, then to tracing backend (Jaeger/Tempo).</li> <li>Logs: Structured JSON logs from backend, forwarded to EPFL SIEM (ELK or SIEM HTTP ingest). Include correlation ID propagation across frontend/backend.</li> <li>Dashboards: Grafana dashboards for app &amp; infra metrics; set alerts on errors, latency, job queue sizes, DB connection exhaustion.</li> <li>Error reporting: Sentry (or EPFL-approved alternative) for uncaught exceptions in backend and front-end.</li> </ul>"},{"location":"architecture/full-tech-stach/#310-security-compliance-i-dont-know-tod-dicscuss","title":"3.10 Security &amp; compliance /!\\ I DON'T KNOW, TOD DICsCUSS","text":"<ul> <li>OWASP best practices: Input validation, output escaping, CSRF protection where needed, secure cookies.</li> <li>Dependency scanning: GitHub/GitLab Dependabot + ( Snyk/Trivy ?? )</li> <li>Static analysis: Bandit/semgrep in CI. ???</li> <li>Secrets: Use Vault or sealed-secrets; never store secrets in repo.</li> <li>Penetration tests / audits: EPFL may request an external security audit. Provide budget in options.</li> <li>Data retention policy: Implement app logic to purge/retain according to cahier (10 years, 5 years for travel). Ensure backups mirror retention rules.</li> </ul>"},{"location":"architecture/full-tech-stach/#4-developer-ergonomics-repo-structure-recommended","title":"4 \u2014 Developer ergonomics &amp; repo structure (recommended)","text":"<p>Monorepo</p>"},{"location":"architecture/full-tech-stach/#5-ci-cd-pipeline-recommended","title":"5 \u2014 CI / CD pipeline (recommended)","text":"<ul> <li>Stages: lint (ESLint + style), unit tests (pytest for backend, vitest/jest for frontend), security scans, build (docker images), push to registry, deploy to staging, run integration tests, promote to prod via manual approval.</li> <li>Image signing: optional but recommended for production compliance.</li> <li>Canary / Blue/Green: K8s deployments should allow safe rollouts (rolling update, canary via ingress weights).</li> </ul>"},{"location":"architecture/full-tech-stach/#6-example-dev-prod-compose-k8s-artifacts-short","title":"6 \u2014 Example dev &amp; prod Compose / k8s artifacts (short)","text":"<ul> <li>Docker Compose: <code>docker-compose.yml</code> with services: backend, frontend(for dev), postgres, redis, traefik, minio (if needed). Traefik configured to route <code>api.local</code> -&gt; backend, <code>app.local</code> -&gt; frontend.</li> <li> <p>K8s:</p> </li> <li> <p>Deployment + Service for backend + HPA + ConfigMap for envs + Secret for keys.</p> </li> <li>Deployment for celery workers.</li> <li>StatefulSet/Managed for Postgres (or external managed service).</li> <li>Redis via operator or managed service.</li> <li>Ingress resource using nginx-ingress controller.</li> </ul> <p>(I can produce concrete example <code>docker-compose.yml</code> and k8s manifests or Helm chart if you want \u2014 tell me which and I\u2019ll generate.)</p>"},{"location":"architecture/full-tech-stach/#7-performance-scaling-capacity-planning","title":"7 \u2014 Performance, scaling &amp; capacity planning","text":"<ul> <li>Stateless design: backend pods can scale horizontally; no sticky sessions required.</li> <li>Session strategy: use JWTs (stateless) + Redis for revocation and short-lived state if needed.</li> <li>DB scaling: read replicas and connection pooling (PgBouncer) for heavy analytic queries. Use caches (Redis) for repeated factor lookups/aggregates.</li> <li>Peak load (February): pre-warm caches, increase replicas temporarily via HPA or manual scale; ensure Celery workers and DB sizing can support bulk CSV ingestion and report generation.</li> </ul>"},{"location":"architecture/full-tech-stach/#8-versioning-dependency-pinning","title":"8 \u2014 Versioning &amp; dependency pinning","text":"<ul> <li> <p>Frontend deps: use the versions you provided:</p> </li> <li> <p>marked: ^9.0.3</p> </li> <li>pinia: ^3.0.1</li> <li>quasar: ^2.18.1</li> <li>vue: ^3.5.13</li> <li>vue-i18n: ^11.1.7</li> <li> <p>vue-router: ^4.3.2</p> </li> <li> <p>Backend deps: pin the listed ones and exact git rev references you provided for enacit4r-* packages, alembic ^1.14.0, asyncpg ^0.30.0, psycopg2 ^2.9.10, dynaconf ^3.2.6, python-dotenv ^1.0.1. Use UV lock for reproducible builds.</p> </li> </ul>"},{"location":"architecture/full-tech-stach/#9-final-recommendations-next-steps","title":"9 \u2014 Final recommendations / next steps","text":"<ol> <li>Accept runtime Python 3.13 (we used this in the spec). If EPFL infra forbids 3.13, revert to 3.10/3.11.</li> <li>Include Redis in staging/prod (strongly recommended). Mark as optional in MVP but prepare code paths for it.</li> <li>Auth adapter: create a dedicated module that handles OIDC/MS Entra and a fallback for other providers (SAML). Keep it pluggable.</li> <li>CI/CD + k8s manifests: implement a GitOps pipeline or CI pipeline with staging/prod deployments. I can create sample GitHub Actions + Helm charts.</li> <li>Observability: wire Prometheus + Grafana + OpenTelemetry early (debugging and capacity planning later).</li> <li>Security hygiene: configure SAST &amp; dependency scanning in CI before code freeze.</li> </ol>"},{"location":"architecture/full-tech-stach/#10-appendix-quick-decision-table","title":"10 \u2014 Appendix: quick decision table","text":"Topic Decision Python runtime 3.13 (target) \u2014 compatible with specified deps (they declare 3.10+). Package manager (backend) UV (recommended for locks &amp; reproducible builds). Web framework FastAPI ASGI server Uvicorn (with Gunicorn in prod if needed) DB Postgres Cache / Broker Redis (recommended) Background tasks Celery (Redis broker) Auth OIDC / MS Entra + pluggable adapter Containers OCI images, docker-compose (Traefik) &amp; k8s (nginx-ingress) Observability Prometheus, Grafana, OpenTelemetry, ELK/SIEM"},{"location":"architecture/kickoff/","title":"\ud83e\udded Developer Kickoff Brief \u2014 Calculateur CO\u2082 @ EPFL","text":"<p>Project purpose: A modular, open-source web application allowing EPFL labs to record, visualise and simulate CO\u2082 emissions from research activities \u2014 built according to EPFL IT &amp; security standards.</p>"},{"location":"architecture/kickoff/#1-technical-overview","title":"1 \u2014 Technical Overview","text":"Layer Stack Purpose / Notes Frontend Vue 3 + Vite + Quasar + Pinia + Vue-Router + Vue-i18n + eCharts + Marked Responsive SPA, modular UI kit, built-in i18n and theming Backend Python 3.13 / FastAPI / Uvicorn / SQLAlchemy + asyncpg + Alembic / Dynaconf / Poetry High-performance REST + WebSocket API, async, typed, OpenAPI docs Auth &amp; Sessions OIDC / OAuth 2 via MS Entra ID + enacit4r-auth EPFL SSO, JWT-based stateless sessions Database PostgreSQL 15+ Main data store; strict migrations, role-based access Cache / Broker Redis 7+ Caching, rate-limiting, background jobs, token blacklist Workers Celery + Redis Async CSV imports, report generation, e-mail tasks Containerisation Docker / docker-compose + Traefik (dev) / Kubernetes + nginx-ingress (prod) Dev reproducibility + scalable deployment Observability Prometheus + Grafana + OpenTelemetry + EPFL SIEM logs Metrics, dashboards, alerting, traceability CI/CD GitHub Actions Lint \u2192 Test \u2192 Build \u2192 Scan \u2192 Deploy (GitOps)"},{"location":"architecture/kickoff/#2-repository-layout","title":"2 \u2014 Repository Layout","text":"<pre><code>root/\n\u251c\u2500\u2500 frontend/\n\u2502   \u251c\u2500\u2500 src/\n\u2502   \u2502   \u251c\u2500\u2500 components/\n\u2502   \u2502   \u251c\u2500\u2500 pages/\n\u2502   \u2502   \u251c\u2500\u2500 stores/          # Pinia stores\n\u2502   \u2502   \u251c\u2500\u2500 charts/          # eCharts configs\n\u2502   \u2502   \u251c\u2500\u2500 i18n/            # locale JSONs\n\u2502   \u2502   \u2514\u2500\u2500 router/\n\u2502   \u251c\u2500\u2500 public/\n\u2502   \u251c\u2500\u2500 vite.config.ts\n\u2502   \u2514\u2500\u2500 package.json\n\u2502\n\u251c\u2500\u2500 backend/\n\u2502   \u251c\u2500\u2500 app/\n\u2502   \u2502   \u251c\u2500\u2500 api/             # FastAPI routers\n\u2502   \u2502   \u251c\u2500\u2500 models/          # SQLAlchemy models\n\u2502   \u2502   \u251c\u2500\u2500 schemas/         # Pydantic schemas\n\u2502   \u2502   \u251c\u2500\u2500 services/        # business logic\n\u2502   \u2502   \u251c\u2500\u2500 auth/            # OIDC adapter\n\u2502   \u2502   \u251c\u2500\u2500 workers/         # Celery tasks\n\u2502   \u2502   \u2514\u2500\u2500 core/            # config, logging, metrics\n\u2502   \u251c\u2500\u2500 migrations/          # Alembic\n\u2502   \u251c\u2500\u2500 tests/\n\u2502   \u251c\u2500\u2500 pyproject.toml       # uv\n\u2502   \u2514\u2500\u2500 Dockerfile\n\u2502\n\u251c\u2500\u2500 infra/\n\u2502   \u251c\u2500\u2500 docker-compose.yml\n\u2502   \u251c\u2500\u2500 traefik/\n\u2502   \u2514\u2500\u2500 k8s/                 # manifests / Helm chart\n\u2502\n\u2514\u2500\u2500 docs/\n    \u251c\u2500\u2500 architecture.md\n    \u251c\u2500\u2500 api_reference.md\n    \u2514\u2500\u2500 contributing.md\n</code></pre>"},{"location":"architecture/kickoff/#3-environment-setup","title":"3 \u2014 Environment setup","text":""},{"location":"architecture/kickoff/#frontend","title":"Frontend","text":"<pre><code>cd frontend\nnpm install\nnpm run dev\nnpm run build    # \u2192 dist/\n</code></pre>"},{"location":"architecture/kickoff/#backend","title":"Backend","text":"<pre><code>cd backend\nuv sync\npoetry run uvicorn app.main:app --reload\n</code></pre>"},{"location":"architecture/kickoff/#docker-local-full-stack","title":"Docker (local full stack)","text":"<pre><code>docker compose up --build\n# services: traefik, frontend, backend, postgres, redis, pgadmin\n</code></pre>"},{"location":"architecture/kickoff/#kubernetes","title":"Kubernetes","text":"<ul> <li>Manifests: <code>infra/k8s/</code></li> <li>Deploy with <code>kubectl apply -k infra/k8s</code> or via Helm.</li> <li>Ingress class: <code>nginx</code> (cert-manager handles TLS).</li> </ul>"},{"location":"architecture/kickoff/#4-coding-standards","title":"4 \u2014 Coding Standards","text":""},{"location":"architecture/kickoff/#41-backend-python-fastapi","title":"4.1 Backend (Python / FastAPI)","text":"Category Rule Style Follow PEP 8, PEP 484 typing, black auto-formatter, isort, ruff for lint. Async Prefer async/await end-to-end; no blocking I/O inside request handlers. Type safety All public functions must be fully type-hinted; use <code>mypy</code> in CI. Config Centralize in <code>app/core/config.py</code> via Dynaconf. Never hard-code secrets. Routing Group endpoints by domain in <code>app/api/v1/\u2026</code>; mount under <code>/api/v1</code>. Validation Use Pydantic schemas for all inputs / outputs; never trust user data. Database Access through repository pattern; commit only in service layer. Testing Use pytest + httpx.AsyncClient; minimum 70 % coverage gate in CI. Docs Ensure FastAPI generates valid OpenAPI 3; keep docstrings up-to-date. Security Validate JWTs on every request; sanitize any Markdown rendered server-side."},{"location":"architecture/kickoff/#42-frontend-vue-quasar","title":"4.2 Frontend (Vue / Quasar)","text":"Category Rule Language Vue 3 composition API, <code>&lt;script setup&gt;</code> syntax; TypeScript optional but encouraged. State Use Pinia for global state; no ad-hoc event bus. Routing vue-router 4; all routes defined in <code>src/router/index.ts</code>. i18n Text never hard-coded; always via <code>$t()</code>. Default EN, fallback FR. Styling Scoped SCSS; adhere to EPFL color palette and accessibility contrast \u2265 4.5:1. Lint ESLint + Prettier; run <code>npm run lint</code> before commit. Security Sanitize Markdown with DOMPurify; CSP headers enforced by backend. Testing Vitest + Vue Test Utils; target 80 % coverage."},{"location":"architecture/kickoff/#5-branching-version-control","title":"5 \u2014 Branching &amp; Version Control","text":"Branch Purpose <code>main</code> stable, tagged releases, deployed to prod <code>develop</code> integration branch for next release <code>feature/&lt;issue&gt;</code> short-lived feature branches <code>fix/&lt;issue&gt;</code> bug fixes <code>chore/\u2026</code> non-functional changes (deps, config) <p>Conventions</p> <ul> <li>Conventional Commits (<code>feat:</code>, <code>fix:</code>, <code>chore:</code> \u2026).</li> <li>PRs must reference issue ID and include short description.</li> <li>Commit merges only</li> </ul>"},{"location":"architecture/kickoff/#6-ci-cd-pipeline-stages","title":"6 \u2014 CI / CD Pipeline Stages","text":"Stage Tool Key checks Lint &amp; Format black / ruff / ESLint / Prettier Style compliance Test pytest / vitest 70 % coverage Build Docker buildx Multi-arch OCI image Scan Trivy + Bandit + npm-audit Security Deploy-staging kubectl / Helm Auto after dev merge + tag Manual promote CI environment Approval-gated prod release <p>Artifacts: versioned docker images tagged <code>vX.Y.Z</code> + <code>latest</code> <code>dev</code>.</p>"},{"location":"architecture/kickoff/#7-security-compliance-practices","title":"7 \u2014 Security &amp; Compliance Practices","text":"<ul> <li>Authentication \u2014 MS Entra ID (OIDC / OAuth2) + JWT validation in backend.</li> <li>Authorization \u2014 Role-based</li> <li>Transport Security \u2014 HTTPS only; TLS managed by ingress/proxy (load balancer)</li> <li>Secrets \u2014 via env vars / Vault / sealed-secrets; never in git. (.env.example allowed)</li> <li>CORS \u2014 NO CORS.</li> <li>Headers \u2014 HSTS, CSP, Referrer-Policy, X-Frame-Options, etc.</li> <li>Logs \u2014 JSON structured; ingestable by EPFL SIEM.</li> <li>Data Retention \u2014 implement retention periods (10 years / 5 years travel).</li> <li>Dependency updates \u2014 weekly Dependabot + quarterly manual review.</li> </ul>"},{"location":"architecture/kickoff/#8-testing-pyramid","title":"8 \u2014 Testing Pyramid","text":"<ol> <li>Unit tests \u2014 70 % of coverage; pure logic &amp; utils.</li> <li>Integration tests \u2014 DB, API routes (FastAPI + TestClient).</li> <li>E2E tests \u2014 Cypress; key user flows only.</li> <li>Load tests \u2014 k6 or Locust on staging before major releases.</li> </ol>"},{"location":"architecture/kickoff/#9-observability-guidelines","title":"9 \u2014 Observability Guidelines","text":"<ul> <li>Add <code>/metrics</code> endpoint (Prometheus).</li> <li>Use OpenTelemetry SDK to emit traces to collector.</li> <li>Log every request with correlation ID (X-Request-ID).</li> <li>Frontend: send analytics events (anonymised) for usage stats.</li> <li>Dashboards: latency p95, error rate, CPU / mem, job queue depth.</li> </ul>"},{"location":"architecture/kickoff/#10-performance-scalability","title":"10 \u2014 Performance &amp; Scalability","text":"Concern Practice Statelessness JWT sessions; no in-memory user state Caching Redis for factor tables + rate limiting DB pooling asyncpg pool / PgBouncer Concurrency Scale pods via HPA + CPU/mem metrics Static assets Served by CDN/efl s3 / Ingress cache layer Heavy tasks Offload to Celery workers (csv upload)"},{"location":"architecture/kickoff/#11-code-review-merge-process","title":"11 \u2014 Code Review &amp; Merge Process","text":"<ul> <li>2 reviewers minimum for backend critical code (auth, DB, security).</li> <li>CI must pass before merge.</li> <li> <p>Each PR includes:</p> </li> <li> <p>Description + screenshots (if UI)</p> </li> <li>Linked issue #</li> <li> <p>Test evidence (<code>pytest \u2013k &lt;feature&gt;</code> output OK)</p> </li> <li> <p>Post-merge: auto-deploy to staging, smoke test, then manual prod approval.</p> </li> </ul>"},{"location":"architecture/kickoff/#12-release-versioning","title":"12 \u2014 Release &amp; Versioning","text":"<ul> <li>Semantic Versioning: <code>MAJOR.MINOR.PATCH</code>.</li> <li>Release notes auto-generated from Conventional Commits.</li> <li>Tag \u2192 GitHub Release \u2192 Docker image \u2192 Manifest or Helm chart update.</li> <li>Each release validated on staging before promotion.</li> </ul>"},{"location":"architecture/kickoff/#13-documentation-knowledge-transfer","title":"13 \u2014 Documentation &amp; Knowledge Transfer","text":"Deliverable Tool / Format Developer Guide <code>/docs/developer_guide.md</code> API Docs auto-generated Swagger / ReDoc Infrastructure Docs <code>/docs/infra.md</code> + Helm values User Guide MkDocs site (deployed via CI) Training 1 workshop + 10 internal staff handover"},{"location":"architecture/kickoff/#14-next-steps-for-dev-team","title":"14 \u2014 Next Steps for Dev Team","text":"<ol> <li>Bootstrap repo using this structure.</li> <li>Configure Poetry, ESLint, black/ruff, pre-commit hooks.</li> <li>Implement minimal FastAPI endpoint <code>/health</code> + frontend ping page.</li> <li>Add OIDC login flow using enacit4r-auth.</li> <li>Create CI pipeline skeleton (GitHub Actions YAML).</li> <li>Deliver first milestone (M1): Auth + CRUD for Labs + Dashboard stub.</li> </ol>"},{"location":"architecture/spec/","title":"Spec","text":"<p>Here\u2019s a concise summary for the lead developer of what needs to be built and delivered according to the \u201cCahier des Charges \u2013 Calculateur CO2@EPFL\u201d:</p>"},{"location":"architecture/spec/#project-goal","title":"\ud83c\udfaf Project Goal","text":"<p>Develop an open-source CO2 calculator for EPFL research activities \u2014 allowing each lab to measure, visualize, and simulate its CO2 emissions. The tool must be scalable, secure, and reusable by other academic institutions.</p>"},{"location":"architecture/spec/#core-deliverables-mandate-de-base","title":"\ud83e\uddf1 Core Deliverables (Mandate de base)","text":""},{"location":"architecture/spec/#1-custom-web-application","title":"1. Custom Web Application","text":"<ul> <li>Responsive web app following EPFL IT standards and branding</li> <li>Multi-language (EN required, extensible to FR and others)</li> <li>Secure authentication via MS Entra ID (OIDC/SAML2)</li> <li>Modular, containerized architecture (deployable via Docker/registry)</li> <li>REST API (JSON, documented with OpenAPI/Swagger)</li> </ul>"},{"location":"architecture/spec/#2-main-functional-modules","title":"2. Main Functional Modules","text":"Module Purpose Mon Laboratoire Annual data input for CO2 sources D\u00e9placements professionnels Capture &amp; calculate travel emissions Infrastructure Buildings, energy use, equipment Consommation \u00e9lectrique \u00e9quipement Energy from lab devices Achats Purchases and material impacts Services internes Shared platforms and internal services Visualisation des r\u00e9sultats Dashboards, PDF/CSV exports Documentation &amp; Contact Help, support, resources Interfaces de gestion (admin) IT and business management dashboards, logs, user roles, data import"},{"location":"architecture/spec/#3-roles-access","title":"3. Roles &amp; Access","text":"<ul> <li>Gestionnaire IT</li> <li>Gestionnaire M\u00e9tier (complet / restreint)</li> <li>Utilisateur\u00b7rice principal\u00b7e</li> <li>Utilisateur\u00b7rice standard</li> </ul> <p>Access rights and views depend on role and faculty (managed via Entra ID groups).</p>"},{"location":"architecture/spec/#4-data-integration","title":"4. Data Integration","text":"<ul> <li>Manual CSV import validation</li> <li>Optional automated ingestion (e.g., lab energy data, staff database)</li> <li>Integration with EPFL Accred for user\u2013unit linkage</li> <li>Externalized logging and retention (1\u201310 years)</li> </ul>"},{"location":"architecture/spec/#5-maintenance-support","title":"5. Maintenance &amp; Support","text":"<ul> <li>Corrective &amp; preventive maintenance</li> <li>SLA-based intervention times (P1\u2013P3 priority levels)</li> <li>Annual high-load period in February (optional enhanced support)</li> <li>Regular security &amp; dependency updates, regression tests</li> </ul>"},{"location":"architecture/spec/#6-training-knowledge-transfer","title":"6. Training &amp; Knowledge Transfer","text":"<ul> <li>Documentation + training for ~10 internal staff</li> <li>EPFL takes ownership of code and operation after handover</li> </ul>"},{"location":"architecture/spec/#technical-organizational-requirements","title":"\u2699\ufe0f Technical &amp; Organizational Requirements","text":"<ul> <li>Must comply with EPFL\u2019s IT and security standards (Annexe 8)</li> <li>Follow HERMES project methodology for project management</li> <li>Code reviews by EPFL (SOLID, OWASP, test coverage required)</li> <li>Deliver within Q2 2026 (target production)</li> <li>Open-source and portable to other institutions</li> </ul>"},{"location":"architecture/spec/#optional-modules-extensions","title":"\ud83e\udde9 Optional Modules / Extensions","text":"<ul> <li>Infrastructure \u2013 direct emissions</li> <li>Achats \u2013 transport &amp; other submodules</li> <li>Impact of external cloud services</li> <li>Simulation of research projects</li> <li>AI-assisted data integration (optional)</li> <li>Additional visualization and emission models</li> </ul>"},{"location":"architecture/spec/#evaluation-weighting-for-awareness","title":"\ud83d\udcb8 Evaluation Weighting (for awareness)","text":"Criterion Weight Functional coverage 40% Price 30% Organization 10% References 10% Sustainability 5% Offer quality 5%"},{"location":"architecture-decision-records/adr-001-fastapi-backend/","title":"ADR-001: Use FastAPI for Backend Microservices","text":""},{"location":"architecture-decision-records/adr-001-fastapi-backend/#status","title":"Status","text":"<p>Accepted</p>"},{"location":"architecture-decision-records/adr-001-fastapi-backend/#context","title":"Context","text":"<p>We needed to select a Python web framework for our backend microservices that would provide:</p> <ul> <li>High performance for handling concurrent requests</li> <li>Built-in support for modern Python features (type hints, async/await)</li> <li>Automatic API documentation generation</li> <li>Easy validation of request/response data</li> <li>Good developer experience and productivity</li> </ul>"},{"location":"architecture-decision-records/adr-001-fastapi-backend/#decision","title":"Decision","text":"<p>We will use FastAPI as our primary framework for backend microservices.</p>"},{"location":"architecture-decision-records/adr-001-fastapi-backend/#rationale","title":"Rationale","text":"<p>FastAPI offers several advantages that align with our project requirements:</p> <ol> <li>Performance: Built on Starlette for ASGI compliance, FastAPI offers performance comparable to Node.js and Go</li> <li>Type Hints: Native support for Python type hints enables automatic request validation and serialization</li> <li>Automatic Documentation: Generates interactive API documentation (Swagger UI and ReDoc) from code annotations</li> <li>Pydantic Integration: Built-in data validation and settings management using Pydantic models</li> <li>Async Support: First-class support for asynchronous programming patterns</li> <li>Dependency Injection: Built-in dependency injection system simplifies testing and modularity</li> </ol> <p>Compared to alternatives like Django REST Framework or Flask:</p> <ul> <li>Django REST Framework is more opinionated and heavier for microservices</li> <li>Flask lacks built-in validation and automatic documentation features</li> </ul>"},{"location":"architecture-decision-records/adr-001-fastapi-backend/#consequences","title":"Consequences","text":""},{"location":"architecture-decision-records/adr-001-fastapi-backend/#positive","title":"Positive","text":"<ul> <li>Faster development with automatic API documentation</li> <li>Improved code quality through type hint enforcement</li> <li>Better performance than traditional Python web frameworks</li> <li>Enhanced developer experience with automatic validation</li> </ul>"},{"location":"architecture-decision-records/adr-001-fastapi-backend/#negative","title":"Negative","text":"<ul> <li>Learning curve for team members unfamiliar with FastAPI</li> <li>Relatively newer framework with smaller community compared to Django/Flask</li> <li>Dependency on Python 3.7+ features</li> </ul>"},{"location":"architecture-decision-records/adr-001-fastapi-backend/#references","title":"References","text":"<ul> <li>FastAPI Documentation</li> <li>Starlette Documentation</li> <li>Pydantic Documentation</li> </ul>"},{"location":"architecture-decision-records/adr-002-jwt-authentication/","title":"ADR-002: Adopt JWT-based Authentication","text":""},{"location":"architecture-decision-records/adr-002-jwt-authentication/#status","title":"Status","text":"<p>Accepted</p>"},{"location":"architecture-decision-records/adr-002-jwt-authentication/#context","title":"Context","text":"<p>We needed to implement an authentication mechanism for our distributed system that would:</p> <ul> <li>Support stateless authentication across multiple services</li> <li>Work well with our chosen frontend framework (Vue.js)</li> <li>Integrate with our identity provider (Microsoft Entra ID)</li> <li>Provide secure token-based authentication</li> <li>Minimize server-side session storage requirements</li> </ul>"},{"location":"architecture-decision-records/adr-002-jwt-authentication/#decision","title":"Decision","text":"<p>We will use JSON Web Tokens (JWT) for authentication across our system.</p>"},{"location":"architecture-decision-records/adr-002-jwt-authentication/#rationale","title":"Rationale","text":"<p>JWT provides several benefits for our distributed architecture:</p> <ol> <li>Stateless Authentication: JWT tokens contain all necessary user information, eliminating the need for server-side session storage</li> <li>Cross-Origin Support: Works well with SPAs and CORS scenarios</li> <li>Standard Format: Well-established standard (RFC 7519) with broad industry adoption</li> <li>Microservices Friendly: No shared session store required between services</li> <li>Mobile Ready: Suitable for mobile applications and API clients</li> <li>Integration with OIDC: Works seamlessly with OpenID Connect providers like Microsoft Entra ID</li> </ol> <p>Compared to session-based authentication:</p> <ul> <li>No server-side storage requirements for session data</li> <li>Better scalability for distributed systems</li> <li>Simpler to implement in microservices architecture</li> </ul>"},{"location":"architecture-decision-records/adr-002-jwt-authentication/#consequences","title":"Consequences","text":""},{"location":"architecture-decision-records/adr-002-jwt-authentication/#positive","title":"Positive","text":"<ul> <li>Improved scalability due to stateless nature</li> <li>Reduced server-side storage requirements</li> <li>Simplified authentication in microservices architecture</li> <li>Better support for mobile and API clients</li> <li>Industry-standard approach with good tooling support</li> </ul>"},{"location":"architecture-decision-records/adr-002-jwt-authentication/#negative","title":"Negative","text":"<ul> <li>Larger token size compared to session IDs</li> <li>Tokens cannot be easily revoked before expiration (without additional mechanisms)</li> <li>Sensitive information must not be stored in tokens</li> <li>Requires careful token expiration and refresh strategies</li> </ul>"},{"location":"architecture-decision-records/adr-002-jwt-authentication/#implementation-details","title":"Implementation Details","text":"<p>Our JWT implementation will include:</p> <ol> <li> <p>Token Types:</p> </li> <li> <p>ID Tokens: For user identification</p> </li> <li>Access Tokens: For API authorization</li> <li> <p>Refresh Tokens: For session continuity (optional)</p> </li> <li> <p>Token Validation:</p> </li> <li> <p>Signature verification using public keys from Microsoft Entra ID</p> </li> <li>Expiration checking</li> <li> <p>Audience validation</p> </li> <li> <p>Security Measures:</p> </li> <li>HTTPS-only transmission</li> <li>Secure storage in HTTP-only cookies or local storage</li> <li>Short-lived access tokens with optional refresh mechanism</li> </ol>"},{"location":"architecture-decision-records/adr-002-jwt-authentication/#references","title":"References","text":"<ul> <li>JWT.IO</li> <li>RFC 7519</li> <li>Microsoft Entra ID Documentation</li> </ul>"},{"location":"architecture-decision-records/adr-003-s3-storage/","title":"ADR-003: Store Files on S3-compatible Object Storage","text":""},{"location":"architecture-decision-records/adr-003-s3-storage/#status","title":"Status","text":"<p>Accepted</p>"},{"location":"architecture-decision-records/adr-003-s3-storage/#context","title":"Context","text":"<p>We needed a solution for storing and managing file uploads in our system that would:</p> <ul> <li>Provide scalable storage for unstructured data</li> <li>Offer high availability and durability</li> <li>Integrate well with our cloud deployment strategy</li> <li>Support direct uploads from browsers to reduce backend load</li> <li>Provide fine-grained access control</li> <li>Be cost-effective for our expected usage patterns</li> </ul>"},{"location":"architecture-decision-records/adr-003-s3-storage/#decision","title":"Decision","text":"<p>We will use S3-compatible object storage for all file storage needs.</p>"},{"location":"architecture-decision-records/adr-003-s3-storage/#rationale","title":"Rationale","text":"<p>Object storage (specifically S3-compatible) is the ideal solution for our file storage requirements:</p> <ol> <li>Scalability: Virtually unlimited storage capacity that automatically scales with demand</li> <li>Durability: Built-in redundancy and durability (99.999999999% for AWS S3)</li> <li>Cost-Effectiveness: Pay-as-you-go pricing model with multiple storage classes</li> <li>Direct Browser Uploads: Presigned URLs enable secure direct uploads from browsers</li> <li>Rich Ecosystem: Extensive tooling and SDKs for all major programming languages</li> <li>Industry Standard: Widely adopted solution with extensive documentation and community support</li> <li>Access Control: Fine-grained access control through IAM policies and presigned URLs</li> </ol> <p>Compared to alternatives:</p> <ul> <li>Storing files in the database would be inefficient and costly</li> <li>Storing files on local disk would limit scalability and availability</li> <li>Other cloud storage solutions lack the maturity and tooling of S3</li> </ul>"},{"location":"architecture-decision-records/adr-003-s3-storage/#consequences","title":"Consequences","text":""},{"location":"architecture-decision-records/adr-003-s3-storage/#positive","title":"Positive","text":"<ul> <li>Highly scalable storage solution that grows with our needs</li> <li>Reduced backend load through direct browser uploads</li> <li>Cost-effective storage with multiple pricing tiers</li> <li>High availability and durability of stored files</li> <li>Easy integration with CDNs for improved delivery performance</li> </ul>"},{"location":"architecture-decision-records/adr-003-s3-storage/#negative","title":"Negative","text":"<ul> <li>Additional complexity in managing file lifecycle and cleanup</li> <li>Potential egress costs for file downloads</li> <li>Dependency on external storage service</li> <li>Need for proper error handling for network-related issues</li> </ul>"},{"location":"architecture-decision-records/adr-003-s3-storage/#implementation-details","title":"Implementation Details","text":"<p>Our S3 implementation will include:</p> <ol> <li> <p>Storage Structure:</p> </li> <li> <p>Bucket organization by environment (dev, staging, prod)</p> </li> <li>Path-based organization for different file types</li> <li> <p>Consistent naming conventions for objects</p> </li> <li> <p>Upload Process:</p> </li> <li> <p>Backend generates presigned URLs for secure uploads</p> </li> <li>Frontend uploads directly to storage using presigned URLs</li> <li> <p>Metadata stored in database with object keys</p> </li> <li> <p>Security Measures:</p> </li> <li> <p>IAM roles with least privilege principle</p> </li> <li>Presigned URLs with limited validity period</li> <li>Server-side encryption for all objects</li> <li> <p>Access logging for audit purposes</p> </li> <li> <p>Lifecycle Management:</p> </li> <li>Automated transition to cheaper storage classes</li> <li>Deletion policies for temporary files</li> <li>Backup strategies for critical data</li> </ol>"},{"location":"architecture-decision-records/adr-003-s3-storage/#references","title":"References","text":"<ul> <li>AWS S3 Documentation</li> <li>S3 API Reference</li> <li>Presigned URLs Documentation</li> </ul>"},{"location":"architecture-decision-records/adr-004-celery-workers/","title":"ADR-004: Use Celery for Background Job Processing","text":""},{"location":"architecture-decision-records/adr-004-celery-workers/#status","title":"Status","text":"<p>Accepted</p>"},{"location":"architecture-decision-records/adr-004-celery-workers/#context","title":"Context","text":"<p>We needed a solution for handling background tasks and asynchronous processing in our system that would:</p> <ul> <li>Support distributed task execution across multiple workers</li> <li>Integrate well with our Python-based backend</li> <li>Provide reliable task queuing and execution</li> <li>Offer monitoring and management capabilities</li> <li>Scale horizontally to handle varying workloads</li> <li>Handle task retries and failure scenarios gracefully</li> </ul>"},{"location":"architecture-decision-records/adr-004-celery-workers/#decision","title":"Decision","text":"<p>We will use Celery with Redis as our distributed task queue system for background job processing.</p>"},{"location":"architecture-decision-records/adr-004-celery-workers/#rationale","title":"Rationale","text":"<p>Celery provides a robust solution for our background processing needs:</p> <ol> <li>Python Native: First-class support for Python with excellent integration</li> <li>Multiple Broker Support: Works with Redis, RabbitMQ, and other message brokers</li> <li>Distributed Execution: Tasks can be executed across multiple worker nodes</li> <li>Flexible Routing: Advanced routing capabilities for different task types</li> <li>Monitoring Tools: Built-in monitoring and management tools (Flower)</li> <li>Retry Mechanisms: Configurable retry policies with exponential backoff</li> <li>Large Community: Extensive documentation and community support</li> </ol> <p>Redis was chosen as the message broker because:</p> <ul> <li>Simple setup and operation</li> <li>Excellent performance for our expected workload</li> <li>Persistence options for task durability</li> <li>Pub/Sub capabilities for real-time features</li> </ul> <p>Compared to alternatives:</p> <ul> <li>RQ is simpler but less feature-rich</li> <li>Custom solutions would require significant development effort</li> <li>Other queue systems (like RabbitMQ) are more complex to operate</li> </ul>"},{"location":"architecture-decision-records/adr-004-celery-workers/#consequences","title":"Consequences","text":""},{"location":"architecture-decision-records/adr-004-celery-workers/#positive","title":"Positive","text":"<ul> <li>Reliable distributed task processing</li> <li>Horizontal scalability for background jobs</li> <li>Built-in monitoring and management</li> <li>Flexible task scheduling options</li> <li>Graceful handling of failures and retries</li> </ul>"},{"location":"architecture-decision-records/adr-004-celery-workers/#negative","title":"Negative","text":"<ul> <li>Additional infrastructure component (Redis)</li> <li>Learning curve for team members</li> <li>Potential for increased complexity in debugging</li> <li>Need for proper monitoring and alerting</li> </ul>"},{"location":"architecture-decision-records/adr-004-celery-workers/#implementation-details","title":"Implementation Details","text":"<p>Our Celery implementation will include:</p> <ol> <li> <p>Task Organization:</p> </li> <li> <p>Separate modules for different task types</p> </li> <li>Consistent naming conventions for tasks</li> <li> <p>Clear separation between task definitions and business logic</p> </li> <li> <p>Worker Configuration:</p> </li> <li> <p>Dedicated worker processes for different task priorities</p> </li> <li>Proper resource allocation and limits</li> <li> <p>Supervision and auto-restart mechanisms</p> </li> <li> <p>Monitoring:</p> </li> <li> <p>Flower for real-time monitoring</p> </li> <li>Custom metrics for task performance</li> <li> <p>Alerting for failed tasks and queue backlogs</p> </li> <li> <p>Error Handling:</p> </li> <li>Comprehensive logging for task execution</li> <li>Configurable retry policies</li> <li>Dead letter queue for repeatedly failing tasks</li> </ol>"},{"location":"architecture-decision-records/adr-004-celery-workers/#references","title":"References","text":"<ul> <li>Celery Documentation</li> <li>Redis Documentation</li> <li>Flower Monitoring Tool</li> </ul>"},{"location":"architecture-decision-records/adr-005-rbac-implementation/","title":"ADR-005: Implement Role-Based Access Control (RBAC)","text":""},{"location":"architecture-decision-records/adr-005-rbac-implementation/#status","title":"Status","text":"<p>Accepted</p>"},{"location":"architecture-decision-records/adr-005-rbac-implementation/#context","title":"Context","text":"<p>We needed to implement an authorization system that would:</p> <ul> <li>Provide fine-grained access control to system resources</li> <li>Integrate with our authentication system (Microsoft Entra ID)</li> <li>Support different user roles with varying permissions</li> <li>Be easily maintainable and auditable</li> <li>Scale with our growing user base and feature set</li> <li>Comply with security best practices</li> </ul>"},{"location":"architecture-decision-records/adr-005-rbac-implementation/#decision","title":"Decision","text":"<p>We will implement Role-Based Access Control (RBAC) as our authorization model.</p>"},{"location":"architecture-decision-records/adr-005-rbac-implementation/#rationale","title":"Rationale","text":"<p>RBAC is well-suited for our requirements:</p> <ol> <li>Simplified Management: Roles aggregate permissions, making it easier to manage access rights</li> <li>Scalability: Efficiently handles growing numbers of users and resources</li> <li>Auditability: Clear mapping between roles and permissions facilitates compliance</li> <li>Industry Standard: Widely adopted approach with established best practices</li> <li>Integration Friendly: Works well with Microsoft Entra ID and JWT tokens</li> <li>Flexibility: Supports both role hierarchies and permission inheritance</li> </ol> <p>Compared to alternatives:</p> <ul> <li>Discretionary Access Control (DAC) is too permissive and difficult to manage</li> <li>Attribute-Based Access Control (ABAC) is more complex than needed for our current requirements</li> <li>Mandatory Access Control (MAC) is overly restrictive for our use case</li> </ul>"},{"location":"architecture-decision-records/adr-005-rbac-implementation/#consequences","title":"Consequences","text":""},{"location":"architecture-decision-records/adr-005-rbac-implementation/#positive","title":"Positive","text":"<ul> <li>Clear separation of duties through role definitions</li> <li>Simplified user permission management</li> <li>Better compliance with security policies</li> <li>Reduced administrative overhead</li> <li>Consistent access control across the system</li> </ul>"},{"location":"architecture-decision-records/adr-005-rbac-implementation/#negative","title":"Negative","text":"<ul> <li>Initial setup effort to define roles and permissions</li> <li>Potential for role explosion if not carefully managed</li> <li>Need for regular role reviews and maintenance</li> <li>Possible over-provisioning if roles are too broad</li> </ul>"},{"location":"architecture-decision-records/adr-005-rbac-implementation/#implementation-details","title":"Implementation Details","text":"<p>Our RBAC implementation will include:</p> <ol> <li> <p>Role Definitions:</p> </li> <li> <p>Predefined roles (Admin, Editor, Viewer, etc.)</p> </li> <li>Role hierarchy where appropriate</li> <li> <p>Clear documentation of role responsibilities</p> </li> <li> <p>Permission Model:</p> </li> <li> <p>Resource-based permissions (read, write, delete)</p> </li> <li>Action-based permissions (approve, reject, publish)</li> <li> <p>Context-aware permissions where needed</p> </li> <li> <p>Integration Points:</p> </li> <li> <p>Microsoft Entra ID groups mapped to application roles</p> </li> <li>JWT claims containing role information</li> <li> <p>Middleware for role-based access control in APIs</p> </li> <li> <p>Authorization Checks:</p> </li> <li> <p>Decorators/functions for protecting views and endpoints</p> </li> <li>Centralized policy evaluation</li> <li> <p>Audit logging for access attempts</p> </li> <li> <p>Management Interface:</p> </li> <li>Admin interface for role assignment</li> <li>Self-service role requests where appropriate</li> <li>Approval workflows for sensitive roles</li> </ol>"},{"location":"architecture-decision-records/adr-005-rbac-implementation/#references","title":"References","text":"<ul> <li>NIST RBAC Model</li> <li>Microsoft Entra ID Roles</li> <li>OWASP Access Control Cheat Sheet</li> </ul>"},{"location":"backend/","title":"Backend Overview","text":"<p>This section provides an overview of the backend layer architecture, technologies, and integration points.</p>"},{"location":"backend/#architecture-pattern","title":"Architecture Pattern","text":"<ul> <li>Framework: FastAPI (Python)</li> <li>Database: PostgreSQL with SQLAlchemy ORM</li> <li>Background Tasks: Celery with Redis</li> <li>Authentication: OAuth2 with OIDC integration</li> <li>API Documentation: OpenAPI (Swagger/UI)</li> </ul>"},{"location":"backend/#main-technologies","title":"Main Technologies","text":"<ul> <li>FastAPI for REST API implementation</li> <li>PostgreSQL for relational data storage</li> <li>SQLAlchemy for ORM and database migrations</li> <li>Celery for asynchronous task processing</li> <li>Redis for caching and task queues</li> <li>Pydantic for data validation and serialization</li> </ul>"},{"location":"backend/#api-interface","title":"API Interface","text":"<p>The backend exposes a RESTful API for frontend consumption:</p> <ul> <li>Base URL: <code>/api/v1/</code></li> <li>Authentication: Bearer token in Authorization header</li> <li>Content Type: JSON for requests and responses</li> <li>Error Handling: Standard HTTP status codes with JSON error bodies</li> </ul>"},{"location":"backend/#integration-points","title":"Integration Points","text":"<ul> <li>Database: PostgreSQL for persistent storage</li> <li>Cache: Redis for caching and session storage</li> <li>Message Broker: Redis for Celery task queue</li> <li>Authentication Service: Microsoft Entra ID (OIDC)</li> <li>File Storage: S3-compatible storage for file uploads</li> <li>Monitoring: Prometheus and OpenTelemetry for metrics and tracing</li> </ul>"},{"location":"backend/#subsystems","title":"Subsystems","text":"<ul> <li>Architecture - Detailed backend architecture</li> <li>API Design - API endpoints and contracts</li> <li>Plugins/Extensions - Extension mechanisms</li> <li>Testing - Testing strategies and tools</li> <li>Deployment - Deployment processes and considerations</li> </ul> <p>For architectural overview, see Architecture Overview.</p>"},{"location":"backend/api/","title":"Backend API Design","text":"<p>This document describes the API endpoints, contracts, and design principles for the backend application.</p>"},{"location":"backend/api/#api-design-principles","title":"API Design Principles","text":"<p>TODO: Document API design guidelines</p>"},{"location":"backend/api/#restful-design","title":"RESTful Design","text":"<ul> <li>Resource-oriented URLs</li> <li>Standard HTTP methods</li> <li>Proper status codes</li> <li>Consistent error responses</li> </ul>"},{"location":"backend/api/#versioning-strategy","title":"Versioning Strategy","text":"<ul> <li>Path-based versioning (<code>/api/v1/</code>)</li> <li>Backward compatibility</li> <li>Deprecation policy</li> <li>Migration guides</li> </ul>"},{"location":"backend/api/#data-formats","title":"Data Formats","text":"<ul> <li>JSON for request/response bodies</li> <li>Standard datetime formats</li> <li>Enum representations</li> <li>Pagination standards</li> </ul>"},{"location":"backend/api/#authentication-and-authorization","title":"Authentication and Authorization","text":"<p>TODO: Document API security</p>"},{"location":"backend/api/#authentication","title":"Authentication","text":"<ul> <li>Bearer token in Authorization header</li> <li>Token validation and refresh</li> <li>Session timeout handling</li> <li>Anonymous access restrictions</li> </ul>"},{"location":"backend/api/#authorization","title":"Authorization","text":"<ul> <li>Role-based access control</li> <li>Resource-level permissions</li> <li>Permission inheritance</li> <li>Audit trail</li> </ul>"},{"location":"backend/api/#core-endpoints","title":"Core Endpoints","text":"<p>TODO: Document primary API endpoints</p>"},{"location":"backend/api/#authentication-endpoints","title":"Authentication Endpoints","text":"<ul> <li><code>POST /auth/login</code> - OIDC initiation</li> <li><code>POST /auth/logout</code> - Session termination</li> <li><code>POST /auth/refresh</code> - Token renewal</li> </ul>"},{"location":"backend/api/#user-management","title":"User Management","text":"<ul> <li><code>GET /users/me</code> - Current user profile</li> <li><code>GET /users/{id}</code> - Specific user details</li> <li><code>PUT /users/{id}</code> - Update user profile</li> </ul>"},{"location":"backend/api/#laboratory-management","title":"Laboratory Management","text":"<ul> <li><code>GET /labs</code> - List laboratories</li> <li><code>POST /labs</code> - Create laboratory</li> <li><code>GET /labs/{id}</code> - Laboratory details</li> <li><code>PUT /labs/{id}</code> - Update laboratory</li> <li><code>DELETE /labs/{id}</code> - Delete laboratory</li> </ul>"},{"location":"backend/api/#data-import","title":"Data Import","text":"<ul> <li><code>POST /labs/{id}/imports</code> - Initiate import</li> <li><code>GET /imports/{id}/status</code> - Check import status</li> <li><code>GET /imports/{id}/rows</code> - Get import rows</li> </ul>"},{"location":"backend/api/#reporting","title":"Reporting","text":"<ul> <li><code>GET /reports/{lab_id}</code> - Get laboratory report</li> <li><code>GET /reports/summary</code> - Get summary report</li> </ul>"},{"location":"backend/api/#administration","title":"Administration","text":"<ul> <li><code>GET /admin/users</code> - List users</li> <li><code>POST /admin/users</code> - Create user</li> <li><code>GET /admin/factors</code> - List emission factors</li> <li><code>POST /admin/factors</code> - Create emission factor</li> </ul>"},{"location":"backend/api/#request-and-response-examples","title":"Request and Response Examples","text":"<p>TODO: Provide example requests and responses</p>"},{"location":"backend/api/#successful-response","title":"Successful Response","text":"<pre><code>{\n  \"data\": {},\n  \"meta\": {}\n}\n</code></pre>"},{"location":"backend/api/#error-response","title":"Error Response","text":"<pre><code>{\n  \"error\": {\n    \"code\": \"VALIDATION_ERROR\",\n    \"message\": \"Invalid input data\",\n    \"details\": []\n  }\n}\n</code></pre>"},{"location":"backend/api/#rate-limiting-and-throttling","title":"Rate Limiting and Throttling","text":"<p>TODO: Document API limits</p>"},{"location":"backend/api/#limits","title":"Limits","text":"<ul> <li>Requests per minute</li> <li>Burst capacity</li> <li>Per-user limits</li> <li>Per-endpoint limits</li> </ul>"},{"location":"backend/api/#response-headers","title":"Response Headers","text":"<ul> <li><code>RateLimit-Limit</code></li> <li><code>RateLimit-Remaining</code></li> <li><code>RateLimit-Reset</code></li> </ul>"},{"location":"backend/api/#api-documentation","title":"API Documentation","text":"<p>TODO: Document API documentation tools</p>"},{"location":"backend/api/#openapi-specification","title":"OpenAPI Specification","text":"<ul> <li>Auto-generated documentation</li> <li>Interactive API explorer</li> <li>Schema validation</li> <li>Client SDK generation</li> </ul> <p>For implementation details, see Backend Architecture.</p>"},{"location":"backend/architecture/","title":"Backend Architecture","text":"<p>This document describes the detailed architecture of the backend application.</p>"},{"location":"backend/architecture/#system-architecture","title":"System Architecture","text":"<p>TODO: Document the backend system architecture</p>"},{"location":"backend/architecture/#module-structure","title":"Module Structure","text":"<ul> <li>Modular monolith organization</li> <li>Module responsibilities and boundaries</li> <li>Inter-module communication</li> <li>Shared libraries and utilities</li> </ul>"},{"location":"backend/architecture/#data-flow","title":"Data Flow","text":"<ul> <li>Request processing pipeline</li> <li>Authentication and authorization</li> <li>Business logic execution</li> <li>Data persistence</li> <li>Response generation</li> </ul>"},{"location":"backend/architecture/#database-design","title":"Database Design","text":"<p>TODO: Document the database architecture</p>"},{"location":"backend/architecture/#orm-layer","title":"ORM Layer","text":"<ul> <li>SQLAlchemy models</li> <li>Session management</li> <li>Query optimization</li> <li>Relationship handling</li> </ul>"},{"location":"backend/architecture/#migration-strategy","title":"Migration Strategy","text":"<ul> <li>Alembic for database migrations</li> <li>Migration naming conventions</li> <li>Version control integration</li> <li>Rollback procedures</li> </ul>"},{"location":"backend/architecture/#background-processing","title":"Background Processing","text":"<p>TODO: Document asynchronous task processing</p>"},{"location":"backend/architecture/#celery-architecture","title":"Celery Architecture","text":"<ul> <li>Task definition and registration</li> <li>Worker configuration</li> <li>Queue management</li> <li>Result storage</li> </ul>"},{"location":"backend/architecture/#task-patterns","title":"Task Patterns","text":"<ul> <li>Immediate execution tasks</li> <li>Scheduled tasks</li> <li>Retry mechanisms</li> <li>Error handling</li> </ul>"},{"location":"backend/architecture/#security-implementation","title":"Security Implementation","text":"<p>TODO: Document backend security measures</p>"},{"location":"backend/architecture/#authentication","title":"Authentication","text":"<ul> <li>OIDC token validation</li> <li>Claim extraction and mapping</li> <li>Session management</li> <li>Token refresh handling</li> </ul>"},{"location":"backend/architecture/#authorization","title":"Authorization","text":"<ul> <li>Permission checking</li> <li>Role-based access control</li> <li>Resource-level permissions</li> <li>Audit logging</li> </ul>"},{"location":"backend/architecture/#caching-strategy","title":"Caching Strategy","text":"<p>TODO: Document caching approaches</p>"},{"location":"backend/architecture/#redis-usage","title":"Redis Usage","text":"<ul> <li>Cache key design</li> <li>Expiration policies</li> <li>Memory management</li> <li>Cluster configuration</li> </ul>"},{"location":"backend/architecture/#cache-patterns","title":"Cache Patterns","text":"<ul> <li>Read-through caching</li> <li>Write-through caching</li> <li>Cache invalidation</li> <li>Fallback mechanisms</li> </ul>"},{"location":"backend/architecture/#error-handling","title":"Error Handling","text":"<p>TODO: Document error handling patterns</p>"},{"location":"backend/architecture/#exception-hierarchy","title":"Exception Hierarchy","text":"<ul> <li>Custom exception types</li> <li>Error code standardization</li> <li>Logging integration</li> <li>User-facing error messages</li> </ul>"},{"location":"backend/architecture/#recovery-strategies","title":"Recovery Strategies","text":"<ul> <li>Graceful degradation</li> <li>Circuit breaker patterns</li> <li>Fallback responses</li> <li>Retry mechanisms</li> </ul> <p>For API specifications, see API Design.</p>"},{"location":"backend/deploy/","title":"Backend Deployment","text":"<p>This document describes the deployment processes and considerations for the backend application.</p>"},{"location":"backend/deploy/#deployment-architecture","title":"Deployment Architecture","text":"<p>TODO: Document the backend deployment architecture</p>"},{"location":"backend/deploy/#containerization","title":"Containerization","text":"<ul> <li>Docker image creation</li> <li>Multi-stage builds</li> <li>Security hardening</li> <li>Base image selection</li> </ul>"},{"location":"backend/deploy/#orchestration","title":"Orchestration","text":"<ul> <li>Kubernetes deployment manifests</li> <li>Helm chart configuration</li> <li>Service discovery</li> <li>Load balancing</li> </ul>"},{"location":"backend/deploy/#runtime-environment","title":"Runtime Environment","text":"<ul> <li>Python runtime version</li> <li>Dependency management</li> <li>Environment variables</li> <li>Configuration files</li> </ul>"},{"location":"backend/deploy/#deployment-process","title":"Deployment Process","text":"<p>TODO: Document the deployment workflow</p>"},{"location":"backend/deploy/#build-pipeline","title":"Build Pipeline","text":"<ul> <li>Source code checkout</li> <li>Dependency installation</li> <li>Security scanning</li> <li>Image building</li> <li>Image pushing to registry</li> </ul>"},{"location":"backend/deploy/#release-process","title":"Release Process","text":"<ul> <li>Version tagging</li> <li>Changelog generation</li> <li>Release notes creation</li> <li>Artifact promotion</li> </ul>"},{"location":"backend/deploy/#deployment-strategies","title":"Deployment Strategies","text":"<ul> <li>Blue-green deployments</li> <li>Canary releases</li> <li>Rolling updates</li> <li>Feature flags</li> </ul>"},{"location":"backend/deploy/#environment-configuration","title":"Environment Configuration","text":"<p>TODO: Document environment-specific configurations</p>"},{"location":"backend/deploy/#configuration-management","title":"Configuration Management","text":"<ul> <li>Environment variables</li> <li>Configuration files</li> <li>Secret management</li> <li>Feature flags</li> </ul>"},{"location":"backend/deploy/#database-configuration","title":"Database Configuration","text":"<ul> <li>Connection pooling</li> <li>Migration execution</li> <li>Backup configuration</li> <li>Replication settings</li> </ul>"},{"location":"backend/deploy/#external-service-configuration","title":"External Service Configuration","text":"<ul> <li>API endpoints</li> <li>Authentication credentials</li> <li>Timeout settings</li> <li>Retry configurations</li> </ul>"},{"location":"backend/deploy/#scaling-and-performance","title":"Scaling and Performance","text":"<p>TODO: Document scaling considerations</p>"},{"location":"backend/deploy/#horizontal-scaling","title":"Horizontal Scaling","text":"<ul> <li>Pod replica management</li> <li>Auto-scaling policies</li> <li>Resource limits and requests</li> <li>Load distribution</li> </ul>"},{"location":"backend/deploy/#vertical-scaling","title":"Vertical Scaling","text":"<ul> <li>Resource allocation</li> <li>Performance tuning</li> <li>Memory optimization</li> <li>CPU optimization</li> </ul>"},{"location":"backend/deploy/#database-scaling","title":"Database Scaling","text":"<ul> <li>Connection pooling</li> <li>Read replicas</li> <li>Sharding strategies</li> <li>Caching layers</li> </ul>"},{"location":"backend/deploy/#monitoring-and-observability","title":"Monitoring and Observability","text":"<p>TODO: Document monitoring setup</p>"},{"location":"backend/deploy/#health-checks","title":"Health Checks","text":"<ul> <li>Liveness probes</li> <li>Readiness probes</li> <li>Startup probes</li> <li>Custom health endpoints</li> </ul>"},{"location":"backend/deploy/#metrics-collection","title":"Metrics Collection","text":"<ul> <li>Prometheus integration</li> <li>Custom metrics</li> <li>Resource utilization</li> <li>Business metrics</li> </ul>"},{"location":"backend/deploy/#logging","title":"Logging","text":"<ul> <li>Structured logging</li> <li>Log levels</li> <li>Log aggregation</li> <li>Log retention</li> </ul>"},{"location":"backend/deploy/#tracing","title":"Tracing","text":"<ul> <li>OpenTelemetry integration</li> <li>Distributed tracing</li> <li>Span correlation</li> <li>Performance analysis</li> </ul>"},{"location":"backend/deploy/#security-considerations","title":"Security Considerations","text":"<p>TODO: Document security measures</p>"},{"location":"backend/deploy/#network-security","title":"Network Security","text":"<ul> <li>Service mesh integration</li> <li>Network policies</li> <li>Ingress configuration</li> <li>TLS termination</li> </ul>"},{"location":"backend/deploy/#application-security","title":"Application Security","text":"<ul> <li>Input validation</li> <li>Output encoding</li> <li>Authentication enforcement</li> <li>Authorization checks</li> </ul>"},{"location":"backend/deploy/#data-security","title":"Data Security","text":"<ul> <li>Encryption at rest</li> <li>Encryption in transit</li> <li>Data masking</li> <li>Access controls</li> </ul>"},{"location":"backend/deploy/#backup-and-disaster-recovery","title":"Backup and Disaster Recovery","text":"<p>TODO: Document backup strategies</p>"},{"location":"backend/deploy/#data-backup","title":"Data Backup","text":"<ul> <li>Database backup schedules</li> <li>Backup retention policies</li> <li>Backup validation</li> <li>Point-in-time recovery</li> </ul>"},{"location":"backend/deploy/#configuration-backup","title":"Configuration Backup","text":"<ul> <li>Configuration versioning</li> <li>Secret backup</li> <li>Deployment manifest backup</li> <li>Recovery procedures</li> </ul>"},{"location":"backend/deploy/#disaster-recovery","title":"Disaster Recovery","text":"<ul> <li>Recovery time objectives</li> <li>Recovery point objectives</li> <li>Failover procedures</li> <li>Testing schedules</li> </ul> <p>For CI/CD pipeline overview, see Architecture CI/CD Pipeline.</p>"},{"location":"backend/plugins/","title":"Backend Plugins and Extensions","text":"<p>This document describes the plugin system and extension mechanisms for the backend application.</p>"},{"location":"backend/plugins/#plugin-architecture","title":"Plugin Architecture","text":"<p>TODO: Document the plugin system design</p>"},{"location":"backend/plugins/#extension-points","title":"Extension Points","text":"<ul> <li>Data import processors</li> <li>Emission calculation engines</li> <li>Report generators</li> <li>Authentication providers</li> <li>Notification channels</li> </ul>"},{"location":"backend/plugins/#plugin-interface","title":"Plugin Interface","text":"<ul> <li>Standard plugin base class</li> <li>Lifecycle hooks</li> <li>Configuration management</li> <li>Dependency injection</li> </ul>"},{"location":"backend/plugins/#csv-import-pipeline","title":"CSV Import Pipeline","text":"<p>TODO: Document the CSV import system</p>"},{"location":"backend/plugins/#upload-flow","title":"Upload Flow","text":"<ol> <li>Client requests signed upload URL</li> <li>Backend creates import job record</li> <li>Client uploads directly to storage</li> <li>Storage triggers processing workflow</li> </ol>"},{"location":"backend/plugins/#processing-workflow","title":"Processing Workflow","text":"<ul> <li>File validation and quarantine</li> <li>Streaming CSV parsing</li> <li>Row-level validation</li> <li>Data transformation</li> <li>Database persistence</li> <li>Status updates and notifications</li> </ul>"},{"location":"backend/plugins/#validation-rules","title":"Validation Rules","text":"<ul> <li>Required column checks</li> <li>Data type validation</li> <li>Business rule enforcement</li> <li>Cross-field validation</li> </ul>"},{"location":"backend/plugins/#error-handling","title":"Error Handling","text":"<ul> <li>Quarantine mechanism for invalid files</li> <li>Row-level error reporting</li> <li>Retry strategies</li> <li>Manual intervention procedures</li> </ul>"},{"location":"backend/plugins/#emission-calculation-engine","title":"Emission Calculation Engine","text":"<p>TODO: Document the emission calculation system</p>"},{"location":"backend/plugins/#factor-model","title":"Factor Model","text":"<ul> <li>Abstract factor interface</li> <li>Concrete factor implementations</li> <li>Metadata management</li> <li>Validity periods</li> </ul>"},{"location":"backend/plugins/#calculation-pipeline","title":"Calculation Pipeline","text":"<ul> <li>Activity data ingestion</li> <li>Factor lookup and selection</li> <li>Emission computation</li> <li>Result aggregation</li> <li>Report generation</li> </ul>"},{"location":"backend/plugins/#extensibility","title":"Extensibility","text":"<ul> <li>Adding new activity types</li> <li>Custom calculation algorithms</li> <li>External factor sources</li> <li>Unit conversion utilities</li> </ul>"},{"location":"backend/plugins/#report-generation","title":"Report Generation","text":"<p>TODO: Document the reporting system</p>"},{"location":"backend/plugins/#report-types","title":"Report Types","text":"<ul> <li>Laboratory summary reports</li> <li>Departmental aggregations</li> <li>Comparative analyses</li> <li>Trend visualizations</li> </ul>"},{"location":"backend/plugins/#template-system","title":"Template System","text":"<ul> <li>Report template definition</li> <li>Data binding mechanisms</li> <li>Formatting options</li> <li>Export formats</li> </ul>"},{"location":"backend/plugins/#scheduling","title":"Scheduling","text":"<ul> <li>Automated report generation</li> <li>Recurring schedules</li> <li>Trigger conditions</li> <li>Delivery mechanisms</li> </ul>"},{"location":"backend/plugins/#custom-authentication-providers","title":"Custom Authentication Providers","text":"<p>TODO: Document authentication extensibility</p>"},{"location":"backend/plugins/#provider-interface","title":"Provider Interface","text":"<ul> <li>Standard authentication interface</li> <li>User mapping strategies</li> <li>Group/role synchronization</li> <li>Session management</li> </ul>"},{"location":"backend/plugins/#implementation-examples","title":"Implementation Examples","text":"<ul> <li>OIDC provider integration</li> <li>LDAP connector</li> <li>Custom database authentication</li> <li>External API authentication</li> </ul> <p>For API integration details, see API Design.</p>"},{"location":"backend/testing/","title":"Backend Testing","text":"<p>This document outlines the testing strategies, tools, and practices for the backend application.</p>"},{"location":"backend/testing/#testing-strategy","title":"Testing Strategy","text":"<p>TODO: Document the overall testing approach</p>"},{"location":"backend/testing/#test-types","title":"Test Types","text":"<ul> <li>Unit tests for individual functions and classes</li> <li>Integration tests for module interactions</li> <li>API tests for endpoint validation</li> <li>Contract tests for external integrations</li> <li>Performance tests for load handling</li> </ul>"},{"location":"backend/testing/#test-pyramid","title":"Test Pyramid","text":"<ul> <li>Majority of tests: Unit tests</li> <li>Significant integration tests</li> <li>Selective API tests</li> <li>Fewer contract and performance tests</li> </ul>"},{"location":"backend/testing/#unit-testing","title":"Unit Testing","text":"<p>TODO: Document unit testing practices</p>"},{"location":"backend/testing/#test-framework","title":"Test Framework","text":"<ul> <li>pytest as the primary test framework</li> <li>pytest-cov for coverage reporting</li> <li>pytest-mock for mocking dependencies</li> <li>Factory Boy for test data generation</li> </ul>"},{"location":"backend/testing/#database-testing","title":"Database Testing","text":"<ul> <li>In-memory SQLite for fast tests</li> <li>SQLAlchemy for ORM testing</li> <li>Fixture management</li> <li>Transaction rollback strategies</li> </ul>"},{"location":"backend/testing/#service-layer-testing","title":"Service Layer Testing","text":"<ul> <li>Business logic validation</li> <li>Error condition testing</li> <li>Edge case coverage</li> <li>Mock external dependencies</li> </ul>"},{"location":"backend/testing/#utility-function-testing","title":"Utility Function Testing","text":"<ul> <li>Pure function testing</li> <li>Validation function testing</li> <li>Helper method testing</li> <li>Algorithm verification</li> </ul>"},{"location":"backend/testing/#integration-testing","title":"Integration Testing","text":"<p>TODO: Document integration testing practices</p>"},{"location":"backend/testing/#database-integration","title":"Database Integration","text":"<ul> <li>PostgreSQL in Docker for realistic testing</li> <li>Migration testing</li> <li>Relationship testing</li> <li>Performance scenario testing</li> </ul>"},{"location":"backend/testing/#external-service-integration","title":"External Service Integration","text":"<ul> <li>Mocked API responses</li> <li>Redis integration testing</li> <li>Storage service testing</li> <li>Authentication service testing</li> </ul>"},{"location":"backend/testing/#module-integration","title":"Module Integration","text":"<ul> <li>Cross-module data flow</li> <li>Shared component usage</li> <li>Configuration integration</li> <li>Error propagation</li> </ul>"},{"location":"backend/testing/#api-testing","title":"API Testing","text":"<p>TODO: Document API testing practices</p>"},{"location":"backend/testing/#endpoint-validation","title":"Endpoint Validation","text":"<ul> <li>HTTP method testing</li> <li>Parameter validation</li> <li>Response format verification</li> <li>Status code correctness</li> </ul>"},{"location":"backend/testing/#authentication-testing","title":"Authentication Testing","text":"<ul> <li>Protected endpoint access</li> <li>Token validation</li> <li>Permission enforcement</li> <li>Session management</li> </ul>"},{"location":"backend/testing/#data-integrity","title":"Data Integrity","text":"<ul> <li>CRUD operation validation</li> <li>Data consistency checks</li> <li>Concurrency testing</li> <li>Rollback verification</li> </ul>"},{"location":"backend/testing/#contract-testing","title":"Contract Testing","text":"<p>TODO: Document contract testing practices</p>"},{"location":"backend/testing/#external-api-contracts","title":"External API Contracts","text":"<ul> <li>OIDC provider integration</li> <li>Storage service contracts</li> <li>Notification service contracts</li> <li>Payment gateway contracts</li> </ul>"},{"location":"backend/testing/#data-format-validation","title":"Data Format Validation","text":"<ul> <li>JSON schema validation</li> <li>XML format validation</li> <li>CSV format validation</li> <li>Binary data validation</li> </ul>"},{"location":"backend/testing/#performance-testing","title":"Performance Testing","text":"<p>TODO: Document performance testing practices</p>"},{"location":"backend/testing/#load-testing","title":"Load Testing","text":"<ul> <li>Concurrent user simulation</li> <li>Request rate testing</li> <li>Resource utilization monitoring</li> <li>Bottleneck identification</li> </ul>"},{"location":"backend/testing/#stress-testing","title":"Stress Testing","text":"<ul> <li>Maximum capacity determination</li> <li>Failure point identification</li> <li>Recovery testing</li> <li>Degradation analysis</li> </ul>"},{"location":"backend/testing/#scalability-testing","title":"Scalability Testing","text":"<ul> <li>Horizontal scaling validation</li> <li>Database performance under load</li> <li>Cache effectiveness</li> <li>Network latency impact</li> </ul>"},{"location":"backend/testing/#test-data-management","title":"Test Data Management","text":"<p>TODO: Document test data strategies</p>"},{"location":"backend/testing/#data-generation","title":"Data Generation","text":"<ul> <li>Synthetic data creation</li> <li>Realistic data anonymization</li> <li>Edge case data</li> <li>Volume data sets</li> </ul>"},{"location":"backend/testing/#data-seeding","title":"Data Seeding","text":"<ul> <li>Database initialization</li> <li>Pre-population strategies</li> <li>Environment-specific data</li> <li>Cleanup procedures</li> </ul>"},{"location":"backend/testing/#continuous-integration","title":"Continuous Integration","text":"<p>TODO: Document CI testing integration</p>"},{"location":"backend/testing/#github-actions-workflow","title":"GitHub Actions Workflow","text":"<ul> <li>Test execution on pull requests</li> <li>Coverage reporting</li> <li>Performance benchmarking</li> <li>Security scanning</li> </ul>"},{"location":"backend/testing/#quality-gates","title":"Quality Gates","text":"<ul> <li>Minimum coverage thresholds</li> <li>Performance regression detection</li> <li>Security vulnerability scanning</li> <li>Code quality checks</li> </ul> <p>For development setup, see the Frontend Development Guide for frontend development or check specific backend component documentation.</p>"},{"location":"database/","title":"Database Overview","text":"<p>This section provides an overview of the database layer, including the technology choices, access patterns, and management strategies.</p>"},{"location":"database/#database-technology","title":"Database Technology","text":"<ul> <li>Engine: PostgreSQL</li> <li>ORM: SQLAlchemy</li> <li>Migration Tool: Alembic</li> <li>Connection Pooling: Built-in PostgreSQL pooling or PgBouncer</li> <li>Backup Solution: pg_dump with cloud storage integration</li> </ul>"},{"location":"database/#key-characteristics","title":"Key Characteristics","text":"<ul> <li>ACID compliance for data integrity</li> <li>JSONB support for flexible data structures</li> <li>Advanced indexing capabilities</li> <li>Robust transaction support</li> <li>Extensive extension ecosystem</li> </ul>"},{"location":"database/#integration-points","title":"Integration Points","text":"<ul> <li>Backend Application: Direct connection through SQLAlchemy</li> <li>Migration System: Alembic for schema versioning</li> <li>Backup System: Automated backup scripts</li> <li>Monitoring: PostgreSQL statistics and custom metrics</li> <li>Admin Tools: pgAdmin, psql, custom admin interfaces</li> </ul>"},{"location":"database/#subsystems","title":"Subsystems","text":"<ul> <li>Schema - Database schema and entity relationships</li> <li>Data Flows - How data moves through the system</li> <li>Migrations - Schema evolution and versioning</li> <li>Maintenance - Backup, recovery, and routine tasks</li> </ul> <p>For architectural overview, see Architecture Overview.</p>"},{"location":"database/data-flows/","title":"Database Data Flows","text":"<p>This document describes how data moves through the system, including ingestion, processing, and retrieval patterns.</p>"},{"location":"database/data-flows/#data-ingestion","title":"Data Ingestion","text":"<p>TODO: Document data ingestion processes</p>"},{"location":"database/data-flows/#user-data","title":"User Data","text":"<ul> <li>User registration and profile creation</li> <li>Authentication and session data</li> <li>Profile updates and modifications</li> <li>User role and permission assignments</li> </ul>"},{"location":"database/data-flows/#laboratory-data","title":"Laboratory Data","text":"<ul> <li>Laboratory creation and setup</li> <li>Laboratory metadata updates</li> <li>Laboratory access control</li> <li>Laboratory deletion and archiving</li> </ul>"},{"location":"database/data-flows/#import-data","title":"Import Data","text":"<ul> <li>CSV file upload initiation</li> <li>File validation and quarantine</li> <li>Streaming data processing</li> <li>Row-level validation and error handling</li> <li>Data transformation and normalization</li> <li>Database insertion and status updates</li> </ul>"},{"location":"database/data-flows/#emission-factor-data","title":"Emission Factor Data","text":"<ul> <li>Factor creation and updates</li> <li>Factor validity periods</li> <li>Factor categorization and tagging</li> <li>Bulk factor imports</li> </ul>"},{"location":"database/data-flows/#activity-data","title":"Activity Data","text":"<ul> <li>Activity record creation</li> <li>Emission calculations</li> <li>Activity metadata storage</li> <li>Activity updates and corrections</li> </ul>"},{"location":"database/data-flows/#data-processing","title":"Data Processing","text":"<p>TODO: Document data processing workflows</p>"},{"location":"database/data-flows/#batch-processing","title":"Batch Processing","text":"<ul> <li>Scheduled data aggregation</li> <li>Report generation workflows</li> <li>Data cleanup and archiving</li> <li>Statistical analysis computations</li> </ul>"},{"location":"database/data-flows/#real-time-processing","title":"Real-time Processing","text":"<ul> <li>Immediate data validation</li> <li>Real-time emission calculations</li> <li>Instant audit logging</li> <li>Live notification triggering</li> </ul>"},{"location":"database/data-flows/#stream-processing","title":"Stream Processing","text":"<ul> <li>Continuous data ingestion</li> <li>Incremental data updates</li> <li>Event-driven processing</li> <li>Pipeline monitoring and error handling</li> </ul>"},{"location":"database/data-flows/#data-retrieval","title":"Data Retrieval","text":"<p>TODO: Document data access patterns</p>"},{"location":"database/data-flows/#user-queries","title":"User Queries","text":"<ul> <li>User profile retrieval</li> <li>User permission checks</li> <li>User activity history</li> <li>User-owned resource listing</li> </ul>"},{"location":"database/data-flows/#laboratory-queries","title":"Laboratory Queries","text":"<ul> <li>Laboratory details retrieval</li> <li>Laboratory member listings</li> <li>Laboratory activity summaries</li> <li>Laboratory comparison reports</li> </ul>"},{"location":"database/data-flows/#import-queries","title":"Import Queries","text":"<ul> <li>Import job status checks</li> <li>Import row inspection</li> <li>Import error analysis</li> <li>Import history browsing</li> </ul>"},{"location":"database/data-flows/#reporting-queries","title":"Reporting Queries","text":"<ul> <li>Emission summary reports</li> <li>Trend analysis queries</li> <li>Comparative statistics</li> <li>Export data preparation</li> </ul>"},{"location":"database/data-flows/#data-ownership-and-access-control","title":"Data Ownership and Access Control","text":"<p>TODO: Document data ownership models</p>"},{"location":"database/data-flows/#entity-ownership","title":"Entity Ownership","text":"<ul> <li>User-owned data</li> <li>Laboratory-owned data</li> <li>System-owned data</li> <li>Shared data resources</li> </ul>"},{"location":"database/data-flows/#access-patterns","title":"Access Patterns","text":"<ul> <li>Direct ownership access</li> <li>Role-based access</li> <li>Collaborative access</li> <li>Public data access</li> </ul>"},{"location":"database/data-flows/#permission-models","title":"Permission Models","text":"<ul> <li>Read permissions</li> <li>Write permissions</li> <li>Administrative permissions</li> <li>Delegated permissions</li> </ul>"},{"location":"database/data-flows/#data-lifecycle","title":"Data Lifecycle","text":"<p>TODO: Document data lifecycle management</p>"},{"location":"database/data-flows/#creation","title":"Creation","text":"<ul> <li>Initial data entry</li> <li>Default value assignment</li> <li>Validation and verification</li> <li>Audit trail recording</li> </ul>"},{"location":"database/data-flows/#modification","title":"Modification","text":"<ul> <li>Update request processing</li> <li>Change validation</li> <li>Conflict resolution</li> <li>History tracking</li> </ul>"},{"location":"database/data-flows/#archival","title":"Archival","text":"<ul> <li>Data aging policies</li> <li>Archive trigger conditions</li> <li>Archive storage strategies</li> <li>Retrieval procedures</li> </ul>"},{"location":"database/data-flows/#deletion","title":"Deletion","text":"<ul> <li>Soft delete implementation</li> <li>Hard delete procedures</li> <li>Cascade deletion rules</li> <li>Compliance considerations</li> </ul>"},{"location":"database/data-flows/#data-integration","title":"Data Integration","text":"<p>TODO: Document external data integration</p>"},{"location":"database/data-flows/#external-data-sources","title":"External Data Sources","text":"<ul> <li>Emission factor databases</li> <li>Organizational directories</li> <li>Reference data systems</li> <li>Third-party APIs</li> </ul>"},{"location":"database/data-flows/#integration-patterns","title":"Integration Patterns","text":"<ul> <li>Batch data imports</li> <li>Real-time API integration</li> <li>File-based data exchange</li> <li>Event-driven updates</li> </ul>"},{"location":"database/data-flows/#data-synchronization","title":"Data Synchronization","text":"<ul> <li>Synchronization schedules</li> <li>Conflict resolution strategies</li> <li>Data consistency checks</li> <li>Error handling and retry</li> </ul> <p>For schema details, see Schema.</p>"},{"location":"database/maintenance/","title":"Database Maintenance","text":"<p>This document describes the database maintenance procedures, including backups, monitoring, and routine tasks.</p>"},{"location":"database/maintenance/#backup-strategy","title":"Backup Strategy","text":"<p>TODO: Document backup procedures</p>"},{"location":"database/maintenance/#backup-types","title":"Backup Types","text":"<ul> <li>Full database backups</li> <li>Incremental backups</li> <li>Transaction log backups</li> <li>Point-in-time recovery backups</li> </ul>"},{"location":"database/maintenance/#backup-schedule","title":"Backup Schedule","text":"<ul> <li>Daily full backups</li> <li>Hourly incremental backups</li> <li>Continuous transaction log backups</li> <li>Weekly archive backups</li> </ul>"},{"location":"database/maintenance/#backup-storage","title":"Backup Storage","text":"<ul> <li>Local storage for recent backups</li> <li>Cloud storage for long-term retention</li> <li>Encrypted backup files</li> <li>Backup rotation and cleanup</li> </ul>"},{"location":"database/maintenance/#backup-validation","title":"Backup Validation","text":"<ul> <li>Regular restore testing</li> <li>Backup integrity verification</li> <li>Recovery time objective testing</li> <li>Recovery point objective validation</li> </ul>"},{"location":"database/maintenance/#recovery-procedures","title":"Recovery Procedures","text":"<p>TODO: Document recovery processes</p>"},{"location":"database/maintenance/#point-in-time-recovery","title":"Point-in-Time Recovery","text":"<ul> <li>Recovery time specification</li> <li>Transaction log replay</li> <li>Consistency verification</li> <li>Application testing</li> </ul>"},{"location":"database/maintenance/#disaster-recovery","title":"Disaster Recovery","text":"<ul> <li>Complete system restoration</li> <li>Alternate site activation</li> <li>Data synchronization</li> <li>Service validation</li> </ul>"},{"location":"database/maintenance/#partial-recovery","title":"Partial Recovery","text":"<ul> <li>Table or schema recovery</li> <li>Single database recovery</li> <li>Filegroup recovery</li> <li>Object-level recovery</li> </ul>"},{"location":"database/maintenance/#monitoring-and-alerting","title":"Monitoring and Alerting","text":"<p>TODO: Document monitoring setup</p>"},{"location":"database/maintenance/#performance-monitoring","title":"Performance Monitoring","text":"<ul> <li>Query performance tracking</li> <li>Index usage analysis</li> <li>Buffer pool efficiency</li> <li>Lock contention monitoring</li> </ul>"},{"location":"database/maintenance/#resource-utilization","title":"Resource Utilization","text":"<ul> <li>CPU usage monitoring</li> <li>Memory consumption tracking</li> <li>Disk space management</li> <li>Network I/O monitoring</li> </ul>"},{"location":"database/maintenance/#database-health","title":"Database Health","text":"<ul> <li>Connection count monitoring</li> <li>Transaction throughput</li> <li>Error rate tracking</li> <li>Deadlock detection</li> </ul>"},{"location":"database/maintenance/#alerting-policies","title":"Alerting Policies","text":"<ul> <li>Critical threshold alerts</li> <li>Warning threshold notifications</li> <li>Automated escalation</li> <li>Notification channels</li> </ul>"},{"location":"database/maintenance/#routine-maintenance-tasks","title":"Routine Maintenance Tasks","text":"<p>TODO: Document scheduled maintenance</p>"},{"location":"database/maintenance/#index-maintenance","title":"Index Maintenance","text":"<ul> <li>Index rebuild schedules</li> <li>Index reorganization</li> <li>Statistics updates</li> <li>Fragmentation analysis</li> </ul>"},{"location":"database/maintenance/#data-maintenance","title":"Data Maintenance","text":"<ul> <li>Data archiving</li> <li>Data purging</li> <li>Table reorganization</li> <li>Space reclamation</li> </ul>"},{"location":"database/maintenance/#log-management","title":"Log Management","text":"<ul> <li>Transaction log truncation</li> <li>Log file rotation</li> <li>Log file sizing</li> <li>Log backup management</li> </ul>"},{"location":"database/maintenance/#database-optimization","title":"Database Optimization","text":"<ul> <li>Query plan optimization</li> <li>Configuration tuning</li> <li>Memory allocation adjustment</li> <li>Connection pool optimization</li> </ul>"},{"location":"database/maintenance/#security-maintenance","title":"Security Maintenance","text":"<p>TODO: Document security procedures</p>"},{"location":"database/maintenance/#access-control","title":"Access Control","text":"<ul> <li>User account reviews</li> <li>Permission audits</li> <li>Role membership verification</li> <li>Privilege escalation monitoring</li> </ul>"},{"location":"database/maintenance/#data-protection","title":"Data Protection","text":"<ul> <li>Encryption key management</li> <li>Certificate renewal</li> <li>Data masking updates</li> <li>Audit log reviews</li> </ul>"},{"location":"database/maintenance/#vulnerability-management","title":"Vulnerability Management","text":"<ul> <li>Security patch deployment</li> <li>Vulnerability scanning</li> <li>Penetration testing</li> <li>Compliance verification</li> </ul>"},{"location":"database/maintenance/#automation-and-scheduling","title":"Automation and Scheduling","text":"<p>TODO: Document automation approaches</p>"},{"location":"database/maintenance/#maintenance-windows","title":"Maintenance Windows","text":"<ul> <li>Scheduled downtime windows</li> <li>Low-impact operation times</li> <li>Business hour considerations</li> <li>Emergency maintenance procedures</li> </ul>"},{"location":"database/maintenance/#script-automation","title":"Script Automation","text":"<ul> <li>Backup script automation</li> <li>Maintenance task scheduling</li> <li>Monitoring script deployment</li> <li>Alerting script management</li> </ul>"},{"location":"database/maintenance/#orchestration-tools","title":"Orchestration Tools","text":"<ul> <li>Cron job management</li> <li>Kubernetes job scheduling</li> <li>CI/CD integration</li> <li>Manual override procedures</li> </ul>"},{"location":"database/maintenance/#troubleshooting","title":"Troubleshooting","text":"<p>TODO: Document troubleshooting procedures</p>"},{"location":"database/maintenance/#common-issues","title":"Common Issues","text":"<ul> <li>Performance degradation</li> <li>Connection failures</li> <li>Storage space exhaustion</li> <li>Corruption detection</li> </ul>"},{"location":"database/maintenance/#diagnostic-procedures","title":"Diagnostic Procedures","text":"<ul> <li>Log file analysis</li> <li>Query plan examination</li> <li>Resource usage investigation</li> <li>Configuration review</li> </ul>"},{"location":"database/maintenance/#resolution-strategies","title":"Resolution Strategies","text":"<ul> <li>Immediate remediation steps</li> <li>Long-term solutions</li> <li>Workaround implementation</li> <li>Prevention measures</li> </ul> <p>For migration procedures, see Migrations.</p>"},{"location":"database/migrations/","title":"Database Migrations","text":"<p>This document describes the database migration process, including tools, conventions, and best practices.</p>"},{"location":"database/migrations/#migration-tool","title":"Migration Tool","text":"<ul> <li>Tool: Alembic</li> <li>Integration: Integrated with SQLAlchemy ORM</li> <li>Version Control: Migrations stored in version control</li> <li>Execution: Command-line interface and programmatic API</li> </ul>"},{"location":"database/migrations/#migration-workflow","title":"Migration Workflow","text":"<p>TODO: Document the migration process</p>"},{"location":"database/migrations/#development-process","title":"Development Process","text":"<ol> <li>Schema changes identified</li> <li>Migration script generation</li> <li>Migration script customization</li> <li>Local testing</li> <li>Code review and approval</li> <li>Deployment to environments</li> </ol>"},{"location":"database/migrations/#migration-script-creation","title":"Migration Script Creation","text":"<ul> <li>Automatic generation using <code>alembic revision --autogenerate</code></li> <li>Manual script writing for complex changes</li> <li>Script template customization</li> <li>Naming convention enforcement</li> </ul>"},{"location":"database/migrations/#migration-testing","title":"Migration Testing","text":"<ul> <li>Local database testing</li> <li>Test environment validation</li> <li>Downgrade testing</li> <li>Performance impact assessment</li> </ul>"},{"location":"database/migrations/#migration-conventions","title":"Migration Conventions","text":"<p>TODO: Document migration standards</p>"},{"location":"database/migrations/#naming-convention","title":"Naming Convention","text":"<ul> <li>Descriptive migration names</li> <li>Date prefix for ordering</li> <li>Action-oriented naming (e.g., <code>add_user_email_column</code>)</li> <li>Consistent formatting and style</li> </ul>"},{"location":"database/migrations/#script-structure","title":"Script Structure","text":"<ul> <li>Upgrade and downgrade functions</li> <li>Transaction handling</li> <li>Error handling and rollback</li> <li>Progress reporting and logging</li> </ul>"},{"location":"database/migrations/#data-migration","title":"Data Migration","text":"<ul> <li>Separate data and schema migrations</li> <li>Batch processing for large datasets</li> <li>Progress tracking for long-running migrations</li> <li>Validation and verification steps</li> </ul>"},{"location":"database/migrations/#migration-execution","title":"Migration Execution","text":"<p>TODO: Document migration deployment</p>"},{"location":"database/migrations/#environment-promotion","title":"Environment Promotion","text":"<ul> <li>Development environment</li> <li>Staging environment</li> <li>Production environment</li> <li>Rollback procedures</li> </ul>"},{"location":"database/migrations/#migration-commands","title":"Migration Commands","text":"<ul> <li><code>alembic upgrade head</code> - Apply all pending migrations</li> <li><code>alembic downgrade</code> - Revert migrations</li> <li><code>alembic current</code> - Show current revision</li> <li><code>alembic history</code> - Show migration history</li> </ul>"},{"location":"database/migrations/#migration-status","title":"Migration Status","text":"<ul> <li>Pending migrations identification</li> <li>Applied migrations tracking</li> <li>Migration conflict resolution</li> <li>Migration dependency management</li> </ul>"},{"location":"database/migrations/#common-migration-patterns","title":"Common Migration Patterns","text":"<p>TODO: Document typical migration scenarios</p>"},{"location":"database/migrations/#schema-changes","title":"Schema Changes","text":"<ul> <li>Adding columns</li> <li>Removing columns</li> <li>Modifying column types</li> <li>Adding constraints</li> <li>Removing constraints</li> <li>Creating tables</li> <li>Dropping tables</li> </ul>"},{"location":"database/migrations/#data-transformations","title":"Data Transformations","text":"<ul> <li>Populating new columns</li> <li>Converting data formats</li> <li>Merging or splitting data</li> <li>Data cleanup and normalization</li> <li>Reference data updates</li> </ul>"},{"location":"database/migrations/#performance-considerations","title":"Performance Considerations","text":"<ul> <li>Index creation and removal</li> <li>Partitioning changes</li> <li>Statistics updates</li> <li>Lock minimization</li> </ul>"},{"location":"database/migrations/#rollback-strategies","title":"Rollback Strategies","text":"<p>TODO: Document rollback procedures</p>"},{"location":"database/migrations/#safe-rollbacks","title":"Safe Rollbacks","text":"<ul> <li>Reversible schema changes</li> <li>Backup creation before migration</li> <li>Transactional migrations</li> <li>Point-in-time recovery</li> </ul>"},{"location":"database/migrations/#complex-rollbacks","title":"Complex Rollbacks","text":"<ul> <li>Data restoration procedures</li> <li>Manual intervention steps</li> <li>Service downtime requirements</li> <li>Communication plans</li> </ul>"},{"location":"database/migrations/#emergency-procedures","title":"Emergency Procedures","text":"<ul> <li>Migration failure detection</li> <li>Immediate rollback triggers</li> <li>Service restoration steps</li> <li>Post-incident analysis</li> </ul>"},{"location":"database/migrations/#migration-monitoring","title":"Migration Monitoring","text":"<p>TODO: Document migration observability</p>"},{"location":"database/migrations/#progress-tracking","title":"Progress Tracking","text":"<ul> <li>Migration duration monitoring</li> <li>Step-by-step progress reporting</li> <li>Resource utilization tracking</li> <li>Error and warning logging</li> </ul>"},{"location":"database/migrations/#performance-impact","title":"Performance Impact","text":"<ul> <li>Query performance before and after</li> <li>Lock contention monitoring</li> <li>Database load assessment</li> <li>User impact evaluation</li> </ul>"},{"location":"database/migrations/#alerting","title":"Alerting","text":"<ul> <li>Migration failure notifications</li> <li>Performance degradation alerts</li> <li>Long-running migration warnings</li> <li>Rollback initiation alerts</li> </ul> <p>For schema details, see Schema.</p>"},{"location":"database/schema/","title":"Database Schema","text":"<p>This document describes the database schema, including tables, relationships, and design principles.</p>"},{"location":"database/schema/#schema-design-principles","title":"Schema Design Principles","text":"<p>TODO: Document schema design guidelines</p>"},{"location":"database/schema/#normalization","title":"Normalization","text":"<ul> <li>Normalization levels</li> <li>Denormalization strategies</li> <li>Performance considerations</li> <li>Data integrity rules</li> </ul>"},{"location":"database/schema/#naming-conventions","title":"Naming Conventions","text":"<ul> <li>Table naming standards</li> <li>Column naming standards</li> <li>Constraint naming</li> <li>Index naming</li> </ul>"},{"location":"database/schema/#data-types","title":"Data Types","text":"<ul> <li>Primary key strategies</li> <li>String length considerations</li> <li>Numeric precision and scale</li> <li>Date and time handling</li> <li>JSON storage patterns</li> </ul>"},{"location":"database/schema/#entity-relationship-diagram","title":"Entity Relationship Diagram","text":"<p>TODO: Insert ERD diagram</p>"},{"location":"database/schema/#core-entities","title":"Core Entities","text":"<ul> <li>Users</li> <li>Laboratories</li> <li>Import Jobs</li> <li>Import Rows</li> <li>Emission Factors</li> <li>Activities</li> <li>Audit Logs</li> </ul>"},{"location":"database/schema/#relationships","title":"Relationships","text":"<ul> <li>One-to-many relationships</li> <li>Many-to-many relationships</li> <li>Self-referencing relationships</li> <li>Weak entities</li> </ul>"},{"location":"database/schema/#table-definitions","title":"Table Definitions","text":"<p>TODO: Document detailed table structures</p>"},{"location":"database/schema/#users-table","title":"Users Table","text":"<ul> <li>id (Primary Key)</li> <li>sciper (Unique)</li> <li>email</li> <li>display_name</li> <li>created_at</li> </ul>"},{"location":"database/schema/#laboratories-table","title":"Laboratories Table","text":"<ul> <li>id (Primary Key)</li> <li>code (Unique)</li> <li>name</li> <li>faculty</li> <li>created_at</li> </ul>"},{"location":"database/schema/#import-jobs-table","title":"Import Jobs Table","text":"<ul> <li>id (Primary Key)</li> <li>lab_id (Foreign Key)</li> <li>uploader_id (Foreign Key)</li> <li>filename</li> <li>s3_key</li> <li>status</li> <li>rows_count</li> <li>error_count</li> <li>created_at</li> <li>processed_at</li> </ul>"},{"location":"database/schema/#import-rows-table","title":"Import Rows Table","text":"<ul> <li>id (Primary Key)</li> <li>import_job_id (Foreign Key)</li> <li>row_number</li> <li>raw_data (JSONB)</li> <li>validated</li> <li>errors (JSONB)</li> </ul>"},{"location":"database/schema/#emission-factors-table","title":"Emission Factors Table","text":"<ul> <li>id (Primary Key)</li> <li>source</li> <li>category</li> <li>key</li> <li>factor</li> <li>unit</li> <li>meta (JSONB)</li> <li>valid_from</li> <li>valid_to</li> </ul>"},{"location":"database/schema/#activities-table","title":"Activities Table","text":"<ul> <li>id (Primary Key)</li> <li>lab_id (Foreign Key)</li> <li>type</li> <li>payload (JSONB)</li> <li>emissions_kg</li> <li>created_at</li> </ul>"},{"location":"database/schema/#audit-logs-table","title":"Audit Logs Table","text":"<ul> <li>id (Primary Key)</li> <li>actor_id (Foreign Key)</li> <li>action</li> <li>target_type</li> <li>target_id</li> <li>details (JSONB)</li> <li>created_at</li> </ul>"},{"location":"database/schema/#indexing-strategy","title":"Indexing Strategy","text":"<p>TODO: Document indexing approaches</p>"},{"location":"database/schema/#primary-indexes","title":"Primary Indexes","text":"<ul> <li>Primary key indexes</li> <li>Unique constraint indexes</li> <li>Foreign key indexes</li> </ul>"},{"location":"database/schema/#performance-indexes","title":"Performance Indexes","text":"<ul> <li>Frequently queried columns</li> <li>Composite indexes</li> <li>Partial indexes</li> <li>Expression indexes</li> </ul>"},{"location":"database/schema/#specialized-indexes","title":"Specialized Indexes","text":"<ul> <li>Full-text search indexes</li> <li>JSONB path indexes</li> <li>Geospatial indexes (if applicable)</li> <li>Time-series indexes</li> </ul>"},{"location":"database/schema/#constraints-and-validation","title":"Constraints and Validation","text":"<p>TODO: Document data integrity rules</p>"},{"location":"database/schema/#database-constraints","title":"Database Constraints","text":"<ul> <li>Primary key constraints</li> <li>Foreign key constraints</li> <li>Unique constraints</li> <li>Check constraints</li> <li>Not-null constraints</li> </ul>"},{"location":"database/schema/#application-level-validation","title":"Application-Level Validation","text":"<ul> <li>Business rule enforcement</li> <li>Cross-field validation</li> <li>Data format validation</li> <li>Referential integrity</li> </ul> <p>For migration procedures, see Migrations.</p>"},{"location":"frontend/","title":"Frontend Overview","text":"<p>This section provides an overview of the frontend layer architecture, technologies, and integration points.</p>"},{"location":"frontend/#architecture-pattern","title":"Architecture Pattern","text":"<ul> <li>Framework: Vue 3 Composition API</li> <li>UI Library: Quasar Framework</li> <li>State Management: Pinia</li> <li>Routing: Vue Router</li> <li>HTTP Client: Axios</li> <li>Authentication: oidc-client-ts</li> </ul>"},{"location":"frontend/#main-technologies","title":"Main Technologies","text":"<ul> <li>Vue 3 for reactive UI components</li> <li>Quasar for responsive UI components and utilities</li> <li>Pinia for state management</li> <li>Vue Router for client-side routing</li> <li>oidc-client-ts for OpenID Connect authentication</li> <li>eCharts for data visualization</li> </ul>"},{"location":"frontend/#api-interface","title":"API Interface","text":"<p>The frontend communicates with the backend through a RESTful API:</p> <ul> <li>Base URL: <code>/api/v1/</code></li> <li>Authentication: Bearer token in Authorization header</li> <li>Content Type: JSON for requests and responses</li> <li>Error Handling: Standard HTTP status codes with JSON error bodies</li> </ul>"},{"location":"frontend/#integration-points","title":"Integration Points","text":"<ul> <li>Authentication Service: Microsoft Entra ID (OIDC)</li> <li>Backend API: FastAPI REST endpoints</li> <li>Static Assets: Served directly by web server</li> </ul>"},{"location":"frontend/#subsystems","title":"Subsystems","text":"<ul> <li>Architecture - Detailed frontend architecture</li> <li>UI System - Component library and design system</li> <li>API Integration - Data layer and API communication</li> <li>Development Guide - Setup and development workflows</li> <li>Testing - Testing strategies and tools</li> <li>Deployment - Build and deployment processes</li> </ul> <p>For architectural overview, see Architecture Overview.</p>"},{"location":"frontend/api/","title":"Data &amp; API Integration","text":"<p>This document describes how the frontend integrates with backend APIs and manages data.</p>"},{"location":"frontend/api/#api-client","title":"API Client","text":"<p>TODO: Document the API client implementation</p>"},{"location":"frontend/api/#http-layer","title":"HTTP Layer","text":"<ul> <li>Request/response interceptors</li> <li>Error handling</li> <li>Retry mechanisms</li> <li>Timeout configurations</li> </ul>"},{"location":"frontend/api/#authentication-integration","title":"Authentication Integration","text":"<ul> <li>Token injection in requests</li> <li>Unauthorized response handling</li> <li>Token refresh coordination</li> </ul>"},{"location":"frontend/api/#data-management","title":"Data Management","text":"<p>TODO: Document data fetching and state synchronization</p>"},{"location":"frontend/api/#caching-strategies","title":"Caching Strategies","text":"<ul> <li>Browser cache headers</li> <li>In-memory caching</li> <li>Cache invalidation</li> <li>Stale-while-revalidate patterns</li> </ul>"},{"location":"frontend/api/#pagination","title":"Pagination","text":"<ul> <li>Offset-based pagination</li> <li>Cursor-based pagination</li> <li>Infinite scrolling</li> <li>Page size management</li> </ul>"},{"location":"frontend/api/#search-and-filtering","title":"Search and Filtering","text":"<ul> <li>Client-side filtering</li> <li>Server-side filtering</li> <li>Search debouncing</li> <li>Filter persistence</li> </ul>"},{"location":"frontend/api/#real-time-updates","title":"Real-time Updates","text":"<p>TODO: Document real-time data handling (if applicable)</p>"},{"location":"frontend/api/#websocket-integration","title":"WebSocket Integration","text":"<ul> <li>Connection management</li> <li>Message handling</li> <li>Reconnection logic</li> <li>Presence indicators</li> </ul>"},{"location":"frontend/api/#file-handling","title":"File Handling","text":""},{"location":"frontend/api/#upload-process","title":"Upload Process","text":"<ul> <li>Signed URL acquisition</li> <li>Direct-to-storage uploads</li> <li>Progress tracking</li> <li>Error handling</li> </ul>"},{"location":"frontend/api/#download-process","title":"Download Process","text":"<ul> <li>Report generation</li> <li>File delivery</li> <li>Progress indication</li> </ul> <p>For API specifications, see Backend API Design.</p>"},{"location":"frontend/architecture/","title":"Frontend Architecture","text":"<p>This document describes the detailed architecture of the frontend application.</p>"},{"location":"frontend/architecture/#component-architecture","title":"Component Architecture","text":"<p>TODO: Document the component hierarchy and organization</p>"},{"location":"frontend/architecture/#state-management","title":"State Management","text":"<ul> <li>Pinia stores for application state</li> <li>Store modules for different domains</li> <li>Reactive state updates</li> <li>Persistence strategies</li> </ul>"},{"location":"frontend/architecture/#routing","title":"Routing","text":"<ul> <li>Vue Router configuration</li> <li>Route guards and authentication</li> <li>Lazy loading of routes</li> <li>Navigation patterns</li> </ul>"},{"location":"frontend/architecture/#authentication-flow","title":"Authentication Flow","text":"<p>TODO: Document the frontend authentication implementation</p>"},{"location":"frontend/architecture/#token-management","title":"Token Management","text":"<ul> <li>Storage strategies (memory vs localStorage vs cookies)</li> <li>Token refresh mechanisms</li> <li>Session expiration handling</li> <li>Logout procedures</li> </ul>"},{"location":"frontend/architecture/#internationalization","title":"Internationalization","text":"<ul> <li>i18n implementation</li> <li>Message catalogs</li> <li>Date and number formatting</li> <li>Language switching</li> </ul>"},{"location":"frontend/architecture/#responsive-design","title":"Responsive Design","text":"<ul> <li>Quasar's responsive utilities</li> <li>Breakpoint handling</li> <li>Mobile-first approach</li> <li>Touch-friendly components</li> </ul>"},{"location":"frontend/architecture/#performance-considerations","title":"Performance Considerations","text":"<ul> <li>Bundle optimization</li> <li>Lazy loading strategies</li> <li>Caching mechanisms</li> <li>Rendering optimizations</li> </ul> <p>For architectural overview, see Architecture Overview.</p>"},{"location":"frontend/deploy/","title":"Frontend Deployment","text":"<p>This document describes the build process and deployment strategies for the frontend application.</p>"},{"location":"frontend/deploy/#build-process","title":"Build Process","text":"<p>TODO: Document the frontend build process</p>"},{"location":"frontend/deploy/#build-configuration","title":"Build Configuration","text":"<ul> <li>Webpack/Vite configuration</li> <li>Environment-specific settings</li> <li>Asset optimization</li> <li>Code splitting strategies</li> </ul>"},{"location":"frontend/deploy/#optimization-techniques","title":"Optimization Techniques","text":"<ul> <li>Tree shaking</li> <li>Minification</li> <li>Image compression</li> <li>Bundle analysis</li> </ul>"},{"location":"frontend/deploy/#output-structure","title":"Output Structure","text":"<ul> <li>Generated files and directories</li> <li>Static asset organization</li> <li>Source map generation</li> <li>Manifest files</li> </ul>"},{"location":"frontend/deploy/#deployment-strategies","title":"Deployment Strategies","text":"<p>TODO: Document deployment approaches</p>"},{"location":"frontend/deploy/#static-deployment","title":"Static Deployment","text":"<ul> <li>CDN distribution</li> <li>Cache headers configuration</li> <li>Compression settings</li> <li>Security headers</li> </ul>"},{"location":"frontend/deploy/#environment-specific-builds","title":"Environment-Specific Builds","text":"<ul> <li>Development build</li> <li>Staging build</li> <li>Production build</li> <li>Feature branch builds</li> </ul>"},{"location":"frontend/deploy/#versioning","title":"Versioning","text":"<ul> <li>Semantic versioning</li> <li>Build identifiers</li> <li>Release tagging</li> <li>Changelog generation</li> </ul>"},{"location":"frontend/deploy/#continuous-deployment","title":"Continuous Deployment","text":"<p>TODO: Document CI/CD integration</p>"},{"location":"frontend/deploy/#github-actions-workflow","title":"GitHub Actions Workflow","text":"<ul> <li>Build job configuration</li> <li>Artifact storage</li> <li>Deployment triggers</li> <li>Notification settings</li> </ul>"},{"location":"frontend/deploy/#argocd-integration","title":"ArgoCD Integration","text":"<ul> <li>Application manifests</li> <li>Sync policies</li> <li>Health checks</li> <li>Rollback procedures</li> </ul>"},{"location":"frontend/deploy/#monitoring-and-analytics","title":"Monitoring and Analytics","text":"<p>TODO: Document post-deployment monitoring</p>"},{"location":"frontend/deploy/#performance-monitoring","title":"Performance Monitoring","text":"<ul> <li>Page load metrics</li> <li>Bundle size tracking</li> <li>Core Web Vitals</li> <li>User experience analytics</li> </ul>"},{"location":"frontend/deploy/#error-tracking","title":"Error Tracking","text":"<ul> <li>JavaScript error reporting</li> <li>Unhandled promise rejection tracking</li> <li>User feedback collection</li> <li>Crash reporting</li> </ul>"},{"location":"frontend/deploy/#rollback-procedures","title":"Rollback Procedures","text":"<p>TODO: Document rollback processes</p>"},{"location":"frontend/deploy/#quick-rollback","title":"Quick Rollback","text":"<ul> <li>Previous version identification</li> <li>Traffic redirection</li> <li>Verification steps</li> <li>Communication plan</li> </ul>"},{"location":"frontend/deploy/#partial-rollbacks","title":"Partial Rollbacks","text":"<ul> <li>Feature flag usage</li> <li>Selective component rollback</li> <li>Data compatibility considerations</li> <li>Testing requirements</li> </ul> <p>For CI/CD pipeline overview, see Architecture CI/CD Pipeline.</p>"},{"location":"frontend/dev-guide/","title":"Frontend Development Guide","text":"<p>This document provides guidance for frontend development, including setup, coding standards, and workflows.</p>"},{"location":"frontend/dev-guide/#development-environment-setup","title":"Development Environment Setup","text":"<p>TODO: Document the development environment setup process</p>"},{"location":"frontend/dev-guide/#prerequisites","title":"Prerequisites","text":"<ul> <li>Node.js version requirements</li> <li>Package manager (npm/yarn/pnpm)</li> <li>Editor recommendations and extensions</li> <li>Browser developer tools</li> </ul>"},{"location":"frontend/dev-guide/#installation","title":"Installation","text":"<pre><code># Clone repository\n# Install dependencies\n# Configure environment variables\n</code></pre>"},{"location":"frontend/dev-guide/#development-server","title":"Development Server","text":"<ul> <li>Starting the development server</li> <li>Hot module replacement</li> <li>Debugging configuration</li> <li>Proxy settings for API calls</li> </ul>"},{"location":"frontend/dev-guide/#project-structure","title":"Project Structure","text":"<p>TODO: Document the frontend project organization</p> <pre><code>frontend/\n\u251c\u2500\u2500 src/\n\u2502   \u251c\u2500\u2500 assets/\n\u2502   \u251c\u2500\u2500 components/\n\u2502   \u251c\u2500\u2500 composables/\n\u2502   \u251c\u2500\u2500 layouts/\n\u2502   \u251c\u2500\u2500 pages/\n\u2502   \u251c\u2500\u2500 router/\n\u2502   \u251c\u2500\u2500 stores/\n\u2502   \u2514\u2500\u2500 App.vue\n\u251c\u2500\u2500 public/\n\u2514\u2500\u2500 package.json\n</code></pre>"},{"location":"frontend/dev-guide/#coding-standards","title":"Coding Standards","text":""},{"location":"frontend/dev-guide/#vue-component-structure","title":"Vue Component Structure","text":"<ul> <li>Component composition patterns</li> <li>Template syntax guidelines</li> <li>Script setup conventions</li> <li>Style scoping</li> </ul>"},{"location":"frontend/dev-guide/#typescript-usage","title":"TypeScript Usage","text":"<ul> <li>Type definitions</li> <li>Interface declarations</li> <li>Generic types</li> <li>Utility types</li> </ul>"},{"location":"frontend/dev-guide/#styling-conventions","title":"Styling Conventions","text":"<ul> <li>CSS class naming (BEM methodology)</li> <li>SCSS/SASS usage</li> <li>Theme variable utilization</li> <li>Responsive utility classes</li> </ul>"},{"location":"frontend/dev-guide/#testing","title":"Testing","text":"<p>TODO: Document testing approaches and tools</p>"},{"location":"frontend/dev-guide/#unit-testing","title":"Unit Testing","text":"<ul> <li>Component testing with Vitest</li> <li>Composable testing</li> <li>Store testing</li> <li>Mocking strategies</li> </ul>"},{"location":"frontend/dev-guide/#end-to-end-testing","title":"End-to-End Testing","text":"<ul> <li>Playwright setup</li> <li>Test scenarios</li> <li>Data setup and teardown</li> <li>Reporting</li> </ul>"},{"location":"frontend/dev-guide/#build-process","title":"Build Process","text":"<p>TODO: Document the build and optimization process</p>"},{"location":"frontend/dev-guide/#production-build","title":"Production Build","text":"<ul> <li>Build command and options</li> <li>Output directory structure</li> <li>Asset optimization</li> <li>Source maps configuration</li> </ul>"},{"location":"frontend/dev-guide/#deployment","title":"Deployment","text":"<ul> <li>Static asset deployment</li> <li>CDN considerations</li> <li>Cache invalidation</li> <li>Environment-specific builds</li> </ul> <p>For continuous integration details, see CI/CD Pipeline.</p>"},{"location":"frontend/testing/","title":"Frontend Testing","text":"<p>This document outlines the testing strategies, tools, and practices for the frontend application.</p>"},{"location":"frontend/testing/#testing-strategy","title":"Testing Strategy","text":"<p>TODO: Document the overall testing approach</p>"},{"location":"frontend/testing/#test-types","title":"Test Types","text":"<ul> <li>Unit tests for individual components and functions</li> <li>Integration tests for component interactions</li> <li>End-to-end tests for user workflows</li> <li>Visual regression tests for UI consistency</li> </ul>"},{"location":"frontend/testing/#test-pyramid","title":"Test Pyramid","text":"<ul> <li>Majority of tests: Unit tests</li> <li>Some integration tests</li> <li>Fewer end-to-end tests</li> <li>Selective visual regression tests</li> </ul>"},{"location":"frontend/testing/#unit-testing","title":"Unit Testing","text":"<p>TODO: Document unit testing practices</p>"},{"location":"frontend/testing/#component-testing","title":"Component Testing","text":"<ul> <li>Testing component rendering</li> <li>Event handling</li> <li>Prop validation</li> <li>Slot content rendering</li> </ul>"},{"location":"frontend/testing/#composable-testing","title":"Composable Testing","text":"<ul> <li>Reactive state testing</li> <li>Lifecycle hook testing</li> <li>Dependency mocking</li> <li>Async operation testing</li> </ul>"},{"location":"frontend/testing/#store-testing","title":"Store Testing","text":"<ul> <li>State mutation testing</li> <li>Getter computation</li> <li>Action side effects</li> <li>Module isolation</li> </ul>"},{"location":"frontend/testing/#utilities-testing","title":"Utilities Testing","text":"<ul> <li>Pure function testing</li> <li>Helper function validation</li> <li>Edge case coverage</li> <li>Error condition testing</li> </ul>"},{"location":"frontend/testing/#integration-testing","title":"Integration Testing","text":"<p>TODO: Document integration testing practices</p>"},{"location":"frontend/testing/#component-integration","title":"Component Integration","text":"<ul> <li>Parent-child component interactions</li> <li>Event propagation</li> <li>Shared state management</li> <li>Context provider/consumer relationships</li> </ul>"},{"location":"frontend/testing/#api-integration","title":"API Integration","text":"<ul> <li>HTTP client mocking</li> <li>Response simulation</li> <li>Error scenario testing</li> <li>Authentication flow testing</li> </ul>"},{"location":"frontend/testing/#end-to-end-testing","title":"End-to-End Testing","text":"<p>TODO: Document end-to-end testing practices</p>"},{"location":"frontend/testing/#test-framework","title":"Test Framework","text":"<ul> <li>Playwright for browser automation</li> <li>Test runner configuration</li> <li>Parallel test execution</li> <li>Cross-browser testing</li> </ul>"},{"location":"frontend/testing/#test-scenarios","title":"Test Scenarios","text":"<ul> <li>User authentication flows</li> <li>Data entry and submission</li> <li>Navigation and routing</li> <li>Error handling and recovery</li> </ul>"},{"location":"frontend/testing/#data-management","title":"Data Management","text":"<ul> <li>Test data setup and teardown</li> <li>Database seeding strategies</li> <li>Mock service configuration</li> <li>Cleanup procedures</li> </ul>"},{"location":"frontend/testing/#visual-regression-testing","title":"Visual Regression Testing","text":"<p>TODO: Document visual testing practices (if applicable)</p>"},{"location":"frontend/testing/#tooling","title":"Tooling","text":"<ul> <li>Screenshot comparison tools</li> <li>Baseline image management</li> <li>Diff detection and reporting</li> <li>Threshold configuration</li> </ul>"},{"location":"frontend/testing/#workflow","title":"Workflow","text":"<ul> <li>Automated screenshot capture</li> <li>Manual review process</li> <li>Baseline update procedures</li> <li>False positive handling</li> </ul>"},{"location":"frontend/testing/#test-reporting-and-monitoring","title":"Test Reporting and Monitoring","text":"<p>TODO: Document test reporting</p>"},{"location":"frontend/testing/#coverage-metrics","title":"Coverage Metrics","text":"<ul> <li>Code coverage targets</li> <li>Branch and function coverage</li> <li>Gap analysis</li> <li>Improvement tracking</li> </ul>"},{"location":"frontend/testing/#continuous-integration","title":"Continuous Integration","text":"<ul> <li>Test execution in CI pipeline</li> <li>Failure notification</li> <li>Performance benchmarking</li> <li>Trend analysis</li> </ul> <p>For development setup, see Development Guide.</p>"},{"location":"frontend/ui-system/","title":"UI System","text":"<p>This document describes the UI component system and design patterns used in the frontend application.</p>"},{"location":"frontend/ui-system/#design-system","title":"Design System","text":"<p>TODO: Document the design system and styling approach</p>"},{"location":"frontend/ui-system/#epfl-theme","title":"EPFL Theme","text":"<ul> <li>Brand colors and typography</li> <li>Spacing and layout guidelines</li> <li>Iconography</li> <li>Accessibility standards</li> </ul>"},{"location":"frontend/ui-system/#component-library","title":"Component Library","text":"<p>TODO: Document the component catalog</p>"},{"location":"frontend/ui-system/#layout-components","title":"Layout Components","text":"<ul> <li>AppShell</li> <li>Header</li> <li>Sidebar</li> <li>Footer</li> </ul>"},{"location":"frontend/ui-system/#form-components","title":"Form Components","text":"<ul> <li>Input fields</li> <li>Select dropdowns</li> <li>Date pickers</li> <li>File uploaders</li> </ul>"},{"location":"frontend/ui-system/#data-display-components","title":"Data Display Components","text":"<ul> <li>Tables</li> <li>Cards</li> <li>Lists</li> <li>Charts</li> </ul>"},{"location":"frontend/ui-system/#feedback-components","title":"Feedback Components","text":"<ul> <li>Toast notifications</li> <li>Modals</li> <li>Progress indicators</li> <li>Loading states</li> </ul>"},{"location":"frontend/ui-system/#component-patterns","title":"Component Patterns","text":""},{"location":"frontend/ui-system/#props-and-events","title":"Props and Events","text":"<p>TODO: Document component interface patterns</p>"},{"location":"frontend/ui-system/#slots-and-customization","title":"Slots and Customization","text":"<p>TODO: Document component customization approaches</p>"},{"location":"frontend/ui-system/#responsive-design","title":"Responsive Design","text":"<ul> <li>Grid system</li> <li>Breakpoints</li> <li>Device-specific adaptations</li> <li>Touch interactions</li> </ul> <p>For implementation details, see the Development Guide.</p>"},{"location":"infra/","title":"Infrastructure Overview","text":"<p>This section provides an overview of the infrastructure layer, including hosting, networking, and operational considerations.</p>"},{"location":"infra/#infrastructure-technology","title":"Infrastructure Technology","text":"<ul> <li>Platform: Kubernetes</li> <li>Container Runtime: Docker</li> <li>Orchestration: Kubernetes with Helm charts</li> <li>Service Mesh: (None - direct service communication)</li> <li>Monitoring: Prometheus, Grafana, OpenTelemetry</li> <li>Logging: ELK stack or similar centralized logging</li> <li>Secrets Management: Kubernetes Secrets or HashiCorp Vault</li> </ul>"},{"location":"infra/#key-components","title":"Key Components","text":"<ul> <li>Hosting Environment: Cloud or on-premises Kubernetes clusters</li> <li>Networking: Internal service communication, external ingress</li> <li>Storage: Persistent volumes for database and file storage</li> <li>Load Balancing: Kubernetes services and ingress controllers</li> <li>Security: Network policies, TLS termination, access controls</li> </ul>"},{"location":"infra/#integration-points","title":"Integration Points","text":"<ul> <li>Application Deployment: Helm charts and ArgoCD</li> <li>Monitoring Systems: Prometheus metrics collection</li> <li>Log Aggregation: Centralized logging infrastructure</li> <li>Backup Systems: Automated backup solutions</li> <li>Alerting: Notification systems for operational issues</li> </ul>"},{"location":"infra/#subsystems","title":"Subsystems","text":"<ul> <li>Hosting &amp; Network - Hosting environment and networking</li> <li>Monitoring &amp; Logging - Observability and logging systems</li> </ul> <p>For architectural overview, see Architecture Overview.</p>"},{"location":"infra/hosting/","title":"Hosting &amp; Network","text":"<p>This document describes the hosting environment, networking configuration, and deployment infrastructure.</p>"},{"location":"infra/hosting/#hosting-environment","title":"Hosting Environment","text":"<p>TODO: Document the hosting platform</p>"},{"location":"infra/hosting/#kubernetes-cluster","title":"Kubernetes Cluster","text":"<ul> <li>Cluster architecture and topology</li> <li>Node pool configuration</li> <li>Resource allocation and limits</li> <li>High availability setup</li> </ul>"},{"location":"infra/hosting/#cloud-provider","title":"Cloud Provider","text":"<ul> <li>Provider selection rationale</li> <li>Region and zone distribution</li> <li>Service integration</li> <li>Cost optimization strategies</li> </ul>"},{"location":"infra/hosting/#on-premises-considerations","title":"On-Premises Considerations","text":"<ul> <li>Hardware requirements</li> <li>Network infrastructure</li> <li>Storage systems</li> <li>Backup and disaster recovery</li> </ul>"},{"location":"infra/hosting/#networking-configuration","title":"Networking Configuration","text":"<p>TODO: Document networking setup</p>"},{"location":"infra/hosting/#service-communication","title":"Service Communication","text":"<ul> <li>Internal service discovery</li> <li>DNS configuration</li> <li>Service mesh (if applicable)</li> <li>Load balancing strategies</li> </ul>"},{"location":"infra/hosting/#external-access","title":"External Access","text":"<ul> <li>Ingress controller configuration</li> <li>TLS certificate management</li> <li>Domain name setup</li> <li>CDN integration (if applicable)</li> </ul>"},{"location":"infra/hosting/#network-security","title":"Network Security","text":"<ul> <li>Firewall rules</li> <li>Network policies</li> <li>DDoS protection</li> <li>Intrusion detection systems</li> </ul>"},{"location":"infra/hosting/#ip-address-management","title":"IP Address Management","text":"<ul> <li>Static IP allocation</li> <li>Dynamic IP assignment</li> <li>IP range planning</li> <li>Address conservation</li> </ul>"},{"location":"infra/hosting/#storage-infrastructure","title":"Storage Infrastructure","text":"<p>TODO: Document storage solutions</p>"},{"location":"infra/hosting/#persistent-storage","title":"Persistent Storage","text":"<ul> <li>Volume provisioning</li> <li>Storage class configuration</li> <li>Backup and snapshot policies</li> <li>Performance tuning</li> </ul>"},{"location":"infra/hosting/#file-storage","title":"File Storage","text":"<ul> <li>S3-compatible storage</li> <li>Access patterns and permissions</li> <li>Lifecycle management</li> <li>Cost optimization</li> </ul>"},{"location":"infra/hosting/#database-storage","title":"Database Storage","text":"<ul> <li>PostgreSQL storage configuration</li> <li>Backup storage locations</li> <li>Archive storage</li> <li>Replication storage</li> </ul>"},{"location":"infra/hosting/#deployment-infrastructure","title":"Deployment Infrastructure","text":"<p>TODO: Document deployment systems</p>"},{"location":"infra/hosting/#gitops-workflow","title":"GitOps Workflow","text":"<ul> <li>ArgoCD configuration</li> <li>Application manifests</li> <li>Sync policies</li> <li>Health checks</li> </ul>"},{"location":"infra/hosting/#helm-charts","title":"Helm Charts","text":"<ul> <li>Chart structure and organization</li> <li>Values management</li> <li>Template customization</li> <li>Release management</li> </ul>"},{"location":"infra/hosting/#container-registry","title":"Container Registry","text":"<ul> <li>Image storage and organization</li> <li>Tagging strategy</li> <li>Security scanning</li> <li>Retention policies</li> </ul>"},{"location":"infra/hosting/#environment-topology","title":"Environment Topology","text":"<p>TODO: Document environment setup</p>"},{"location":"infra/hosting/#development-environment","title":"Development Environment","text":"<ul> <li>Local development setup</li> <li>Development cluster</li> <li>Resource allocation</li> <li>Access controls</li> </ul>"},{"location":"infra/hosting/#staging-environment","title":"Staging Environment","text":"<ul> <li>Pre-production testing</li> <li>Production-like configuration</li> <li>Data isolation</li> <li>Performance testing</li> </ul>"},{"location":"infra/hosting/#production-environment","title":"Production Environment","text":"<ul> <li>High availability configuration</li> <li>Load distribution</li> <li>Monitoring and alerting</li> <li>Disaster recovery</li> </ul>"},{"location":"infra/hosting/#scaling-and-performance","title":"Scaling and Performance","text":"<p>TODO: Document scaling approaches</p>"},{"location":"infra/hosting/#horizontal-scaling","title":"Horizontal Scaling","text":"<ul> <li>Auto-scaling policies</li> <li>Resource quotas</li> <li>Node pool management</li> <li>Load distribution</li> </ul>"},{"location":"infra/hosting/#vertical-scaling","title":"Vertical Scaling","text":"<ul> <li>Resource limit adjustments</li> <li>Performance tuning</li> <li>Capacity planning</li> <li>Bottleneck identification</li> </ul>"},{"location":"infra/hosting/#network-scaling","title":"Network Scaling","text":"<ul> <li>Bandwidth management</li> <li>Connection pooling</li> <li>Latency optimization</li> <li>Throughput optimization</li> </ul>"},{"location":"infra/hosting/#security-infrastructure","title":"Security Infrastructure","text":"<p>TODO: Document security measures</p>"},{"location":"infra/hosting/#access-controls","title":"Access Controls","text":"<ul> <li>Role-based access control</li> <li>Service account management</li> <li>API key management</li> <li>Certificate management</li> </ul>"},{"location":"infra/hosting/#data-protection","title":"Data Protection","text":"<ul> <li>Encryption at rest</li> <li>Encryption in transit</li> <li>Key management</li> <li>Data loss prevention</li> </ul>"},{"location":"infra/hosting/#compliance","title":"Compliance","text":"<ul> <li>Regulatory requirements</li> <li>Audit logging</li> <li>Security scanning</li> <li>Vulnerability management</li> </ul> <p>For monitoring details, see Monitoring &amp; Logging.</p>"},{"location":"infra/monitoring/","title":"Monitoring &amp; Logging","text":"<p>This document describes the monitoring, logging, and observability systems for the infrastructure.</p>"},{"location":"infra/monitoring/#monitoring-system","title":"Monitoring System","text":"<p>TODO: Document monitoring infrastructure</p>"},{"location":"infra/monitoring/#metrics-collection","title":"Metrics Collection","text":"<ul> <li>Prometheus for metric collection</li> <li>OpenTelemetry for distributed tracing</li> <li>Custom application metrics</li> <li>Infrastructure metrics</li> </ul>"},{"location":"infra/monitoring/#alerting-system","title":"Alerting System","text":"<ul> <li>Alertmanager configuration</li> <li>Notification channels</li> <li>Escalation policies</li> <li>Alert deduplication</li> </ul>"},{"location":"infra/monitoring/#visualization","title":"Visualization","text":"<ul> <li>Grafana dashboards</li> <li>Custom dashboard development</li> <li>Metric exploration</li> <li>Historical trend analysis</li> </ul>"},{"location":"infra/monitoring/#logging-infrastructure","title":"Logging Infrastructure","text":"<p>TODO: Document logging setup</p>"},{"location":"infra/monitoring/#log-collection","title":"Log Collection","text":"<ul> <li>Centralized log aggregation</li> <li>Log format standardization</li> <li>Structured logging implementation</li> <li>Log enrichment</li> </ul>"},{"location":"infra/monitoring/#log-storage","title":"Log Storage","text":"<ul> <li>Elasticsearch for log storage</li> <li>Log retention policies</li> <li>Index management</li> <li>Backup and recovery</li> </ul>"},{"location":"infra/monitoring/#log-analysis","title":"Log Analysis","text":"<ul> <li>Kibana for log visualization</li> <li>Log search and filtering</li> <li>Pattern recognition</li> <li>Anomaly detection</li> </ul>"},{"location":"infra/monitoring/#key-metrics","title":"Key Metrics","text":"<p>TODO: Document important metrics to monitor</p>"},{"location":"infra/monitoring/#application-metrics","title":"Application Metrics","text":"<ul> <li>Request latency</li> <li>Error rates</li> <li>Throughput</li> <li>Resource utilization</li> </ul>"},{"location":"infra/monitoring/#database-metrics","title":"Database Metrics","text":"<ul> <li>Query performance</li> <li>Connection pool usage</li> <li>Lock contention</li> <li>Storage utilization</li> </ul>"},{"location":"infra/monitoring/#infrastructure-metrics","title":"Infrastructure Metrics","text":"<ul> <li>CPU usage</li> <li>Memory consumption</li> <li>Network I/O</li> <li>Disk I/O</li> </ul>"},{"location":"infra/monitoring/#business-metrics","title":"Business Metrics","text":"<ul> <li>User activity</li> <li>Data processing volume</li> <li>Report generation</li> <li>System adoption</li> </ul>"},{"location":"infra/monitoring/#dashboard-design","title":"Dashboard Design","text":"<p>TODO: Document dashboard organization</p>"},{"location":"infra/monitoring/#system-overview","title":"System Overview","text":"<ul> <li>High-level health indicators</li> <li>Critical service status</li> <li>Performance summaries</li> <li>Alert summaries</li> </ul>"},{"location":"infra/monitoring/#detailed-views","title":"Detailed Views","text":"<ul> <li>Service-specific dashboards</li> <li>Database performance dashboards</li> <li>Infrastructure resource dashboards</li> <li>Business metric dashboards</li> </ul>"},{"location":"infra/monitoring/#custom-dashboards","title":"Custom Dashboards","text":"<ul> <li>Team-specific views</li> <li>Project-specific monitoring</li> <li>Experimental metrics</li> <li>Ad-hoc analysis</li> </ul>"},{"location":"infra/monitoring/#alerting-strategy","title":"Alerting Strategy","text":"<p>TODO: Document alerting approaches</p>"},{"location":"infra/monitoring/#alert-categories","title":"Alert Categories","text":"<ul> <li>Critical alerts (immediate response)</li> <li>Warning alerts (timely response)</li> <li>Info alerts (periodic review)</li> <li>Debug alerts (troubleshooting)</li> </ul>"},{"location":"infra/monitoring/#alert-thresholds","title":"Alert Thresholds","text":"<ul> <li>Static thresholds</li> <li>Dynamic thresholds</li> <li>Statistical anomaly detection</li> <li>Machine learning-based detection</li> </ul>"},{"location":"infra/monitoring/#notification-channels","title":"Notification Channels","text":"<ul> <li>Email notifications</li> <li>Slack integration</li> <li>SMS alerts</li> <li>PagerDuty integration</li> </ul>"},{"location":"infra/monitoring/#log-management","title":"Log Management","text":"<p>TODO: Document log handling</p>"},{"location":"infra/monitoring/#log-levels","title":"Log Levels","text":"<ul> <li>Error logs</li> <li>Warning logs</li> <li>Info logs</li> <li>Debug logs</li> </ul>"},{"location":"infra/monitoring/#log-retention","title":"Log Retention","text":"<ul> <li>Short-term retention (high detail)</li> <li>Medium-term retention (reduced detail)</li> <li>Long-term retention (minimal detail)</li> <li>Archive storage</li> </ul>"},{"location":"infra/monitoring/#log-security","title":"Log Security","text":"<ul> <li>Log access controls</li> <li>Sensitive data filtering</li> <li>Log encryption</li> <li>Compliance considerations</li> </ul>"},{"location":"infra/monitoring/#tracing-and-profiling","title":"Tracing and Profiling","text":"<p>TODO: Document distributed tracing</p>"},{"location":"infra/monitoring/#request-tracing","title":"Request Tracing","text":"<ul> <li>End-to-end request tracking</li> <li>Service hop visualization</li> <li>Latency analysis</li> <li>Error propagation tracking</li> </ul>"},{"location":"infra/monitoring/#performance-profiling","title":"Performance Profiling","text":"<ul> <li>CPU profiling</li> <li>Memory profiling</li> <li>I/O profiling</li> <li>Database query profiling</li> </ul>"},{"location":"infra/monitoring/#bottleneck-identification","title":"Bottleneck Identification","text":"<ul> <li>Slow service detection</li> <li>Resource contention analysis</li> <li>Inefficient code paths</li> <li>Optimization opportunities</li> </ul>"},{"location":"infra/monitoring/#incident-response","title":"Incident Response","text":"<p>TODO: Document incident handling</p>"},{"location":"infra/monitoring/#detection","title":"Detection","text":"<ul> <li>Automated alerting</li> <li>Manual detection</li> <li>User-reported issues</li> <li>Proactive monitoring</li> </ul>"},{"location":"infra/monitoring/#response-procedures","title":"Response Procedures","text":"<ul> <li>Initial triage</li> <li>Escalation protocols</li> <li>Communication plans</li> <li>Resolution tracking</li> </ul>"},{"location":"infra/monitoring/#post-incident-analysis","title":"Post-Incident Analysis","text":"<ul> <li>Root cause analysis</li> <li>Impact assessment</li> <li>Preventive measures</li> <li>Documentation updates</li> </ul> <p>For hosting details, see Hosting &amp; Network.</p>"}]}